{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "train_mnist = loadmat('mnist_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_mnist['train_X']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_mnist['train_labels']\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAE model and training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "z_dim = 100\n",
    "X_dim = 784\n",
    "train_batch_size = 5000\n",
    "N = 1000\n",
    "epochs = 200\n",
    "cuda = False\n",
    "\n",
    "params = {'n_classes': n_classes, 'z_dim': z_dim, 'X_dim': X_dim,\n",
    "          'train_batch_size': train_batch_size,\n",
    "          'N': N, 'epochs': epochs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyMNISTDataset(object):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataset = MyMNISTDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAE Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Q_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Q_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(X_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        # Gaussian code (z)\n",
    "        self.lin3gauss = nn.Linear(N, z_dim)\n",
    "        # Categorical code (y)\n",
    "        self.lin3cat = nn.Linear(N, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        xgauss = self.lin3gauss(x)\n",
    "        xcat = F.softmax(self.lin3cat(x))\n",
    "\n",
    "        return xcat, xgauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class P_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(P_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim + n_classes, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, X_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Category discriminative network \n",
    "class D_net_cat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D_net_cat, self).__init__()\n",
    "        self.lin1 = nn.Linear(n_classes, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin3(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian discriminative network\n",
    "class D_net_gauss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D_net_gauss, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.2, training=self.training)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return F.sigmoid(self.lin3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some suporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_categorical(batch_size, n_classes=10):\n",
    "    '''\n",
    "     Sample from a categorical distribution\n",
    "     of size batch_size and # of classes n_classes\n",
    "     return: torch.autograd.Variable with the sample\n",
    "    '''\n",
    "    cat = np.random.randint(0, 10, batch_size)\n",
    "    cat = np.eye(n_classes)[cat].astype('float32')\n",
    "    cat = torch.from_numpy(cat)\n",
    "    return Variable(cat)\n",
    "\n",
    "\n",
    "def report_loss(epoch, D_loss_cat, D_loss_gauss, G_loss, recon_loss):\n",
    "    '''\n",
    "    Print loss\n",
    "    '''\n",
    "    print('Epoch-{}; D_loss_cat: {:.4}; D_loss_gauss: {:.4}; G_loss: {:.4}, reco_loss: {:.4}' \\\n",
    "          .format(epoch,D_loss_cat.data[0],D_loss_gauss.data[0],G_loss.data[0],recon_loss.data[0]))\n",
    "\n",
    "\n",
    "def get_categorical(labels, n_classes=10):\n",
    "    cat = np.array(labels.data.tolist())\n",
    "    cat = np.eye(n_classes)[cat].astype('float32')\n",
    "    cat = torch.from_numpy(cat)\n",
    "    return Variable(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_accuracy(Q, data_loader):\n",
    "    Q.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (X, target) in enumerate(data_loader):\n",
    "        X.resize_(data_loader.batch_size, X_dim)\n",
    "        X = Variable(X.float())\n",
    "        target = target.numpy()\n",
    "        \n",
    "        output = Q(X)[0]\n",
    "        pred = output.data.max(1)[1].numpy()\n",
    "        batch_loss = pred.__eq__(target).sum() / target.shape[0]\n",
    "        correct += batch_loss\n",
    "    return 100. * correct / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch, P, Q, D_cat, D_gauss, P_solver, Q_solver, Q_generator_solver, D_cat_solver, D_gauss_solver, train_labeled_loader):\n",
    "    '''\n",
    "    Train procedure for one epoch.\n",
    "    '''\n",
    "    TINY = 1e-15\n",
    "    # Set the networks in train mode (apply dropout when needed)\n",
    "    Q.train()\n",
    "    P.train()\n",
    "    D_cat.train()\n",
    "    D_gauss.train()\n",
    "\n",
    "    for batch_idx, (X, target) in enumerate(train_labeled_loader):\n",
    "        X.resize_(train_batch_size, X_dim)        \n",
    "        X, target = Variable(X.float()), Variable(target.float())\n",
    "        \n",
    "        # Init gradients\n",
    "        P.zero_grad()\n",
    "        Q.zero_grad()\n",
    "        D_cat.zero_grad()\n",
    "        D_gauss.zero_grad()\n",
    "\n",
    "        #######################\n",
    "        # Reconstruction phase\n",
    "        #######################\n",
    "        z_sample = torch.cat(Q(X), 1)    # concatenate label and embedding\n",
    "        X_sample = P(z_sample)\n",
    "\n",
    "        recon_loss = F.binary_cross_entropy(X_sample + TINY, X.resize(train_batch_size, X_dim) + TINY)\n",
    "        recon_loss.backward()\n",
    "        P_solver.step()\n",
    "        Q_solver.step()\n",
    "\n",
    "        P.zero_grad()\n",
    "        Q.zero_grad()\n",
    "        D_cat.zero_grad()\n",
    "        D_gauss.zero_grad()\n",
    "\n",
    "        ######################################################\n",
    "        # Generative Advesarial netowrk Regularization phase\n",
    "        ######################################################\n",
    "        # Discriminator training\n",
    "        Q.eval()\n",
    "        z_real_cat = sample_categorical(train_batch_size, n_classes=n_classes)\n",
    "        z_real_gauss = Variable(torch.randn(train_batch_size, z_dim))\n",
    "\n",
    "        z_fake_cat, z_fake_gauss = Q(X)\n",
    "\n",
    "        D_real_cat = D_cat(z_real_cat)\n",
    "        D_real_gauss = D_gauss(z_real_gauss)\n",
    "        D_fake_cat = D_cat(z_fake_cat)\n",
    "        D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "\n",
    "        D_loss_cat = -torch.mean(torch.log(D_real_cat + TINY) + torch.log(1 - D_fake_cat + TINY))\n",
    "        D_loss_gauss = -torch.mean(torch.log(D_real_gauss + TINY) + torch.log(1 - D_fake_gauss + TINY))\n",
    "\n",
    "        D_loss = D_loss_cat + D_loss_gauss\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_cat_solver.step()\n",
    "        D_gauss_solver.step()\n",
    "\n",
    "        P.zero_grad()\n",
    "        Q.zero_grad()\n",
    "        D_cat.zero_grad()\n",
    "        D_gauss.zero_grad()\n",
    "\n",
    "\n",
    "        z_fake_cat, z_fake_gauss = Q(X)\n",
    "        D_fake_cat = D_cat(z_fake_cat)\n",
    "        D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "        G_loss = - torch.mean(torch.log(D_fake_cat + TINY)) - torch.mean(torch.log(D_fake_gauss + TINY))          \n",
    "        G_loss = G_loss \n",
    "        \n",
    "        # Generator training \n",
    "        # the generator requires informative gradients in order to modify its parameters and do well at the next \n",
    "        # iteration. It requires a strong discriminator so that it can learn to \"fool\" it the next round. If the \n",
    "        # discriminator is poor and simply forms a decision boundary on the basis of gross input features (like \n",
    "        # the mean of the image, e.g.), the gradients from that classification will be less helpful for the generator, \n",
    "        # and so the generator will never go beyond a simple bad generated version of the data distribution.\n",
    "        if (epoch > 0 and epoch % 3 == 0):\n",
    "            Q.train()\n",
    "            z_fake_cat, z_fake_gauss = Q(X)\n",
    "\n",
    "            D_fake_cat = D_cat(z_fake_cat)\n",
    "            D_fake_gauss = D_gauss(z_fake_gauss)\n",
    "\n",
    "            G_loss = - torch.mean(torch.log(D_fake_cat + TINY)) - torch.mean(torch.log(D_fake_gauss + TINY))          \n",
    "            G_loss = G_loss\n",
    "            G_loss.backward()\n",
    "            Q_generator_solver.step()\n",
    "\n",
    "            P.zero_grad()\n",
    "            Q.zero_grad()\n",
    "            D_cat.zero_grad()\n",
    "            D_gauss.zero_grad()\n",
    "            \n",
    "            G_loss = G_loss\n",
    "\n",
    "            \n",
    "\n",
    "        print(\"the {}-th batch at \".format(batch_idx))\n",
    "        report_loss(epoch, D_loss_cat, D_loss_gauss, G_loss, recon_loss)\n",
    "    \n",
    "    return D_loss_cat, D_loss_gauss, G_loss, recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def generate_model(train_labeled_loader):\n",
    "    torch.manual_seed(10)\n",
    "\n",
    "    Q = Q_net()\n",
    "    P = P_net()\n",
    "    D_gauss = D_net_gauss()\n",
    "    D_cat = D_net_cat()\n",
    "\n",
    "    # Set learning rates\n",
    "    gen_lr = 0.001\n",
    "    reg_D_lr = 0.001\n",
    "    reg_G_lr = 0.001\n",
    "\n",
    "    # Set optimizators\n",
    "    P_solver = optim.Adam(P.parameters(), lr=gen_lr)   # decoder optimizer\n",
    "    Q_solver = optim.Adam(Q.parameters(), lr=gen_lr)   # encoder optimizer\n",
    "\n",
    "\n",
    "    Q_generator_solver = optim.Adam(Q.parameters(), lr=reg_G_lr)   # decoder optimizer for GAN generator\n",
    "     \n",
    "    D_gauss_solver = optim.Adam(D_gauss.parameters(), lr=reg_D_lr) # optimizer for GAN Gauss discriminator\n",
    "    D_cat_solver = optim.Adam(D_cat.parameters(), lr=reg_D_lr)     # optimizer for GAN Ca discriminator\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        D_loss_cat, D_loss_gauss, G_loss, recon_loss = train(epoch, P, Q, D_cat,\n",
    "                                                                         D_gauss, P_solver,\n",
    "                                                                         Q_solver, Q_generator_solver,\n",
    "                                                                         D_cat_solver, D_gauss_solver,\n",
    "                                                                         train_labeled_loader)\n",
    "        if epoch % 1 == 0:\n",
    "            train_acc = classification_accuracy(Q, train_labeled_loader)\n",
    "            print('Train accuracy: {} %'.format(train_acc))\n",
    "    end = time.time()\n",
    "    print('Training time: {} minutes'.format((end - start)/60))\n",
    "\n",
    "    return Q, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0-th batch at \n",
      "Epoch-0; D_loss_cat: 1.393; D_loss_gauss: 1.35; G_loss: 1.303, reco_loss: 0.7106\n",
      "the 1-th batch at \n",
      "Epoch-0; D_loss_cat: 1.248; D_loss_gauss: 1.044; G_loss: 1.403, reco_loss: 0.6847\n",
      "the 2-th batch at \n",
      "Epoch-0; D_loss_cat: 1.126; D_loss_gauss: 1.009; G_loss: 1.686, reco_loss: 0.6096\n",
      "the 3-th batch at \n",
      "Epoch-0; D_loss_cat: 1.009; D_loss_gauss: 0.6079; G_loss: 2.58, reco_loss: 0.4481\n",
      "the 4-th batch at \n",
      "Epoch-0; D_loss_cat: 0.8721; D_loss_gauss: 0.2765; G_loss: 3.311, reco_loss: 0.4118\n",
      "the 5-th batch at \n",
      "Epoch-0; D_loss_cat: 0.7412; D_loss_gauss: 0.2012; G_loss: 3.664, reco_loss: 0.3424\n",
      "the 6-th batch at \n",
      "Epoch-0; D_loss_cat: 0.6205; D_loss_gauss: 0.1661; G_loss: 3.993, reco_loss: 0.2923\n",
      "the 7-th batch at \n",
      "Epoch-0; D_loss_cat: 0.5084; D_loss_gauss: 0.1286; G_loss: 4.462, reco_loss: 0.2999\n",
      "the 8-th batch at \n",
      "Epoch-0; D_loss_cat: 0.4079; D_loss_gauss: 0.08711; G_loss: 5.14, reco_loss: 0.3097\n",
      "the 9-th batch at \n",
      "Epoch-0; D_loss_cat: 0.3305; D_loss_gauss: 0.05152; G_loss: 6.026, reco_loss: 0.3065\n",
      "the 10-th batch at \n",
      "Epoch-0; D_loss_cat: 0.2602; D_loss_gauss: 0.02804; G_loss: 7.122, reco_loss: 0.2966\n",
      "the 11-th batch at \n",
      "Epoch-0; D_loss_cat: 0.206; D_loss_gauss: 0.0155; G_loss: 8.305, reco_loss: 0.2853\n",
      "Train accuracy: 3.039912666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-1; D_loss_cat: 0.1571; D_loss_gauss: 0.01138; G_loss: 9.265, reco_loss: 0.2759\n",
      "the 1-th batch at \n",
      "Epoch-1; D_loss_cat: 0.1183; D_loss_gauss: 0.01024; G_loss: 9.857, reco_loss: 0.2728\n",
      "the 2-th batch at \n",
      "Epoch-1; D_loss_cat: 0.08956; D_loss_gauss: 0.0118; G_loss: 10.01, reco_loss: 0.269\n",
      "the 3-th batch at \n",
      "Epoch-1; D_loss_cat: 0.06587; D_loss_gauss: 0.01546; G_loss: 9.952, reco_loss: 0.2649\n",
      "the 4-th batch at \n",
      "Epoch-1; D_loss_cat: 0.0499; D_loss_gauss: 0.01965; G_loss: 9.959, reco_loss: 0.2635\n",
      "the 5-th batch at \n",
      "Epoch-1; D_loss_cat: 0.03763; D_loss_gauss: 0.02168; G_loss: 10.25, reco_loss: 0.2632\n",
      "the 6-th batch at \n",
      "Epoch-1; D_loss_cat: 0.02863; D_loss_gauss: 0.02242; G_loss: 10.65, reco_loss: 0.2649\n",
      "the 7-th batch at \n",
      "Epoch-1; D_loss_cat: 0.02216; D_loss_gauss: 0.02049; G_loss: 11.39, reco_loss: 0.2636\n",
      "the 8-th batch at \n",
      "Epoch-1; D_loss_cat: 0.01744; D_loss_gauss: 0.01661; G_loss: 12.28, reco_loss: 0.262\n",
      "the 9-th batch at \n",
      "Epoch-1; D_loss_cat: 0.0141; D_loss_gauss: 0.01546; G_loss: 12.86, reco_loss: 0.2602\n",
      "the 10-th batch at \n",
      "Epoch-1; D_loss_cat: 0.01133; D_loss_gauss: 0.01551; G_loss: 13.15, reco_loss: 0.2588\n",
      "the 11-th batch at \n",
      "Epoch-1; D_loss_cat: 0.009668; D_loss_gauss: 0.0189; G_loss: 13.2, reco_loss: 0.2583\n",
      "Train accuracy: 0.0 %\n",
      "the 0-th batch at \n",
      "Epoch-2; D_loss_cat: 0.007826; D_loss_gauss: 0.01929; G_loss: 13.26, reco_loss: 0.2576\n",
      "the 1-th batch at \n",
      "Epoch-2; D_loss_cat: 0.006948; D_loss_gauss: 0.02022; G_loss: 13.48, reco_loss: 0.2561\n",
      "the 2-th batch at \n",
      "Epoch-2; D_loss_cat: 0.006455; D_loss_gauss: 0.01966; G_loss: 13.78, reco_loss: 0.2548\n",
      "the 3-th batch at \n",
      "Epoch-2; D_loss_cat: 0.005874; D_loss_gauss: 0.01857; G_loss: 14.19, reco_loss: 0.255\n",
      "the 4-th batch at \n",
      "Epoch-2; D_loss_cat: 0.006455; D_loss_gauss: 0.01701; G_loss: 14.55, reco_loss: 0.256\n",
      "the 5-th batch at \n",
      "Epoch-2; D_loss_cat: 0.007346; D_loss_gauss: 0.01639; G_loss: 15.07, reco_loss: 0.255\n",
      "the 6-th batch at \n",
      "Epoch-2; D_loss_cat: 0.008253; D_loss_gauss: 0.01581; G_loss: 15.42, reco_loss: 0.2539\n",
      "the 7-th batch at \n",
      "Epoch-2; D_loss_cat: 0.00975; D_loss_gauss: 0.01867; G_loss: 15.78, reco_loss: 0.2542\n",
      "the 8-th batch at \n",
      "Epoch-2; D_loss_cat: 0.01136; D_loss_gauss: 0.01919; G_loss: 16.17, reco_loss: 0.2514\n",
      "the 9-th batch at \n",
      "Epoch-2; D_loss_cat: 0.01235; D_loss_gauss: 0.01894; G_loss: 16.61, reco_loss: 0.2512\n",
      "the 10-th batch at \n",
      "Epoch-2; D_loss_cat: 0.01594; D_loss_gauss: 0.01827; G_loss: 17.07, reco_loss: 0.251\n",
      "the 11-th batch at \n",
      "Epoch-2; D_loss_cat: 0.01928; D_loss_gauss: 0.0161; G_loss: 17.68, reco_loss: 0.2496\n",
      "Train accuracy: 0.00018133333333333331 %\n",
      "the 0-th batch at \n",
      "Epoch-3; D_loss_cat: 0.02319; D_loss_gauss: 0.0165; G_loss: 17.94, reco_loss: 0.2508\n",
      "the 1-th batch at \n",
      "Epoch-3; D_loss_cat: 0.03791; D_loss_gauss: 0.0635; G_loss: 13.69, reco_loss: 0.259\n",
      "the 2-th batch at \n",
      "Epoch-3; D_loss_cat: 0.06586; D_loss_gauss: 0.1759; G_loss: 11.98, reco_loss: 0.2639\n",
      "the 3-th batch at \n",
      "Epoch-3; D_loss_cat: 0.0925; D_loss_gauss: 0.8835; G_loss: 11.48, reco_loss: 0.2634\n",
      "the 4-th batch at \n",
      "Epoch-3; D_loss_cat: 0.1303; D_loss_gauss: 1.532; G_loss: 11.17, reco_loss: 0.2572\n",
      "the 5-th batch at \n",
      "Epoch-3; D_loss_cat: 0.1513; D_loss_gauss: 1.827; G_loss: 10.77, reco_loss: 0.2551\n",
      "the 6-th batch at \n",
      "Epoch-3; D_loss_cat: 0.17; D_loss_gauss: 1.463; G_loss: 10.89, reco_loss: 0.2551\n",
      "the 7-th batch at \n",
      "Epoch-3; D_loss_cat: 0.1908; D_loss_gauss: 0.7806; G_loss: 11.89, reco_loss: 0.2592\n",
      "the 8-th batch at \n",
      "Epoch-3; D_loss_cat: 0.1721; D_loss_gauss: 0.7043; G_loss: 12.71, reco_loss: 0.255\n",
      "the 9-th batch at \n",
      "Epoch-3; D_loss_cat: 0.1832; D_loss_gauss: 0.6254; G_loss: 13.01, reco_loss: 0.2516\n",
      "the 10-th batch at \n",
      "Epoch-3; D_loss_cat: 0.1866; D_loss_gauss: 0.5044; G_loss: 13.7, reco_loss: 0.2563\n",
      "the 11-th batch at \n",
      "Epoch-3; D_loss_cat: 0.1759; D_loss_gauss: 0.3529; G_loss: 13.99, reco_loss: 0.2549\n",
      "Train accuracy: 7.285093666666665 %\n",
      "the 0-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1697; D_loss_gauss: 0.2607; G_loss: 13.68, reco_loss: 0.2555\n",
      "the 1-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1786; D_loss_gauss: 0.1735; G_loss: 14.32, reco_loss: 0.2546\n",
      "the 2-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1809; D_loss_gauss: 0.1155; G_loss: 15.17, reco_loss: 0.2523\n",
      "the 3-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1832; D_loss_gauss: 0.0832; G_loss: 15.53, reco_loss: 0.2512\n",
      "the 4-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1731; D_loss_gauss: 0.05966; G_loss: 15.64, reco_loss: 0.2497\n",
      "the 5-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1808; D_loss_gauss: 0.05373; G_loss: 15.46, reco_loss: 0.2482\n",
      "the 6-th batch at \n",
      "Epoch-4; D_loss_cat: 0.173; D_loss_gauss: 0.04689; G_loss: 15.68, reco_loss: 0.2468\n",
      "the 7-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1669; D_loss_gauss: 0.04234; G_loss: 15.99, reco_loss: 0.2457\n",
      "the 8-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1534; D_loss_gauss: 0.0369; G_loss: 15.7, reco_loss: 0.2472\n",
      "the 9-th batch at \n",
      "Epoch-4; D_loss_cat: 0.149; D_loss_gauss: 0.03144; G_loss: 15.49, reco_loss: 0.2468\n",
      "the 10-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1533; D_loss_gauss: 0.0275; G_loss: 15.51, reco_loss: 0.2461\n",
      "the 11-th batch at \n",
      "Epoch-4; D_loss_cat: 0.1545; D_loss_gauss: 0.02291; G_loss: 15.64, reco_loss: 0.245\n",
      "Train accuracy: 3.9063943333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1554; D_loss_gauss: 0.01981; G_loss: 15.99, reco_loss: 0.2447\n",
      "the 1-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1498; D_loss_gauss: 0.01937; G_loss: 16.35, reco_loss: 0.2457\n",
      "the 2-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1659; D_loss_gauss: 0.01245; G_loss: 16.91, reco_loss: 0.2434\n",
      "the 3-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1645; D_loss_gauss: 0.01154; G_loss: 17.51, reco_loss: 0.2407\n",
      "the 4-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1695; D_loss_gauss: 0.01081; G_loss: 17.51, reco_loss: 0.2425\n",
      "the 5-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1656; D_loss_gauss: 0.0108; G_loss: 17.24, reco_loss: 0.2409\n",
      "the 6-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1541; D_loss_gauss: 0.00822; G_loss: 16.9, reco_loss: 0.2409\n",
      "the 7-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1518; D_loss_gauss: 0.009754; G_loss: 16.79, reco_loss: 0.2414\n",
      "the 8-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1716; D_loss_gauss: 0.008425; G_loss: 17.24, reco_loss: 0.2408\n",
      "the 9-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1724; D_loss_gauss: 0.006596; G_loss: 17.71, reco_loss: 0.2385\n",
      "the 10-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1754; D_loss_gauss: 0.005294; G_loss: 17.67, reco_loss: 0.2392\n",
      "the 11-th batch at \n",
      "Epoch-5; D_loss_cat: 0.1653; D_loss_gauss: 0.006432; G_loss: 17.67, reco_loss: 0.2373\n",
      "Train accuracy: 1.8003046666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1551; D_loss_gauss: 0.00682; G_loss: 17.84, reco_loss: 0.2387\n",
      "the 1-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1556; D_loss_gauss: 0.009206; G_loss: 16.49, reco_loss: 0.2414\n",
      "the 2-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1412; D_loss_gauss: 0.01621; G_loss: 14.57, reco_loss: 0.241\n",
      "the 3-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1359; D_loss_gauss: 0.05227; G_loss: 12.46, reco_loss: 0.2389\n",
      "the 4-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1447; D_loss_gauss: 0.1918; G_loss: 10.83, reco_loss: 0.239\n",
      "the 5-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1282; D_loss_gauss: 0.5928; G_loss: 9.812, reco_loss: 0.24\n",
      "the 6-th batch at \n",
      "Epoch-6; D_loss_cat: 0.125; D_loss_gauss: 0.9587; G_loss: 9.409, reco_loss: 0.2371\n",
      "the 7-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1082; D_loss_gauss: 1.22; G_loss: 9.365, reco_loss: 0.2368\n",
      "the 8-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1048; D_loss_gauss: 1.556; G_loss: 9.589, reco_loss: 0.2382\n",
      "the 9-th batch at \n",
      "Epoch-6; D_loss_cat: 0.1027; D_loss_gauss: 1.321; G_loss: 10.62, reco_loss: 0.2356\n",
      "the 10-th batch at \n",
      "Epoch-6; D_loss_cat: 0.08143; D_loss_gauss: 0.5511; G_loss: 12.41, reco_loss: 0.2405\n",
      "the 11-th batch at \n",
      "Epoch-6; D_loss_cat: 0.07035; D_loss_gauss: 0.3131; G_loss: 14.58, reco_loss: 0.2357\n",
      "Train accuracy: 6.848984000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-7; D_loss_cat: 0.06085; D_loss_gauss: 0.5146; G_loss: 16.4, reco_loss: 0.2373\n",
      "the 1-th batch at \n",
      "Epoch-7; D_loss_cat: 0.09965; D_loss_gauss: 0.7115; G_loss: 19.5, reco_loss: 0.2393\n",
      "the 2-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1057; D_loss_gauss: 0.7465; G_loss: 21.41, reco_loss: 0.2338\n",
      "the 3-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1202; D_loss_gauss: 0.5978; G_loss: 21.8, reco_loss: 0.2341\n",
      "the 4-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1284; D_loss_gauss: 0.3909; G_loss: 21.32, reco_loss: 0.2322\n",
      "the 5-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1175; D_loss_gauss: 0.2187; G_loss: 20.65, reco_loss: 0.2309\n",
      "the 6-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1254; D_loss_gauss: 0.1192; G_loss: 20.42, reco_loss: 0.231\n",
      "the 7-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1281; D_loss_gauss: 0.06875; G_loss: 20.92, reco_loss: 0.2296\n",
      "the 8-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1225; D_loss_gauss: 0.03254; G_loss: 21.36, reco_loss: 0.2303\n",
      "the 9-th batch at \n",
      "Epoch-7; D_loss_cat: 0.134; D_loss_gauss: 0.01814; G_loss: 21.04, reco_loss: 0.2292\n",
      "the 10-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1233; D_loss_gauss: 0.008135; G_loss: 20.53, reco_loss: 0.2264\n",
      "the 11-th batch at \n",
      "Epoch-7; D_loss_cat: 0.1292; D_loss_gauss: 0.005999; G_loss: 19.99, reco_loss: 0.2259\n",
      "Train accuracy: 4.366615666666665 %\n",
      "the 0-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1179; D_loss_gauss: 0.003128; G_loss: 19.49, reco_loss: 0.2282\n",
      "the 1-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1197; D_loss_gauss: 0.004065; G_loss: 19.24, reco_loss: 0.227\n",
      "the 2-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1175; D_loss_gauss: 0.002517; G_loss: 18.92, reco_loss: 0.2267\n",
      "the 3-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1123; D_loss_gauss: 0.00413; G_loss: 18.83, reco_loss: 0.2261\n",
      "the 4-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1308; D_loss_gauss: 0.005269; G_loss: 18.93, reco_loss: 0.2244\n",
      "the 5-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1359; D_loss_gauss: 0.00517; G_loss: 19.24, reco_loss: 0.2235\n",
      "the 6-th batch at \n",
      "Epoch-8; D_loss_cat: 0.139; D_loss_gauss: 0.006249; G_loss: 19.32, reco_loss: 0.2225\n",
      "the 7-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1374; D_loss_gauss: 0.008714; G_loss: 18.96, reco_loss: 0.2216\n",
      "the 8-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1374; D_loss_gauss: 0.008519; G_loss: 18.56, reco_loss: 0.2229\n",
      "the 9-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1192; D_loss_gauss: 0.008208; G_loss: 18.02, reco_loss: 0.2241\n",
      "the 10-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1371; D_loss_gauss: 0.006334; G_loss: 18.38, reco_loss: 0.2223\n",
      "the 11-th batch at \n",
      "Epoch-8; D_loss_cat: 0.1346; D_loss_gauss: 0.004125; G_loss: 18.69, reco_loss: 0.2212\n",
      "Train accuracy: 4.2101396666666675 %\n",
      "the 0-th batch at \n",
      "Epoch-9; D_loss_cat: 0.1358; D_loss_gauss: 0.003556; G_loss: 18.6, reco_loss: 0.2232\n",
      "the 1-th batch at \n",
      "Epoch-9; D_loss_cat: 0.1215; D_loss_gauss: 0.004445; G_loss: 17.77, reco_loss: 0.2236\n",
      "the 2-th batch at \n",
      "Epoch-9; D_loss_cat: 0.09811; D_loss_gauss: 0.009516; G_loss: 16.63, reco_loss: 0.2259\n",
      "the 3-th batch at \n",
      "Epoch-9; D_loss_cat: 0.09181; D_loss_gauss: 0.03293; G_loss: 15.63, reco_loss: 0.2254\n",
      "the 4-th batch at \n",
      "Epoch-9; D_loss_cat: 0.06671; D_loss_gauss: 0.08121; G_loss: 14.6, reco_loss: 0.2266\n",
      "the 5-th batch at \n",
      "Epoch-9; D_loss_cat: 0.05614; D_loss_gauss: 0.1887; G_loss: 13.54, reco_loss: 0.2266\n",
      "the 6-th batch at \n",
      "Epoch-9; D_loss_cat: 0.04197; D_loss_gauss: 0.4153; G_loss: 12.3, reco_loss: 0.2262\n",
      "the 7-th batch at \n",
      "Epoch-9; D_loss_cat: 0.03869; D_loss_gauss: 0.8585; G_loss: 10.96, reco_loss: 0.2251\n",
      "the 8-th batch at \n",
      "Epoch-9; D_loss_cat: 0.03754; D_loss_gauss: 1.157; G_loss: 10.18, reco_loss: 0.2252\n",
      "the 9-th batch at \n",
      "Epoch-9; D_loss_cat: 0.04654; D_loss_gauss: 1.29; G_loss: 9.918, reco_loss: 0.2248\n",
      "the 10-th batch at \n",
      "Epoch-9; D_loss_cat: 0.05886; D_loss_gauss: 1.038; G_loss: 10.57, reco_loss: 0.2255\n",
      "the 11-th batch at \n",
      "Epoch-9; D_loss_cat: 0.06246; D_loss_gauss: 0.8076; G_loss: 11.84, reco_loss: 0.2286\n",
      "Train accuracy: 7.901310333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-10; D_loss_cat: 0.08196; D_loss_gauss: 0.2712; G_loss: 14.28, reco_loss: 0.2285\n",
      "the 1-th batch at \n",
      "Epoch-10; D_loss_cat: 0.09703; D_loss_gauss: 0.04699; G_loss: 18.03, reco_loss: 0.2246\n",
      "the 2-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1087; D_loss_gauss: 0.1099; G_loss: 20.87, reco_loss: 0.22\n",
      "the 3-th batch at \n",
      "Epoch-10; D_loss_cat: 0.108; D_loss_gauss: 0.1992; G_loss: 23.47, reco_loss: 0.2217\n",
      "the 4-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1037; D_loss_gauss: 0.2647; G_loss: 25.32, reco_loss: 0.2212\n",
      "the 5-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1055; D_loss_gauss: 0.3602; G_loss: 26.49, reco_loss: 0.2214\n",
      "the 6-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1139; D_loss_gauss: 0.4229; G_loss: 27.15, reco_loss: 0.2203\n",
      "the 7-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1213; D_loss_gauss: 0.4481; G_loss: 27.55, reco_loss: 0.2194\n",
      "the 8-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1145; D_loss_gauss: 0.4114; G_loss: 27.55, reco_loss: 0.2187\n",
      "the 9-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1171; D_loss_gauss: 0.3667; G_loss: 27.42, reco_loss: 0.2171\n",
      "the 10-th batch at \n",
      "Epoch-10; D_loss_cat: 0.119; D_loss_gauss: 0.2797; G_loss: 27.05, reco_loss: 0.2185\n",
      "the 11-th batch at \n",
      "Epoch-10; D_loss_cat: 0.1159; D_loss_gauss: 0.2414; G_loss: 26.42, reco_loss: 0.2155\n",
      "Train accuracy: 7.058447666666668 %\n",
      "the 0-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1232; D_loss_gauss: 0.1644; G_loss: 25.79, reco_loss: 0.2186\n",
      "the 1-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1265; D_loss_gauss: 0.1125; G_loss: 25.45, reco_loss: 0.2161\n",
      "the 2-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1176; D_loss_gauss: 0.06905; G_loss: 24.77, reco_loss: 0.2142\n",
      "the 3-th batch at \n",
      "Epoch-11; D_loss_cat: 0.117; D_loss_gauss: 0.05459; G_loss: 24.41, reco_loss: 0.2157\n",
      "the 4-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1148; D_loss_gauss: 0.04461; G_loss: 23.68, reco_loss: 0.2139\n",
      "the 5-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1214; D_loss_gauss: 0.02258; G_loss: 23.24, reco_loss: 0.214\n",
      "the 6-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1228; D_loss_gauss: 0.02197; G_loss: 22.72, reco_loss: 0.2146\n",
      "the 7-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1186; D_loss_gauss: 0.0132; G_loss: 22.39, reco_loss: 0.2123\n",
      "the 8-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1165; D_loss_gauss: 0.01108; G_loss: 22.14, reco_loss: 0.2127\n",
      "the 9-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1169; D_loss_gauss: 0.009371; G_loss: 21.85, reco_loss: 0.2138\n",
      "the 10-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1226; D_loss_gauss: 0.005286; G_loss: 21.55, reco_loss: 0.2128\n",
      "the 11-th batch at \n",
      "Epoch-11; D_loss_cat: 0.1209; D_loss_gauss: 0.006874; G_loss: 21.29, reco_loss: 0.2117\n",
      "Train accuracy: 6.606200666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1268; D_loss_gauss: 0.003949; G_loss: 20.59, reco_loss: 0.2147\n",
      "the 1-th batch at \n",
      "Epoch-12; D_loss_cat: 0.121; D_loss_gauss: 0.003551; G_loss: 19.97, reco_loss: 0.2151\n",
      "the 2-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1069; D_loss_gauss: 0.003168; G_loss: 18.69, reco_loss: 0.2174\n",
      "the 3-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1145; D_loss_gauss: 0.004973; G_loss: 17.15, reco_loss: 0.2166\n",
      "the 4-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1206; D_loss_gauss: 0.02431; G_loss: 15.75, reco_loss: 0.2185\n",
      "the 5-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1364; D_loss_gauss: 0.1082; G_loss: 14.02, reco_loss: 0.2164\n",
      "the 6-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1276; D_loss_gauss: 0.285; G_loss: 12.22, reco_loss: 0.2171\n",
      "the 7-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1382; D_loss_gauss: 0.6266; G_loss: 10.74, reco_loss: 0.218\n",
      "the 8-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1589; D_loss_gauss: 0.9702; G_loss: 10.48, reco_loss: 0.2183\n",
      "the 9-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1929; D_loss_gauss: 1.06; G_loss: 10.9, reco_loss: 0.2162\n",
      "the 10-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1973; D_loss_gauss: 1.244; G_loss: 11.2, reco_loss: 0.2185\n",
      "the 11-th batch at \n",
      "Epoch-12; D_loss_cat: 0.1955; D_loss_gauss: 0.601; G_loss: 13.6, reco_loss: 0.2245\n",
      "Train accuracy: 7.892758000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-13; D_loss_cat: 0.2453; D_loss_gauss: 0.292; G_loss: 14.3, reco_loss: 0.2174\n",
      "the 1-th batch at \n",
      "Epoch-13; D_loss_cat: 0.2714; D_loss_gauss: 0.09958; G_loss: 17.57, reco_loss: 0.2209\n",
      "the 2-th batch at \n",
      "Epoch-13; D_loss_cat: 0.2248; D_loss_gauss: 0.08165; G_loss: 21.61, reco_loss: 0.216\n",
      "the 3-th batch at \n",
      "Epoch-13; D_loss_cat: 0.19; D_loss_gauss: 0.113; G_loss: 25.76, reco_loss: 0.2186\n",
      "the 4-th batch at \n",
      "Epoch-13; D_loss_cat: 0.1924; D_loss_gauss: 0.1641; G_loss: 28.07, reco_loss: 0.2109\n",
      "the 5-th batch at \n",
      "Epoch-13; D_loss_cat: 0.1983; D_loss_gauss: 0.2364; G_loss: 29.43, reco_loss: 0.2104\n",
      "the 6-th batch at \n",
      "Epoch-13; D_loss_cat: 0.2048; D_loss_gauss: 0.2737; G_loss: 29.96, reco_loss: 0.2124\n",
      "the 7-th batch at \n",
      "Epoch-13; D_loss_cat: 0.1735; D_loss_gauss: 0.2973; G_loss: 30.67, reco_loss: 0.2099\n",
      "the 8-th batch at \n",
      "Epoch-13; D_loss_cat: 0.1539; D_loss_gauss: 0.3372; G_loss: 30.95, reco_loss: 0.2095\n",
      "the 9-th batch at \n",
      "Epoch-13; D_loss_cat: 0.1519; D_loss_gauss: 0.3196; G_loss: 31.04, reco_loss: 0.209\n",
      "the 10-th batch at \n",
      "Epoch-13; D_loss_cat: 0.1515; D_loss_gauss: 0.319; G_loss: 30.99, reco_loss: 0.2073\n",
      "the 11-th batch at \n",
      "Epoch-13; D_loss_cat: 0.1559; D_loss_gauss: 0.3268; G_loss: 30.99, reco_loss: 0.206\n",
      "Train accuracy: 7.672979999999999 %\n",
      "the 0-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1508; D_loss_gauss: 0.257; G_loss: 30.86, reco_loss: 0.2095\n",
      "the 1-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1428; D_loss_gauss: 0.2119; G_loss: 30.51, reco_loss: 0.2055\n",
      "the 2-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1548; D_loss_gauss: 0.1905; G_loss: 29.71, reco_loss: 0.2034\n",
      "the 3-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1426; D_loss_gauss: 0.1399; G_loss: 29.12, reco_loss: 0.2045\n",
      "the 4-th batch at \n",
      "Epoch-14; D_loss_cat: 0.134; D_loss_gauss: 0.1253; G_loss: 28.53, reco_loss: 0.2045\n",
      "the 5-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1405; D_loss_gauss: 0.08737; G_loss: 28.22, reco_loss: 0.2028\n",
      "the 6-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1435; D_loss_gauss: 0.06337; G_loss: 28.37, reco_loss: 0.2011\n",
      "the 7-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1393; D_loss_gauss: 0.05711; G_loss: 28.14, reco_loss: 0.2007\n",
      "the 8-th batch at \n",
      "Epoch-14; D_loss_cat: 0.13; D_loss_gauss: 0.03216; G_loss: 27.58, reco_loss: 0.2017\n",
      "the 9-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1365; D_loss_gauss: 0.02547; G_loss: 27.11, reco_loss: 0.1982\n",
      "the 10-th batch at \n",
      "Epoch-14; D_loss_cat: 0.144; D_loss_gauss: 0.01755; G_loss: 26.58, reco_loss: 0.1994\n",
      "the 11-th batch at \n",
      "Epoch-14; D_loss_cat: 0.1382; D_loss_gauss: 0.02044; G_loss: 26.61, reco_loss: 0.1984\n",
      "Train accuracy: 7.1472359999999995 %\n",
      "the 0-th batch at \n",
      "Epoch-15; D_loss_cat: 0.1284; D_loss_gauss: 0.01126; G_loss: 26.27, reco_loss: 0.2024\n",
      "the 1-th batch at \n",
      "Epoch-15; D_loss_cat: 0.1494; D_loss_gauss: 0.009814; G_loss: 25.48, reco_loss: 0.2021\n",
      "the 2-th batch at \n",
      "Epoch-15; D_loss_cat: 0.1637; D_loss_gauss: 0.007723; G_loss: 23.5, reco_loss: 0.2034\n",
      "the 3-th batch at \n",
      "Epoch-15; D_loss_cat: 0.1721; D_loss_gauss: 0.007805; G_loss: 21.04, reco_loss: 0.2019\n",
      "the 4-th batch at \n",
      "Epoch-15; D_loss_cat: 0.1667; D_loss_gauss: 0.02798; G_loss: 18.36, reco_loss: 0.2038\n",
      "the 5-th batch at \n",
      "Epoch-15; D_loss_cat: 0.1852; D_loss_gauss: 0.1099; G_loss: 15.5, reco_loss: 0.2043\n",
      "the 6-th batch at \n",
      "Epoch-15; D_loss_cat: 0.2228; D_loss_gauss: 0.3887; G_loss: 12.97, reco_loss: 0.2032\n",
      "the 7-th batch at \n",
      "Epoch-15; D_loss_cat: 0.2295; D_loss_gauss: 0.9826; G_loss: 10.91, reco_loss: 0.2031\n",
      "the 8-th batch at \n",
      "Epoch-15; D_loss_cat: 0.2636; D_loss_gauss: 1.73; G_loss: 9.389, reco_loss: 0.2059\n",
      "the 9-th batch at \n",
      "Epoch-15; D_loss_cat: 0.2964; D_loss_gauss: 1.952; G_loss: 9.118, reco_loss: 0.2038\n",
      "the 10-th batch at \n",
      "Epoch-15; D_loss_cat: 0.349; D_loss_gauss: 1.399; G_loss: 8.684, reco_loss: 0.2056\n",
      "the 11-th batch at \n",
      "Epoch-15; D_loss_cat: 0.3971; D_loss_gauss: 0.6638; G_loss: 10.93, reco_loss: 0.2069\n",
      "Train accuracy: 7.960852333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-16; D_loss_cat: 0.4325; D_loss_gauss: 0.23; G_loss: 12.64, reco_loss: 0.2056\n",
      "the 1-th batch at \n",
      "Epoch-16; D_loss_cat: 0.4202; D_loss_gauss: 0.1126; G_loss: 15.85, reco_loss: 0.2176\n",
      "the 2-th batch at \n",
      "Epoch-16; D_loss_cat: 0.4433; D_loss_gauss: 0.1684; G_loss: 20.55, reco_loss: 0.2112\n",
      "the 3-th batch at \n",
      "Epoch-16; D_loss_cat: 0.3595; D_loss_gauss: 0.2403; G_loss: 24.48, reco_loss: 0.2094\n",
      "the 4-th batch at \n",
      "Epoch-16; D_loss_cat: 0.3531; D_loss_gauss: 0.324; G_loss: 26.67, reco_loss: 0.197\n",
      "the 5-th batch at \n",
      "Epoch-16; D_loss_cat: 0.3547; D_loss_gauss: 0.3694; G_loss: 28.56, reco_loss: 0.2027\n",
      "the 6-th batch at \n",
      "Epoch-16; D_loss_cat: 0.3184; D_loss_gauss: 0.3969; G_loss: 29.1, reco_loss: 0.1979\n",
      "the 7-th batch at \n",
      "Epoch-16; D_loss_cat: 0.3021; D_loss_gauss: 0.4321; G_loss: 28.29, reco_loss: 0.1928\n",
      "the 8-th batch at \n",
      "Epoch-16; D_loss_cat: 0.2815; D_loss_gauss: 0.4637; G_loss: 27.56, reco_loss: 0.1958\n",
      "the 9-th batch at \n",
      "Epoch-16; D_loss_cat: 0.2734; D_loss_gauss: 0.4139; G_loss: 27.2, reco_loss: 0.1963\n",
      "the 10-th batch at \n",
      "Epoch-16; D_loss_cat: 0.2632; D_loss_gauss: 0.3836; G_loss: 26.89, reco_loss: 0.1925\n",
      "the 11-th batch at \n",
      "Epoch-16; D_loss_cat: 0.2577; D_loss_gauss: 0.3358; G_loss: 26.11, reco_loss: 0.1898\n",
      "Train accuracy: 7.779491666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2678; D_loss_gauss: 0.2907; G_loss: 25.41, reco_loss: 0.196\n",
      "the 1-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2496; D_loss_gauss: 0.2408; G_loss: 24.96, reco_loss: 0.1918\n",
      "the 2-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2374; D_loss_gauss: 0.2; G_loss: 24.25, reco_loss: 0.1901\n",
      "the 3-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2343; D_loss_gauss: 0.1634; G_loss: 23.12, reco_loss: 0.1886\n",
      "the 4-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2435; D_loss_gauss: 0.1338; G_loss: 22.67, reco_loss: 0.1852\n",
      "the 5-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2353; D_loss_gauss: 0.1059; G_loss: 22.08, reco_loss: 0.1886\n",
      "the 6-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2437; D_loss_gauss: 0.07893; G_loss: 21.71, reco_loss: 0.1854\n",
      "the 7-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2502; D_loss_gauss: 0.05791; G_loss: 21.04, reco_loss: 0.1852\n",
      "the 8-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2509; D_loss_gauss: 0.04472; G_loss: 20.67, reco_loss: 0.1841\n",
      "the 9-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2452; D_loss_gauss: 0.03695; G_loss: 20.42, reco_loss: 0.1839\n",
      "the 10-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2336; D_loss_gauss: 0.0254; G_loss: 20.11, reco_loss: 0.1837\n",
      "the 11-th batch at \n",
      "Epoch-17; D_loss_cat: 0.2346; D_loss_gauss: 0.01847; G_loss: 19.46, reco_loss: 0.1803\n",
      "Train accuracy: 7.338985666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-18; D_loss_cat: 0.2244; D_loss_gauss: 0.01704; G_loss: 18.68, reco_loss: 0.188\n",
      "the 1-th batch at \n",
      "Epoch-18; D_loss_cat: 0.2889; D_loss_gauss: 0.02219; G_loss: 16.79, reco_loss: 0.1937\n",
      "the 2-th batch at \n",
      "Epoch-18; D_loss_cat: 0.307; D_loss_gauss: 0.06526; G_loss: 14.65, reco_loss: 0.1961\n",
      "the 3-th batch at \n",
      "Epoch-18; D_loss_cat: 0.3565; D_loss_gauss: 0.1767; G_loss: 11.21, reco_loss: 0.1947\n",
      "the 4-th batch at \n",
      "Epoch-18; D_loss_cat: 0.3746; D_loss_gauss: 0.6363; G_loss: 8.112, reco_loss: 0.1923\n",
      "the 5-th batch at \n",
      "Epoch-18; D_loss_cat: 0.3805; D_loss_gauss: 1.871; G_loss: 6.548, reco_loss: 0.1954\n",
      "the 6-th batch at \n",
      "Epoch-18; D_loss_cat: 0.4267; D_loss_gauss: 3.641; G_loss: 5.125, reco_loss: 0.1927\n",
      "the 7-th batch at \n",
      "Epoch-18; D_loss_cat: 0.4434; D_loss_gauss: 4.744; G_loss: 3.819, reco_loss: 0.194\n",
      "the 8-th batch at \n",
      "Epoch-18; D_loss_cat: 0.4651; D_loss_gauss: 4.477; G_loss: 3.742, reco_loss: 0.1979\n",
      "the 9-th batch at \n",
      "Epoch-18; D_loss_cat: 0.4677; D_loss_gauss: 2.957; G_loss: 3.97, reco_loss: 0.1941\n",
      "the 10-th batch at \n",
      "Epoch-18; D_loss_cat: 0.4681; D_loss_gauss: 1.6; G_loss: 3.643, reco_loss: 0.1981\n",
      "the 11-th batch at \n",
      "Epoch-18; D_loss_cat: 0.4799; D_loss_gauss: 0.8937; G_loss: 4.041, reco_loss: 0.1995\n",
      "Train accuracy: 8.003624666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4884; D_loss_gauss: 0.7223; G_loss: 4.942, reco_loss: 0.1986\n",
      "the 1-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4704; D_loss_gauss: 0.5033; G_loss: 7.766, reco_loss: 0.1858\n",
      "the 2-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4969; D_loss_gauss: 0.4618; G_loss: 11.05, reco_loss: 0.1858\n",
      "the 3-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4752; D_loss_gauss: 0.5373; G_loss: 14.98, reco_loss: 0.1828\n",
      "the 4-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4532; D_loss_gauss: 0.5652; G_loss: 17.59, reco_loss: 0.1822\n",
      "the 5-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4585; D_loss_gauss: 0.564; G_loss: 19.08, reco_loss: 0.1796\n",
      "the 6-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4535; D_loss_gauss: 0.5521; G_loss: 21.02, reco_loss: 0.1793\n",
      "the 7-th batch at \n",
      "Epoch-19; D_loss_cat: 0.467; D_loss_gauss: 0.5319; G_loss: 22.64, reco_loss: 0.1784\n",
      "the 8-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4451; D_loss_gauss: 0.4801; G_loss: 22.99, reco_loss: 0.1773\n",
      "the 9-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4364; D_loss_gauss: 0.4415; G_loss: 22.58, reco_loss: 0.1774\n",
      "the 10-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4477; D_loss_gauss: 0.4006; G_loss: 22.99, reco_loss: 0.1753\n",
      "the 11-th batch at \n",
      "Epoch-19; D_loss_cat: 0.4283; D_loss_gauss: 0.3883; G_loss: 23.86, reco_loss: 0.1754\n",
      "Train accuracy: 7.857519333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4268; D_loss_gauss: 0.3348; G_loss: 24.13, reco_loss: 0.183\n",
      "the 1-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4263; D_loss_gauss: 0.3017; G_loss: 23.52, reco_loss: 0.1744\n",
      "the 2-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4208; D_loss_gauss: 0.2523; G_loss: 23.12, reco_loss: 0.1735\n",
      "the 3-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4212; D_loss_gauss: 0.2205; G_loss: 23.49, reco_loss: 0.1723\n",
      "the 4-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4181; D_loss_gauss: 0.1848; G_loss: 23.16, reco_loss: 0.1732\n",
      "the 5-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4025; D_loss_gauss: 0.1497; G_loss: 22.62, reco_loss: 0.1716\n",
      "the 6-th batch at \n",
      "Epoch-20; D_loss_cat: 0.3979; D_loss_gauss: 0.1313; G_loss: 22.11, reco_loss: 0.1729\n",
      "the 7-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4103; D_loss_gauss: 0.1144; G_loss: 21.98, reco_loss: 0.1698\n",
      "the 8-th batch at \n",
      "Epoch-20; D_loss_cat: 0.3957; D_loss_gauss: 0.0996; G_loss: 21.8, reco_loss: 0.1709\n",
      "the 9-th batch at \n",
      "Epoch-20; D_loss_cat: 0.392; D_loss_gauss: 0.06523; G_loss: 21.35, reco_loss: 0.1703\n",
      "the 10-th batch at \n",
      "Epoch-20; D_loss_cat: 0.3942; D_loss_gauss: 0.06255; G_loss: 20.82, reco_loss: 0.1698\n",
      "the 11-th batch at \n",
      "Epoch-20; D_loss_cat: 0.4133; D_loss_gauss: 0.04833; G_loss: 20.38, reco_loss: 0.1699\n",
      "Train accuracy: 7.797348666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-21; D_loss_cat: 0.411; D_loss_gauss: 0.03267; G_loss: 19.91, reco_loss: 0.1771\n",
      "the 1-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4161; D_loss_gauss: 0.02645; G_loss: 17.75, reco_loss: 0.1831\n",
      "the 2-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4334; D_loss_gauss: 0.0259; G_loss: 14.51, reco_loss: 0.1874\n",
      "the 3-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4207; D_loss_gauss: 0.03431; G_loss: 10.3, reco_loss: 0.1849\n",
      "the 4-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4364; D_loss_gauss: 0.4989; G_loss: 6.026, reco_loss: 0.1836\n",
      "the 5-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4382; D_loss_gauss: 2.094; G_loss: 3.712, reco_loss: 0.1856\n",
      "the 6-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4339; D_loss_gauss: 3.921; G_loss: 3.197, reco_loss: 0.1839\n",
      "the 7-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4483; D_loss_gauss: 5.466; G_loss: 2.965, reco_loss: 0.1843\n",
      "the 8-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4463; D_loss_gauss: 5.764; G_loss: 2.659, reco_loss: 0.1845\n",
      "the 9-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4391; D_loss_gauss: 4.988; G_loss: 2.664, reco_loss: 0.1858\n",
      "the 10-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4575; D_loss_gauss: 3.825; G_loss: 2.706, reco_loss: 0.1847\n",
      "the 11-th batch at \n",
      "Epoch-21; D_loss_cat: 0.4577; D_loss_gauss: 2.686; G_loss: 2.762, reco_loss: 0.1832\n",
      "Train accuracy: 8.057127333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4731; D_loss_gauss: 1.977; G_loss: 2.783, reco_loss: 0.1857\n",
      "the 1-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4498; D_loss_gauss: 1.234; G_loss: 3.273, reco_loss: 0.1748\n",
      "the 2-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4279; D_loss_gauss: 0.8126; G_loss: 4.267, reco_loss: 0.1739\n",
      "the 3-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4615; D_loss_gauss: 0.5346; G_loss: 5.497, reco_loss: 0.1726\n",
      "the 4-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4594; D_loss_gauss: 0.4402; G_loss: 7.018, reco_loss: 0.17\n",
      "the 5-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4182; D_loss_gauss: 0.4014; G_loss: 9.238, reco_loss: 0.1696\n",
      "the 6-th batch at \n",
      "Epoch-22; D_loss_cat: 0.432; D_loss_gauss: 0.4236; G_loss: 10.93, reco_loss: 0.1691\n",
      "the 7-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4471; D_loss_gauss: 0.4409; G_loss: 11.96, reco_loss: 0.1695\n",
      "the 8-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4378; D_loss_gauss: 0.4651; G_loss: 13.06, reco_loss: 0.1665\n",
      "the 9-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4464; D_loss_gauss: 0.4851; G_loss: 14.5, reco_loss: 0.1684\n",
      "the 10-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4368; D_loss_gauss: 0.4939; G_loss: 15.49, reco_loss: 0.1658\n",
      "the 11-th batch at \n",
      "Epoch-22; D_loss_cat: 0.4472; D_loss_gauss: 0.4948; G_loss: 15.75, reco_loss: 0.1655\n",
      "Train accuracy: 7.903513000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-23; D_loss_cat: 0.423; D_loss_gauss: 0.4722; G_loss: 16.28, reco_loss: 0.175\n",
      "the 1-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4251; D_loss_gauss: 0.4617; G_loss: 16.83, reco_loss: 0.1659\n",
      "the 2-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4127; D_loss_gauss: 0.4471; G_loss: 17.21, reco_loss: 0.1644\n",
      "the 3-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4113; D_loss_gauss: 0.4134; G_loss: 16.93, reco_loss: 0.1643\n",
      "the 4-th batch at \n",
      "Epoch-23; D_loss_cat: 0.414; D_loss_gauss: 0.3802; G_loss: 16.79, reco_loss: 0.1642\n",
      "the 5-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4127; D_loss_gauss: 0.3367; G_loss: 16.85, reco_loss: 0.1641\n",
      "the 6-th batch at \n",
      "Epoch-23; D_loss_cat: 0.3927; D_loss_gauss: 0.2889; G_loss: 17.04, reco_loss: 0.1623\n",
      "the 7-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4072; D_loss_gauss: 0.247; G_loss: 16.8, reco_loss: 0.1627\n",
      "the 8-th batch at \n",
      "Epoch-23; D_loss_cat: 0.3958; D_loss_gauss: 0.1996; G_loss: 16.29, reco_loss: 0.1631\n",
      "the 9-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4123; D_loss_gauss: 0.1612; G_loss: 16.18, reco_loss: 0.1626\n",
      "the 10-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4125; D_loss_gauss: 0.1268; G_loss: 16.11, reco_loss: 0.1627\n",
      "the 11-th batch at \n",
      "Epoch-23; D_loss_cat: 0.4012; D_loss_gauss: 0.09374; G_loss: 15.84, reco_loss: 0.1622\n",
      "Train accuracy: 7.871074333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4251; D_loss_gauss: 0.06855; G_loss: 15.24, reco_loss: 0.1709\n",
      "the 1-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4268; D_loss_gauss: 0.05309; G_loss: 13.86, reco_loss: 0.1726\n",
      "the 2-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4268; D_loss_gauss: 0.04229; G_loss: 12.18, reco_loss: 0.1733\n",
      "the 3-th batch at \n",
      "Epoch-24; D_loss_cat: 0.42; D_loss_gauss: 0.07579; G_loss: 9.652, reco_loss: 0.1735\n",
      "the 4-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4309; D_loss_gauss: 0.2994; G_loss: 6.479, reco_loss: 0.173\n",
      "the 5-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4241; D_loss_gauss: 0.8818; G_loss: 4.155, reco_loss: 0.1751\n",
      "the 6-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4291; D_loss_gauss: 1.832; G_loss: 3.47, reco_loss: 0.1736\n",
      "the 7-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4528; D_loss_gauss: 2.654; G_loss: 3.174, reco_loss: 0.174\n",
      "the 8-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4383; D_loss_gauss: 3.149; G_loss: 2.8, reco_loss: 0.1779\n",
      "the 9-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4513; D_loss_gauss: 3.271; G_loss: 2.576, reco_loss: 0.1753\n",
      "the 10-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4524; D_loss_gauss: 3.017; G_loss: 2.821, reco_loss: 0.1743\n",
      "the 11-th batch at \n",
      "Epoch-24; D_loss_cat: 0.4598; D_loss_gauss: 2.347; G_loss: 3.102, reco_loss: 0.1762\n",
      "Train accuracy: 8.040841666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4584; D_loss_gauss: 1.475; G_loss: 3.464, reco_loss: 0.1752\n",
      "the 1-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4612; D_loss_gauss: 0.8329; G_loss: 3.801, reco_loss: 0.1643\n",
      "the 2-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4559; D_loss_gauss: 0.5986; G_loss: 4.371, reco_loss: 0.164\n",
      "the 3-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4606; D_loss_gauss: 0.5137; G_loss: 5.147, reco_loss: 0.1646\n",
      "the 4-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4349; D_loss_gauss: 0.5032; G_loss: 5.964, reco_loss: 0.1621\n",
      "the 5-th batch at \n",
      "Epoch-25; D_loss_cat: 0.463; D_loss_gauss: 0.5685; G_loss: 6.204, reco_loss: 0.1629\n",
      "the 6-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4461; D_loss_gauss: 0.6241; G_loss: 6.637, reco_loss: 0.1606\n",
      "the 7-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4575; D_loss_gauss: 0.7108; G_loss: 7.36, reco_loss: 0.1609\n",
      "the 8-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4528; D_loss_gauss: 0.7276; G_loss: 7.981, reco_loss: 0.1604\n",
      "the 9-th batch at \n",
      "Epoch-25; D_loss_cat: 0.449; D_loss_gauss: 0.6972; G_loss: 8.291, reco_loss: 0.16\n",
      "the 10-th batch at \n",
      "Epoch-25; D_loss_cat: 0.4447; D_loss_gauss: 0.6414; G_loss: 8.317, reco_loss: 0.1592\n",
      "the 11-th batch at \n",
      "Epoch-25; D_loss_cat: 0.436; D_loss_gauss: 0.6001; G_loss: 8.872, reco_loss: 0.1579\n",
      "Train accuracy: 8.01303 %\n",
      "the 0-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4406; D_loss_gauss: 0.5429; G_loss: 9.212, reco_loss: 0.1673\n",
      "the 1-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4364; D_loss_gauss: 0.4671; G_loss: 9.226, reco_loss: 0.1586\n",
      "the 2-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4371; D_loss_gauss: 0.4091; G_loss: 9.132, reco_loss: 0.1581\n",
      "the 3-th batch at \n",
      "Epoch-26; D_loss_cat: 0.436; D_loss_gauss: 0.3505; G_loss: 9.389, reco_loss: 0.1574\n",
      "the 4-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4276; D_loss_gauss: 0.3123; G_loss: 9.796, reco_loss: 0.1565\n",
      "the 5-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4365; D_loss_gauss: 0.2686; G_loss: 9.772, reco_loss: 0.1571\n",
      "the 6-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4421; D_loss_gauss: 0.2478; G_loss: 9.687, reco_loss: 0.156\n",
      "the 7-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4466; D_loss_gauss: 0.215; G_loss: 9.667, reco_loss: 0.1569\n",
      "the 8-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4212; D_loss_gauss: 0.1958; G_loss: 10.14, reco_loss: 0.1561\n",
      "the 9-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4477; D_loss_gauss: 0.1755; G_loss: 10.15, reco_loss: 0.1561\n",
      "the 10-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4336; D_loss_gauss: 0.1598; G_loss: 10.02, reco_loss: 0.1548\n",
      "the 11-th batch at \n",
      "Epoch-26; D_loss_cat: 0.4229; D_loss_gauss: 0.1455; G_loss: 10.16, reco_loss: 0.1534\n",
      "Train accuracy: 8.026386333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4333; D_loss_gauss: 0.1336; G_loss: 10.07, reco_loss: 0.1651\n",
      "the 1-th batch at \n",
      "Epoch-27; D_loss_cat: 0.417; D_loss_gauss: 0.1303; G_loss: 8.626, reco_loss: 0.1666\n",
      "the 2-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4489; D_loss_gauss: 0.1428; G_loss: 6.904, reco_loss: 0.1673\n",
      "the 3-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4305; D_loss_gauss: 0.1735; G_loss: 5.682, reco_loss: 0.1668\n",
      "the 4-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4171; D_loss_gauss: 0.2399; G_loss: 5.192, reco_loss: 0.1676\n",
      "the 5-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4117; D_loss_gauss: 0.3577; G_loss: 4.786, reco_loss: 0.1657\n",
      "the 6-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4366; D_loss_gauss: 0.5903; G_loss: 4.077, reco_loss: 0.1651\n",
      "the 7-th batch at \n",
      "Epoch-27; D_loss_cat: 0.436; D_loss_gauss: 0.996; G_loss: 3.379, reco_loss: 0.166\n",
      "the 8-th batch at \n",
      "Epoch-27; D_loss_cat: 0.439; D_loss_gauss: 1.582; G_loss: 3.229, reco_loss: 0.1672\n",
      "the 9-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4211; D_loss_gauss: 2.116; G_loss: 3.472, reco_loss: 0.1665\n",
      "the 10-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4561; D_loss_gauss: 2.468; G_loss: 3.358, reco_loss: 0.1659\n",
      "the 11-th batch at \n",
      "Epoch-27; D_loss_cat: 0.4523; D_loss_gauss: 2.478; G_loss: 3.23, reco_loss: 0.1668\n",
      "Train accuracy: 8.035814666666669 %\n",
      "the 0-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4529; D_loss_gauss: 2.205; G_loss: 3.958, reco_loss: 0.1656\n",
      "the 1-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4477; D_loss_gauss: 0.6837; G_loss: 7.321, reco_loss: 0.1571\n",
      "the 2-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4369; D_loss_gauss: 0.4048; G_loss: 10.26, reco_loss: 0.1572\n",
      "the 3-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4554; D_loss_gauss: 0.4886; G_loss: 12.37, reco_loss: 0.1561\n",
      "the 4-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4427; D_loss_gauss: 0.6389; G_loss: 14.58, reco_loss: 0.1545\n",
      "the 5-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4605; D_loss_gauss: 0.7682; G_loss: 16.76, reco_loss: 0.1542\n",
      "the 6-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4411; D_loss_gauss: 0.9221; G_loss: 17.95, reco_loss: 0.1531\n",
      "the 7-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4541; D_loss_gauss: 0.9839; G_loss: 18.07, reco_loss: 0.1529\n",
      "the 8-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4504; D_loss_gauss: 0.9816; G_loss: 17.55, reco_loss: 0.154\n",
      "the 9-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4544; D_loss_gauss: 0.9213; G_loss: 17.39, reco_loss: 0.1512\n",
      "the 10-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4527; D_loss_gauss: 0.8696; G_loss: 17.12, reco_loss: 0.1517\n",
      "the 11-th batch at \n",
      "Epoch-28; D_loss_cat: 0.4586; D_loss_gauss: 0.7127; G_loss: 16.38, reco_loss: 0.1517\n",
      "Train accuracy: 8.018704333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4425; D_loss_gauss: 0.6114; G_loss: 15.39, reco_loss: 0.1608\n",
      "the 1-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4487; D_loss_gauss: 0.5133; G_loss: 14.73, reco_loss: 0.1506\n",
      "the 2-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4472; D_loss_gauss: 0.4082; G_loss: 14.02, reco_loss: 0.1492\n",
      "the 3-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4285; D_loss_gauss: 0.3414; G_loss: 13.18, reco_loss: 0.1506\n",
      "the 4-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4352; D_loss_gauss: 0.2661; G_loss: 12.26, reco_loss: 0.1511\n",
      "the 5-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4448; D_loss_gauss: 0.2265; G_loss: 11.44, reco_loss: 0.1493\n",
      "the 6-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4408; D_loss_gauss: 0.1666; G_loss: 11.21, reco_loss: 0.1488\n",
      "the 7-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4392; D_loss_gauss: 0.1359; G_loss: 10.89, reco_loss: 0.1486\n",
      "the 8-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4309; D_loss_gauss: 0.1168; G_loss: 10.34, reco_loss: 0.148\n",
      "the 9-th batch at \n",
      "Epoch-29; D_loss_cat: 0.442; D_loss_gauss: 0.083; G_loss: 9.688, reco_loss: 0.1472\n",
      "the 10-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4409; D_loss_gauss: 0.07094; G_loss: 9.079, reco_loss: 0.1478\n",
      "the 11-th batch at \n",
      "Epoch-29; D_loss_cat: 0.4262; D_loss_gauss: 0.06112; G_loss: 8.891, reco_loss: 0.1467\n",
      "Train accuracy: 8.043057666666668 %\n",
      "the 0-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4516; D_loss_gauss: 0.05772; G_loss: 8.399, reco_loss: 0.1595\n",
      "the 1-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4524; D_loss_gauss: 0.1146; G_loss: 6.442, reco_loss: 0.162\n",
      "the 2-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4277; D_loss_gauss: 0.3204; G_loss: 5.122, reco_loss: 0.1615\n",
      "the 3-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4387; D_loss_gauss: 0.7196; G_loss: 4.356, reco_loss: 0.1592\n",
      "the 4-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4388; D_loss_gauss: 1.22; G_loss: 3.906, reco_loss: 0.1599\n",
      "the 5-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4619; D_loss_gauss: 1.642; G_loss: 3.498, reco_loss: 0.1605\n",
      "the 6-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4576; D_loss_gauss: 1.936; G_loss: 3.551, reco_loss: 0.1602\n",
      "the 7-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4469; D_loss_gauss: 1.805; G_loss: 4.582, reco_loss: 0.1611\n",
      "the 8-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4331; D_loss_gauss: 1.117; G_loss: 6.924, reco_loss: 0.1614\n",
      "the 9-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4407; D_loss_gauss: 0.448; G_loss: 10.22, reco_loss: 0.1607\n",
      "the 10-th batch at \n",
      "Epoch-30; D_loss_cat: 0.4446; D_loss_gauss: 0.1913; G_loss: 12.88, reco_loss: 0.162\n",
      "the 11-th batch at \n",
      "Epoch-30; D_loss_cat: 0.439; D_loss_gauss: 0.2425; G_loss: 13.93, reco_loss: 0.1633\n",
      "Train accuracy: 8.055275000000002 %\n",
      "the 0-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4381; D_loss_gauss: 0.3916; G_loss: 13.42, reco_loss: 0.1634\n",
      "the 1-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4368; D_loss_gauss: 0.5777; G_loss: 15.83, reco_loss: 0.1551\n",
      "the 2-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4624; D_loss_gauss: 0.6355; G_loss: 15.85, reco_loss: 0.1543\n",
      "the 3-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4359; D_loss_gauss: 0.6192; G_loss: 15.46, reco_loss: 0.1519\n",
      "the 4-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4416; D_loss_gauss: 0.5233; G_loss: 15.91, reco_loss: 0.1517\n",
      "the 5-th batch at \n",
      "Epoch-31; D_loss_cat: 0.445; D_loss_gauss: 0.4232; G_loss: 16.77, reco_loss: 0.1505\n",
      "the 6-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4502; D_loss_gauss: 0.3225; G_loss: 17.14, reco_loss: 0.1487\n",
      "the 7-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4353; D_loss_gauss: 0.2575; G_loss: 16.75, reco_loss: 0.149\n",
      "the 8-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4484; D_loss_gauss: 0.1911; G_loss: 15.88, reco_loss: 0.148\n",
      "the 9-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4303; D_loss_gauss: 0.1701; G_loss: 15.26, reco_loss: 0.1471\n",
      "the 10-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4383; D_loss_gauss: 0.1256; G_loss: 14.64, reco_loss: 0.1456\n",
      "the 11-th batch at \n",
      "Epoch-31; D_loss_cat: 0.4398; D_loss_gauss: 0.1049; G_loss: 14.4, reco_loss: 0.1467\n",
      "Train accuracy: 8.065758666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4418; D_loss_gauss: 0.1016; G_loss: 14.35, reco_loss: 0.1571\n",
      "the 1-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4336; D_loss_gauss: 0.08022; G_loss: 14.4, reco_loss: 0.146\n",
      "the 2-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4337; D_loss_gauss: 0.0651; G_loss: 13.82, reco_loss: 0.1443\n",
      "the 3-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4471; D_loss_gauss: 0.06363; G_loss: 13.37, reco_loss: 0.144\n",
      "the 4-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4307; D_loss_gauss: 0.05399; G_loss: 12.84, reco_loss: 0.1436\n",
      "the 5-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4364; D_loss_gauss: 0.05009; G_loss: 12.68, reco_loss: 0.1441\n",
      "the 6-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4174; D_loss_gauss: 0.04771; G_loss: 12.86, reco_loss: 0.1428\n",
      "the 7-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4316; D_loss_gauss: 0.04113; G_loss: 12.79, reco_loss: 0.1425\n",
      "the 8-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4249; D_loss_gauss: 0.04042; G_loss: 12.36, reco_loss: 0.1429\n",
      "the 9-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4313; D_loss_gauss: 0.03565; G_loss: 12.21, reco_loss: 0.1424\n",
      "the 10-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4482; D_loss_gauss: 0.03348; G_loss: 12.09, reco_loss: 0.1419\n",
      "the 11-th batch at \n",
      "Epoch-32; D_loss_cat: 0.4456; D_loss_gauss: 0.03292; G_loss: 12.01, reco_loss: 0.1411\n",
      "Train accuracy: 8.086293 %\n",
      "the 0-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4534; D_loss_gauss: 0.02761; G_loss: 11.38, reco_loss: 0.1546\n",
      "the 1-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4435; D_loss_gauss: 0.05645; G_loss: 7.889, reco_loss: 0.1615\n",
      "the 2-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4338; D_loss_gauss: 0.1257; G_loss: 6.295, reco_loss: 0.1649\n",
      "the 3-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4656; D_loss_gauss: 0.2643; G_loss: 5.129, reco_loss: 0.1603\n",
      "the 4-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4357; D_loss_gauss: 0.5473; G_loss: 4.428, reco_loss: 0.1569\n",
      "the 5-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4345; D_loss_gauss: 0.8525; G_loss: 4.096, reco_loss: 0.1612\n",
      "the 6-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4553; D_loss_gauss: 1.143; G_loss: 3.793, reco_loss: 0.1611\n",
      "the 7-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4451; D_loss_gauss: 1.409; G_loss: 3.606, reco_loss: 0.16\n",
      "the 8-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4332; D_loss_gauss: 1.476; G_loss: 3.797, reco_loss: 0.1602\n",
      "the 9-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4411; D_loss_gauss: 1.166; G_loss: 4.328, reco_loss: 0.164\n",
      "the 10-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4293; D_loss_gauss: 0.8499; G_loss: 5.118, reco_loss: 0.1622\n",
      "the 11-th batch at \n",
      "Epoch-33; D_loss_cat: 0.4432; D_loss_gauss: 0.6467; G_loss: 5.829, reco_loss: 0.1604\n",
      "Train accuracy: 7.9957889999999985 %\n",
      "the 0-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4464; D_loss_gauss: 0.5662; G_loss: 6.27, reco_loss: 0.163\n",
      "the 1-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4463; D_loss_gauss: 0.3343; G_loss: 9.432, reco_loss: 0.1543\n",
      "the 2-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4291; D_loss_gauss: 0.3897; G_loss: 11.69, reco_loss: 0.1539\n",
      "the 3-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4481; D_loss_gauss: 0.5075; G_loss: 13.0, reco_loss: 0.1525\n",
      "the 4-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4376; D_loss_gauss: 0.6213; G_loss: 13.95, reco_loss: 0.1499\n",
      "the 5-th batch at \n",
      "Epoch-34; D_loss_cat: 0.439; D_loss_gauss: 0.6127; G_loss: 15.18, reco_loss: 0.1489\n",
      "the 6-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4317; D_loss_gauss: 0.6469; G_loss: 16.47, reco_loss: 0.1486\n",
      "the 7-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4452; D_loss_gauss: 0.6418; G_loss: 17.66, reco_loss: 0.1453\n",
      "the 8-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4608; D_loss_gauss: 0.6037; G_loss: 18.36, reco_loss: 0.1438\n",
      "the 9-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4416; D_loss_gauss: 0.5584; G_loss: 18.62, reco_loss: 0.1439\n",
      "the 10-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4513; D_loss_gauss: 0.5195; G_loss: 18.31, reco_loss: 0.1437\n",
      "the 11-th batch at \n",
      "Epoch-34; D_loss_cat: 0.4414; D_loss_gauss: 0.4402; G_loss: 17.7, reco_loss: 0.1417\n",
      "Train accuracy: 8.029195333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-35; D_loss_cat: 0.454; D_loss_gauss: 0.3867; G_loss: 17.04, reco_loss: 0.1546\n",
      "the 1-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4393; D_loss_gauss: 0.3705; G_loss: 16.62, reco_loss: 0.141\n",
      "the 2-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4282; D_loss_gauss: 0.3065; G_loss: 16.38, reco_loss: 0.1416\n",
      "the 3-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4418; D_loss_gauss: 0.2581; G_loss: 16.04, reco_loss: 0.1414\n",
      "the 4-th batch at \n",
      "Epoch-35; D_loss_cat: 0.456; D_loss_gauss: 0.2306; G_loss: 15.57, reco_loss: 0.1393\n",
      "the 5-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4601; D_loss_gauss: 0.195; G_loss: 15.11, reco_loss: 0.1385\n",
      "the 6-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4321; D_loss_gauss: 0.1855; G_loss: 15.03, reco_loss: 0.1397\n",
      "the 7-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4435; D_loss_gauss: 0.1721; G_loss: 14.34, reco_loss: 0.1385\n",
      "the 8-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4326; D_loss_gauss: 0.1443; G_loss: 13.77, reco_loss: 0.1382\n",
      "the 9-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4253; D_loss_gauss: 0.1322; G_loss: 13.4, reco_loss: 0.1384\n",
      "the 10-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4227; D_loss_gauss: 0.1045; G_loss: 13.31, reco_loss: 0.1385\n",
      "the 11-th batch at \n",
      "Epoch-35; D_loss_cat: 0.4692; D_loss_gauss: 0.09026; G_loss: 12.94, reco_loss: 0.1371\n",
      "Train accuracy: 8.055077333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4409; D_loss_gauss: 0.07731; G_loss: 12.57, reco_loss: 0.1521\n",
      "the 1-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4488; D_loss_gauss: 0.07827; G_loss: 10.27, reco_loss: 0.1585\n",
      "the 2-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4268; D_loss_gauss: 0.08247; G_loss: 8.636, reco_loss: 0.1614\n",
      "the 3-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4338; D_loss_gauss: 0.1028; G_loss: 6.923, reco_loss: 0.1573\n",
      "the 4-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4359; D_loss_gauss: 0.214; G_loss: 5.555, reco_loss: 0.1536\n",
      "the 5-th batch at \n",
      "Epoch-36; D_loss_cat: 0.444; D_loss_gauss: 0.4228; G_loss: 4.566, reco_loss: 0.1559\n",
      "the 6-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4384; D_loss_gauss: 0.7471; G_loss: 4.302, reco_loss: 0.1557\n",
      "the 7-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4394; D_loss_gauss: 1.171; G_loss: 4.239, reco_loss: 0.1563\n",
      "the 8-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4376; D_loss_gauss: 1.531; G_loss: 4.482, reco_loss: 0.1565\n",
      "the 9-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4407; D_loss_gauss: 1.118; G_loss: 6.873, reco_loss: 0.1577\n",
      "the 10-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4459; D_loss_gauss: 0.4977; G_loss: 10.76, reco_loss: 0.1574\n",
      "the 11-th batch at \n",
      "Epoch-36; D_loss_cat: 0.4267; D_loss_gauss: 0.2035; G_loss: 14.25, reco_loss: 0.1589\n",
      "Train accuracy: 8.007188000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4504; D_loss_gauss: 0.2076; G_loss: 16.03, reco_loss: 0.1559\n",
      "the 1-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4315; D_loss_gauss: 0.3173; G_loss: 19.42, reco_loss: 0.1511\n",
      "the 2-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4273; D_loss_gauss: 0.531; G_loss: 21.09, reco_loss: 0.1523\n",
      "the 3-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4234; D_loss_gauss: 0.592; G_loss: 22.69, reco_loss: 0.1505\n",
      "the 4-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4417; D_loss_gauss: 0.6595; G_loss: 24.18, reco_loss: 0.1484\n",
      "the 5-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4366; D_loss_gauss: 0.5407; G_loss: 25.31, reco_loss: 0.1453\n",
      "the 6-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4218; D_loss_gauss: 0.4279; G_loss: 26.06, reco_loss: 0.1464\n",
      "the 7-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4353; D_loss_gauss: 0.3602; G_loss: 25.62, reco_loss: 0.144\n",
      "the 8-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4499; D_loss_gauss: 0.2495; G_loss: 24.36, reco_loss: 0.1424\n",
      "the 9-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4609; D_loss_gauss: 0.1659; G_loss: 23.49, reco_loss: 0.141\n",
      "the 10-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4394; D_loss_gauss: 0.1208; G_loss: 23.06, reco_loss: 0.1402\n",
      "the 11-th batch at \n",
      "Epoch-37; D_loss_cat: 0.4356; D_loss_gauss: 0.08843; G_loss: 22.24, reco_loss: 0.1408\n",
      "Train accuracy: 8.005091666666665 %\n",
      "the 0-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4468; D_loss_gauss: 0.06731; G_loss: 21.46, reco_loss: 0.1524\n",
      "the 1-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4291; D_loss_gauss: 0.0531; G_loss: 20.61, reco_loss: 0.1382\n",
      "the 2-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4373; D_loss_gauss: 0.04654; G_loss: 20.31, reco_loss: 0.1372\n",
      "the 3-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4331; D_loss_gauss: 0.04068; G_loss: 19.43, reco_loss: 0.1371\n",
      "the 4-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4373; D_loss_gauss: 0.02788; G_loss: 18.39, reco_loss: 0.1365\n",
      "the 5-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4459; D_loss_gauss: 0.02822; G_loss: 17.58, reco_loss: 0.1364\n",
      "the 6-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4578; D_loss_gauss: 0.02494; G_loss: 17.16, reco_loss: 0.136\n",
      "the 7-th batch at \n",
      "Epoch-38; D_loss_cat: 0.445; D_loss_gauss: 0.02179; G_loss: 16.59, reco_loss: 0.1366\n",
      "the 8-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4561; D_loss_gauss: 0.01753; G_loss: 16.08, reco_loss: 0.1356\n",
      "the 9-th batch at \n",
      "Epoch-38; D_loss_cat: 0.433; D_loss_gauss: 0.0165; G_loss: 16.01, reco_loss: 0.1346\n",
      "the 10-th batch at \n",
      "Epoch-38; D_loss_cat: 0.427; D_loss_gauss: 0.01652; G_loss: 16.22, reco_loss: 0.1335\n",
      "the 11-th batch at \n",
      "Epoch-38; D_loss_cat: 0.4513; D_loss_gauss: 0.0128; G_loss: 15.96, reco_loss: 0.1341\n",
      "Train accuracy: 8.058583666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4422; D_loss_gauss: 0.01466; G_loss: 15.18, reco_loss: 0.1493\n",
      "the 1-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4458; D_loss_gauss: 0.01698; G_loss: 12.52, reco_loss: 0.1612\n",
      "the 2-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4337; D_loss_gauss: 0.04699; G_loss: 9.238, reco_loss: 0.1547\n",
      "the 3-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4339; D_loss_gauss: 0.2559; G_loss: 5.899, reco_loss: 0.1531\n",
      "the 4-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4182; D_loss_gauss: 0.8833; G_loss: 4.031, reco_loss: 0.154\n",
      "the 5-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4079; D_loss_gauss: 1.45; G_loss: 3.681, reco_loss: 0.1551\n",
      "the 6-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4312; D_loss_gauss: 1.782; G_loss: 3.328, reco_loss: 0.1558\n",
      "the 7-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4316; D_loss_gauss: 2.02; G_loss: 2.839, reco_loss: 0.1533\n",
      "the 8-th batch at \n",
      "Epoch-39; D_loss_cat: 0.423; D_loss_gauss: 2.103; G_loss: 3.011, reco_loss: 0.1561\n",
      "the 9-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4376; D_loss_gauss: 1.989; G_loss: 3.313, reco_loss: 0.153\n",
      "the 10-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4396; D_loss_gauss: 1.624; G_loss: 3.528, reco_loss: 0.1541\n",
      "the 11-th batch at \n",
      "Epoch-39; D_loss_cat: 0.4319; D_loss_gauss: 1.123; G_loss: 4.239, reco_loss: 0.1534\n",
      "Train accuracy: 8.051894333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4349; D_loss_gauss: 0.7499; G_loss: 5.498, reco_loss: 0.1531\n",
      "the 1-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4552; D_loss_gauss: 0.2806; G_loss: 8.048, reco_loss: 0.1438\n",
      "the 2-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4581; D_loss_gauss: 0.2503; G_loss: 10.18, reco_loss: 0.1432\n",
      "the 3-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4519; D_loss_gauss: 0.2898; G_loss: 12.18, reco_loss: 0.1437\n",
      "the 4-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4539; D_loss_gauss: 0.4057; G_loss: 14.0, reco_loss: 0.1394\n",
      "the 5-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4399; D_loss_gauss: 0.4269; G_loss: 15.18, reco_loss: 0.1397\n",
      "the 6-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4442; D_loss_gauss: 0.4257; G_loss: 16.14, reco_loss: 0.1391\n",
      "the 7-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4487; D_loss_gauss: 0.4296; G_loss: 17.4, reco_loss: 0.1373\n",
      "the 8-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4374; D_loss_gauss: 0.3675; G_loss: 18.32, reco_loss: 0.1377\n",
      "the 9-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4627; D_loss_gauss: 0.3153; G_loss: 18.53, reco_loss: 0.1344\n",
      "the 10-th batch at \n",
      "Epoch-40; D_loss_cat: 0.4369; D_loss_gauss: 0.2661; G_loss: 18.46, reco_loss: 0.136\n",
      "the 11-th batch at \n",
      "Epoch-40; D_loss_cat: 0.462; D_loss_gauss: 0.2026; G_loss: 18.66, reco_loss: 0.1354\n",
      "Train accuracy: 8.042865333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4416; D_loss_gauss: 0.178; G_loss: 18.51, reco_loss: 0.1476\n",
      "the 1-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4627; D_loss_gauss: 0.1642; G_loss: 17.95, reco_loss: 0.1339\n",
      "the 2-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4413; D_loss_gauss: 0.1416; G_loss: 17.54, reco_loss: 0.1337\n",
      "the 3-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4258; D_loss_gauss: 0.1227; G_loss: 17.75, reco_loss: 0.1336\n",
      "the 4-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4553; D_loss_gauss: 0.1003; G_loss: 17.43, reco_loss: 0.1315\n",
      "the 5-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4341; D_loss_gauss: 0.1028; G_loss: 16.91, reco_loss: 0.1327\n",
      "the 6-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4517; D_loss_gauss: 0.09853; G_loss: 16.86, reco_loss: 0.132\n",
      "the 7-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4414; D_loss_gauss: 0.08559; G_loss: 16.75, reco_loss: 0.1329\n",
      "the 8-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4273; D_loss_gauss: 0.07912; G_loss: 16.58, reco_loss: 0.1295\n",
      "the 9-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4379; D_loss_gauss: 0.07124; G_loss: 16.27, reco_loss: 0.1302\n",
      "the 10-th batch at \n",
      "Epoch-41; D_loss_cat: 0.432; D_loss_gauss: 0.06556; G_loss: 16.16, reco_loss: 0.1312\n",
      "the 11-th batch at \n",
      "Epoch-41; D_loss_cat: 0.4657; D_loss_gauss: 0.06729; G_loss: 15.96, reco_loss: 0.13\n",
      "Train accuracy: 8.070430333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4513; D_loss_gauss: 0.06208; G_loss: 15.47, reco_loss: 0.1452\n",
      "the 1-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4519; D_loss_gauss: 0.05882; G_loss: 13.84, reco_loss: 0.1477\n",
      "the 2-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4305; D_loss_gauss: 0.05826; G_loss: 11.91, reco_loss: 0.1479\n",
      "the 3-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4526; D_loss_gauss: 0.06347; G_loss: 9.641, reco_loss: 0.1462\n",
      "the 4-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4405; D_loss_gauss: 0.1007; G_loss: 7.76, reco_loss: 0.1482\n",
      "the 5-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4506; D_loss_gauss: 0.2348; G_loss: 6.257, reco_loss: 0.1474\n",
      "the 6-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4428; D_loss_gauss: 0.4945; G_loss: 5.108, reco_loss: 0.148\n",
      "the 7-th batch at \n",
      "Epoch-42; D_loss_cat: 0.434; D_loss_gauss: 0.7799; G_loss: 4.333, reco_loss: 0.1483\n",
      "the 8-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4434; D_loss_gauss: 1.191; G_loss: 3.79, reco_loss: 0.1499\n",
      "the 9-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4441; D_loss_gauss: 1.627; G_loss: 3.495, reco_loss: 0.1503\n",
      "the 10-th batch at \n",
      "Epoch-42; D_loss_cat: 0.4343; D_loss_gauss: 1.942; G_loss: 3.408, reco_loss: 0.1499\n",
      "the 11-th batch at \n",
      "Epoch-42; D_loss_cat: 0.457; D_loss_gauss: 2.047; G_loss: 3.137, reco_loss: 0.1507\n",
      "Train accuracy: 7.949314333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4431; D_loss_gauss: 2.078; G_loss: 3.102, reco_loss: 0.1509\n",
      "the 1-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4572; D_loss_gauss: 0.7635; G_loss: 4.95, reco_loss: 0.1386\n",
      "the 2-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4568; D_loss_gauss: 0.2688; G_loss: 6.555, reco_loss: 0.139\n",
      "the 3-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4236; D_loss_gauss: 0.1638; G_loss: 8.242, reco_loss: 0.1374\n",
      "the 4-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4419; D_loss_gauss: 0.159; G_loss: 9.413, reco_loss: 0.1379\n",
      "the 5-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4381; D_loss_gauss: 0.1734; G_loss: 10.39, reco_loss: 0.1364\n",
      "the 6-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4491; D_loss_gauss: 0.1961; G_loss: 11.75, reco_loss: 0.1339\n",
      "the 7-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4512; D_loss_gauss: 0.2139; G_loss: 12.92, reco_loss: 0.1342\n",
      "the 8-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4531; D_loss_gauss: 0.2549; G_loss: 13.8, reco_loss: 0.1323\n",
      "the 9-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4476; D_loss_gauss: 0.243; G_loss: 14.4, reco_loss: 0.1318\n",
      "the 10-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4443; D_loss_gauss: 0.2643; G_loss: 14.89, reco_loss: 0.1313\n",
      "the 11-th batch at \n",
      "Epoch-43; D_loss_cat: 0.4396; D_loss_gauss: 0.2727; G_loss: 15.48, reco_loss: 0.1303\n",
      "Train accuracy: 8.063256333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4349; D_loss_gauss: 0.2647; G_loss: 15.5, reco_loss: 0.1455\n",
      "the 1-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4283; D_loss_gauss: 0.2781; G_loss: 15.52, reco_loss: 0.129\n",
      "the 2-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4534; D_loss_gauss: 0.2562; G_loss: 15.55, reco_loss: 0.1288\n",
      "the 3-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4363; D_loss_gauss: 0.2404; G_loss: 15.71, reco_loss: 0.1297\n",
      "the 4-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4374; D_loss_gauss: 0.2309; G_loss: 15.66, reco_loss: 0.1278\n",
      "the 5-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4278; D_loss_gauss: 0.2167; G_loss: 15.4, reco_loss: 0.1284\n",
      "the 6-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4535; D_loss_gauss: 0.1919; G_loss: 15.15, reco_loss: 0.1281\n",
      "the 7-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4369; D_loss_gauss: 0.1878; G_loss: 15.31, reco_loss: 0.1282\n",
      "the 8-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4409; D_loss_gauss: 0.1712; G_loss: 15.2, reco_loss: 0.1275\n",
      "the 9-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4399; D_loss_gauss: 0.1525; G_loss: 14.97, reco_loss: 0.1269\n",
      "the 10-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4552; D_loss_gauss: 0.1496; G_loss: 14.94, reco_loss: 0.1267\n",
      "the 11-th batch at \n",
      "Epoch-44; D_loss_cat: 0.4167; D_loss_gauss: 0.1325; G_loss: 15.09, reco_loss: 0.1283\n",
      "Train accuracy: 8.097238 %\n",
      "the 0-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4262; D_loss_gauss: 0.1241; G_loss: 14.74, reco_loss: 0.1429\n",
      "the 1-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4426; D_loss_gauss: 0.1135; G_loss: 13.11, reco_loss: 0.1475\n",
      "the 2-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4247; D_loss_gauss: 0.1165; G_loss: 12.19, reco_loss: 0.1467\n",
      "the 3-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4254; D_loss_gauss: 0.1013; G_loss: 10.78, reco_loss: 0.145\n",
      "the 4-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4426; D_loss_gauss: 0.1014; G_loss: 8.448, reco_loss: 0.1443\n",
      "the 5-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4305; D_loss_gauss: 0.1343; G_loss: 6.648, reco_loss: 0.1459\n",
      "the 6-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4316; D_loss_gauss: 0.2802; G_loss: 5.477, reco_loss: 0.1458\n",
      "the 7-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4252; D_loss_gauss: 0.7564; G_loss: 4.158, reco_loss: 0.1462\n",
      "the 8-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4486; D_loss_gauss: 1.794; G_loss: 2.691, reco_loss: 0.1457\n",
      "the 9-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4389; D_loss_gauss: 2.76; G_loss: 2.401, reco_loss: 0.1476\n",
      "the 10-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4542; D_loss_gauss: 3.289; G_loss: 2.657, reco_loss: 0.147\n",
      "the 11-th batch at \n",
      "Epoch-45; D_loss_cat: 0.4632; D_loss_gauss: 3.446; G_loss: 2.501, reco_loss: 0.1485\n",
      "Train accuracy: 8.032839333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4433; D_loss_gauss: 3.258; G_loss: 2.322, reco_loss: 0.1472\n",
      "the 1-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4467; D_loss_gauss: 1.712; G_loss: 3.013, reco_loss: 0.1366\n",
      "the 2-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4552; D_loss_gauss: 0.8637; G_loss: 4.297, reco_loss: 0.1358\n",
      "the 3-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4438; D_loss_gauss: 0.4881; G_loss: 5.879, reco_loss: 0.1347\n",
      "the 4-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4538; D_loss_gauss: 0.3346; G_loss: 7.664, reco_loss: 0.1342\n",
      "the 5-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4412; D_loss_gauss: 0.325; G_loss: 9.566, reco_loss: 0.1325\n",
      "the 6-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4549; D_loss_gauss: 0.3453; G_loss: 11.0, reco_loss: 0.1321\n",
      "the 7-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4501; D_loss_gauss: 0.3897; G_loss: 12.09, reco_loss: 0.1298\n",
      "the 8-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4726; D_loss_gauss: 0.4215; G_loss: 12.84, reco_loss: 0.1294\n",
      "the 9-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4664; D_loss_gauss: 0.4206; G_loss: 13.92, reco_loss: 0.1278\n",
      "the 10-th batch at \n",
      "Epoch-46; D_loss_cat: 0.4586; D_loss_gauss: 0.4251; G_loss: 14.43, reco_loss: 0.1286\n",
      "the 11-th batch at \n",
      "Epoch-46; D_loss_cat: 0.457; D_loss_gauss: 0.4064; G_loss: 14.85, reco_loss: 0.1274\n",
      "Train accuracy: 8.056354666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4405; D_loss_gauss: 0.3891; G_loss: 15.42, reco_loss: 0.1433\n",
      "the 1-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4347; D_loss_gauss: 0.3829; G_loss: 15.7, reco_loss: 0.1277\n",
      "the 2-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4574; D_loss_gauss: 0.353; G_loss: 15.21, reco_loss: 0.1268\n",
      "the 3-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4449; D_loss_gauss: 0.3454; G_loss: 15.0, reco_loss: 0.1266\n",
      "the 4-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4432; D_loss_gauss: 0.3242; G_loss: 15.15, reco_loss: 0.1258\n",
      "the 5-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4522; D_loss_gauss: 0.3114; G_loss: 14.95, reco_loss: 0.1257\n",
      "the 6-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4462; D_loss_gauss: 0.2925; G_loss: 14.66, reco_loss: 0.1243\n",
      "the 7-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4429; D_loss_gauss: 0.2688; G_loss: 14.98, reco_loss: 0.1254\n",
      "the 8-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4491; D_loss_gauss: 0.251; G_loss: 15.03, reco_loss: 0.1238\n",
      "the 9-th batch at \n",
      "Epoch-47; D_loss_cat: 0.421; D_loss_gauss: 0.2446; G_loss: 15.0, reco_loss: 0.1244\n",
      "the 10-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4505; D_loss_gauss: 0.2238; G_loss: 14.87, reco_loss: 0.1254\n",
      "the 11-th batch at \n",
      "Epoch-47; D_loss_cat: 0.4563; D_loss_gauss: 0.208; G_loss: 14.82, reco_loss: 0.1235\n",
      "Train accuracy: 8.076701000000002 %\n",
      "the 0-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4473; D_loss_gauss: 0.2017; G_loss: 14.41, reco_loss: 0.1403\n",
      "the 1-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4611; D_loss_gauss: 0.1856; G_loss: 12.98, reco_loss: 0.1414\n",
      "the 2-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4341; D_loss_gauss: 0.1717; G_loss: 11.65, reco_loss: 0.1406\n",
      "the 3-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4317; D_loss_gauss: 0.1699; G_loss: 10.15, reco_loss: 0.1406\n",
      "the 4-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4233; D_loss_gauss: 0.1604; G_loss: 8.528, reco_loss: 0.1418\n",
      "the 5-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4175; D_loss_gauss: 0.1592; G_loss: 7.572, reco_loss: 0.1413\n",
      "the 6-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4183; D_loss_gauss: 0.1839; G_loss: 6.687, reco_loss: 0.1423\n",
      "the 7-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4475; D_loss_gauss: 0.2734; G_loss: 5.179, reco_loss: 0.1436\n",
      "the 8-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4341; D_loss_gauss: 0.5034; G_loss: 4.037, reco_loss: 0.1425\n",
      "the 9-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4374; D_loss_gauss: 0.8479; G_loss: 3.632, reco_loss: 0.144\n",
      "the 10-th batch at \n",
      "Epoch-48; D_loss_cat: 0.43; D_loss_gauss: 1.219; G_loss: 3.208, reco_loss: 0.1445\n",
      "the 11-th batch at \n",
      "Epoch-48; D_loss_cat: 0.4617; D_loss_gauss: 1.588; G_loss: 2.536, reco_loss: 0.1455\n",
      "Train accuracy: 8.035108999999999 %\n",
      "the 0-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4726; D_loss_gauss: 1.824; G_loss: 2.704, reco_loss: 0.145\n",
      "the 1-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4387; D_loss_gauss: 1.073; G_loss: 3.888, reco_loss: 0.1342\n",
      "the 2-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4435; D_loss_gauss: 0.65; G_loss: 4.61, reco_loss: 0.1331\n",
      "the 3-th batch at \n",
      "Epoch-49; D_loss_cat: 0.443; D_loss_gauss: 0.4061; G_loss: 5.495, reco_loss: 0.1321\n",
      "the 4-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4379; D_loss_gauss: 0.2526; G_loss: 7.184, reco_loss: 0.1319\n",
      "the 5-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4368; D_loss_gauss: 0.2099; G_loss: 8.663, reco_loss: 0.1301\n",
      "the 6-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4488; D_loss_gauss: 0.1893; G_loss: 9.472, reco_loss: 0.1298\n",
      "the 7-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4613; D_loss_gauss: 0.1877; G_loss: 10.56, reco_loss: 0.1278\n",
      "the 8-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4448; D_loss_gauss: 0.1865; G_loss: 12.21, reco_loss: 0.1272\n",
      "the 9-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4593; D_loss_gauss: 0.2126; G_loss: 13.06, reco_loss: 0.1266\n",
      "the 10-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4425; D_loss_gauss: 0.2106; G_loss: 13.69, reco_loss: 0.1256\n",
      "the 11-th batch at \n",
      "Epoch-49; D_loss_cat: 0.4599; D_loss_gauss: 0.1971; G_loss: 14.33, reco_loss: 0.1249\n",
      "Train accuracy: 8.039664000000002 %\n",
      "the 0-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4547; D_loss_gauss: 0.208; G_loss: 14.76, reco_loss: 0.1407\n",
      "the 1-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4264; D_loss_gauss: 0.2003; G_loss: 15.15, reco_loss: 0.1247\n",
      "the 2-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4425; D_loss_gauss: 0.1923; G_loss: 15.04, reco_loss: 0.1243\n",
      "the 3-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4414; D_loss_gauss: 0.1948; G_loss: 15.14, reco_loss: 0.1241\n",
      "the 4-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4555; D_loss_gauss: 0.1809; G_loss: 15.04, reco_loss: 0.1239\n",
      "the 5-th batch at \n",
      "Epoch-50; D_loss_cat: 0.457; D_loss_gauss: 0.1692; G_loss: 15.1, reco_loss: 0.1224\n",
      "the 6-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4292; D_loss_gauss: 0.1596; G_loss: 15.1, reco_loss: 0.123\n",
      "the 7-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4591; D_loss_gauss: 0.161; G_loss: 14.74, reco_loss: 0.1222\n",
      "the 8-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4295; D_loss_gauss: 0.13; G_loss: 14.82, reco_loss: 0.1217\n",
      "the 9-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4373; D_loss_gauss: 0.1393; G_loss: 14.98, reco_loss: 0.1223\n",
      "the 10-th batch at \n",
      "Epoch-50; D_loss_cat: 0.4651; D_loss_gauss: 0.1277; G_loss: 14.47, reco_loss: 0.122\n",
      "the 11-th batch at \n",
      "Epoch-50; D_loss_cat: 0.454; D_loss_gauss: 0.1102; G_loss: 14.27, reco_loss: 0.1211\n",
      "Train accuracy: 8.073669333333331 %\n",
      "the 0-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4366; D_loss_gauss: 0.1008; G_loss: 14.41, reco_loss: 0.1378\n",
      "the 1-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4454; D_loss_gauss: 0.09259; G_loss: 13.22, reco_loss: 0.144\n",
      "the 2-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4243; D_loss_gauss: 0.09338; G_loss: 11.56, reco_loss: 0.1415\n",
      "the 3-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4273; D_loss_gauss: 0.08776; G_loss: 10.42, reco_loss: 0.1414\n",
      "the 4-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4276; D_loss_gauss: 0.09611; G_loss: 8.834, reco_loss: 0.1412\n",
      "the 5-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4533; D_loss_gauss: 0.1214; G_loss: 6.91, reco_loss: 0.1416\n",
      "the 6-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4542; D_loss_gauss: 0.2255; G_loss: 5.361, reco_loss: 0.1414\n",
      "the 7-th batch at \n",
      "Epoch-51; D_loss_cat: 0.448; D_loss_gauss: 0.5551; G_loss: 4.392, reco_loss: 0.1424\n",
      "the 8-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4454; D_loss_gauss: 1.139; G_loss: 3.375, reco_loss: 0.1421\n",
      "the 9-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4599; D_loss_gauss: 1.781; G_loss: 2.607, reco_loss: 0.1434\n",
      "the 10-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4582; D_loss_gauss: 2.322; G_loss: 2.85, reco_loss: 0.1438\n",
      "the 11-th batch at \n",
      "Epoch-51; D_loss_cat: 0.4613; D_loss_gauss: 2.628; G_loss: 2.826, reco_loss: 0.1448\n",
      "Train accuracy: 8.032794666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4736; D_loss_gauss: 2.621; G_loss: 2.396, reco_loss: 0.1457\n",
      "the 1-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4562; D_loss_gauss: 1.151; G_loss: 3.894, reco_loss: 0.1346\n",
      "the 2-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4498; D_loss_gauss: 0.4358; G_loss: 6.169, reco_loss: 0.1333\n",
      "the 3-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4517; D_loss_gauss: 0.2139; G_loss: 7.789, reco_loss: 0.134\n",
      "the 4-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4433; D_loss_gauss: 0.1847; G_loss: 9.709, reco_loss: 0.1325\n",
      "the 5-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4504; D_loss_gauss: 0.1963; G_loss: 11.84, reco_loss: 0.1308\n",
      "the 6-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4256; D_loss_gauss: 0.2128; G_loss: 13.3, reco_loss: 0.1304\n",
      "the 7-th batch at \n",
      "Epoch-52; D_loss_cat: 0.464; D_loss_gauss: 0.2395; G_loss: 14.13, reco_loss: 0.126\n",
      "the 8-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4594; D_loss_gauss: 0.2503; G_loss: 15.34, reco_loss: 0.1269\n",
      "the 9-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4418; D_loss_gauss: 0.2596; G_loss: 16.79, reco_loss: 0.1274\n",
      "the 10-th batch at \n",
      "Epoch-52; D_loss_cat: 0.473; D_loss_gauss: 0.254; G_loss: 16.98, reco_loss: 0.1253\n",
      "the 11-th batch at \n",
      "Epoch-52; D_loss_cat: 0.4515; D_loss_gauss: 0.2549; G_loss: 17.07, reco_loss: 0.1243\n",
      "Train accuracy: 8.043208000000002 %\n",
      "the 0-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4651; D_loss_gauss: 0.2586; G_loss: 17.6, reco_loss: 0.1395\n",
      "the 1-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4392; D_loss_gauss: 0.245; G_loss: 17.84, reco_loss: 0.123\n",
      "the 2-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4356; D_loss_gauss: 0.2492; G_loss: 17.58, reco_loss: 0.1225\n",
      "the 3-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4367; D_loss_gauss: 0.2426; G_loss: 17.33, reco_loss: 0.1224\n",
      "the 4-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4488; D_loss_gauss: 0.2121; G_loss: 17.17, reco_loss: 0.1223\n",
      "the 5-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4537; D_loss_gauss: 0.2099; G_loss: 16.66, reco_loss: 0.1217\n",
      "the 6-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4504; D_loss_gauss: 0.1948; G_loss: 16.28, reco_loss: 0.1219\n",
      "the 7-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4354; D_loss_gauss: 0.1824; G_loss: 16.29, reco_loss: 0.1216\n",
      "the 8-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4423; D_loss_gauss: 0.1613; G_loss: 16.16, reco_loss: 0.1208\n",
      "the 9-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4289; D_loss_gauss: 0.1576; G_loss: 16.11, reco_loss: 0.1207\n",
      "the 10-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4368; D_loss_gauss: 0.1478; G_loss: 16.0, reco_loss: 0.1207\n",
      "the 11-th batch at \n",
      "Epoch-53; D_loss_cat: 0.4543; D_loss_gauss: 0.1384; G_loss: 15.82, reco_loss: 0.1196\n",
      "Train accuracy: 8.078451000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4504; D_loss_gauss: 0.1317; G_loss: 15.32, reco_loss: 0.1357\n",
      "the 1-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4236; D_loss_gauss: 0.1216; G_loss: 14.89, reco_loss: 0.1413\n",
      "the 2-th batch at \n",
      "Epoch-54; D_loss_cat: 0.43; D_loss_gauss: 0.1156; G_loss: 13.25, reco_loss: 0.1387\n",
      "the 3-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4139; D_loss_gauss: 0.1095; G_loss: 11.57, reco_loss: 0.1389\n",
      "the 4-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4336; D_loss_gauss: 0.1041; G_loss: 10.01, reco_loss: 0.1377\n",
      "the 5-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4357; D_loss_gauss: 0.105; G_loss: 8.705, reco_loss: 0.1398\n",
      "the 6-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4262; D_loss_gauss: 0.1077; G_loss: 7.507, reco_loss: 0.141\n",
      "the 7-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4222; D_loss_gauss: 0.1244; G_loss: 6.858, reco_loss: 0.1407\n",
      "the 8-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4264; D_loss_gauss: 0.1682; G_loss: 5.905, reco_loss: 0.1407\n",
      "the 9-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4415; D_loss_gauss: 0.2829; G_loss: 4.619, reco_loss: 0.14\n",
      "the 10-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4374; D_loss_gauss: 0.5035; G_loss: 4.105, reco_loss: 0.1415\n",
      "the 11-th batch at \n",
      "Epoch-54; D_loss_cat: 0.4332; D_loss_gauss: 0.8245; G_loss: 3.719, reco_loss: 0.1416\n",
      "Train accuracy: 8.008068000000002 %\n",
      "the 0-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4488; D_loss_gauss: 1.209; G_loss: 3.026, reco_loss: 0.1425\n",
      "the 1-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4439; D_loss_gauss: 0.8154; G_loss: 3.608, reco_loss: 0.1295\n",
      "the 2-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4625; D_loss_gauss: 0.5256; G_loss: 4.733, reco_loss: 0.1265\n",
      "the 3-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4491; D_loss_gauss: 0.2833; G_loss: 5.958, reco_loss: 0.1288\n",
      "the 4-th batch at \n",
      "Epoch-55; D_loss_cat: 0.435; D_loss_gauss: 0.1646; G_loss: 7.094, reco_loss: 0.1256\n",
      "the 5-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4457; D_loss_gauss: 0.1253; G_loss: 8.196, reco_loss: 0.1251\n",
      "the 6-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4411; D_loss_gauss: 0.112; G_loss: 9.227, reco_loss: 0.125\n",
      "the 7-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4439; D_loss_gauss: 0.09813; G_loss: 10.29, reco_loss: 0.1235\n",
      "the 8-th batch at \n",
      "Epoch-55; D_loss_cat: 0.43; D_loss_gauss: 0.1029; G_loss: 11.22, reco_loss: 0.1239\n",
      "the 9-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4557; D_loss_gauss: 0.1014; G_loss: 12.01, reco_loss: 0.1217\n",
      "the 10-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4457; D_loss_gauss: 0.1019; G_loss: 13.12, reco_loss: 0.1222\n",
      "the 11-th batch at \n",
      "Epoch-55; D_loss_cat: 0.4341; D_loss_gauss: 0.1086; G_loss: 13.8, reco_loss: 0.1213\n",
      "Train accuracy: 8.076951333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4364; D_loss_gauss: 0.1066; G_loss: 14.0, reco_loss: 0.1365\n",
      "the 1-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4397; D_loss_gauss: 0.1025; G_loss: 14.47, reco_loss: 0.1193\n",
      "the 2-th batch at \n",
      "Epoch-56; D_loss_cat: 0.413; D_loss_gauss: 0.1131; G_loss: 15.32, reco_loss: 0.1219\n",
      "the 3-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4209; D_loss_gauss: 0.1066; G_loss: 15.61, reco_loss: 0.1196\n",
      "the 4-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4222; D_loss_gauss: 0.1059; G_loss: 15.52, reco_loss: 0.1192\n",
      "the 5-th batch at \n",
      "Epoch-56; D_loss_cat: 0.411; D_loss_gauss: 0.1071; G_loss: 15.99, reco_loss: 0.1187\n",
      "the 6-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4265; D_loss_gauss: 0.09106; G_loss: 16.17, reco_loss: 0.1191\n",
      "the 7-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4377; D_loss_gauss: 0.08692; G_loss: 15.84, reco_loss: 0.1191\n",
      "the 8-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4289; D_loss_gauss: 0.08898; G_loss: 16.07, reco_loss: 0.1188\n",
      "the 9-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4139; D_loss_gauss: 0.07939; G_loss: 16.42, reco_loss: 0.1177\n",
      "the 10-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4246; D_loss_gauss: 0.07822; G_loss: 16.22, reco_loss: 0.1178\n",
      "the 11-th batch at \n",
      "Epoch-56; D_loss_cat: 0.4326; D_loss_gauss: 0.07422; G_loss: 15.96, reco_loss: 0.1173\n",
      "Train accuracy: 8.110252 %\n",
      "the 0-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4264; D_loss_gauss: 0.06636; G_loss: 16.01, reco_loss: 0.1344\n",
      "the 1-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4089; D_loss_gauss: 0.06394; G_loss: 14.23, reco_loss: 0.1386\n",
      "the 2-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4264; D_loss_gauss: 0.06289; G_loss: 11.42, reco_loss: 0.1382\n",
      "the 3-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4339; D_loss_gauss: 0.06452; G_loss: 9.642, reco_loss: 0.1378\n",
      "the 4-th batch at \n",
      "Epoch-57; D_loss_cat: 0.438; D_loss_gauss: 0.09881; G_loss: 7.891, reco_loss: 0.1389\n",
      "the 5-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4354; D_loss_gauss: 0.1819; G_loss: 5.984, reco_loss: 0.1401\n",
      "the 6-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4355; D_loss_gauss: 0.3383; G_loss: 4.643, reco_loss: 0.1414\n",
      "the 7-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4464; D_loss_gauss: 0.6727; G_loss: 4.084, reco_loss: 0.1415\n",
      "the 8-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4572; D_loss_gauss: 1.129; G_loss: 3.442, reco_loss: 0.1415\n",
      "the 9-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4524; D_loss_gauss: 1.411; G_loss: 3.151, reco_loss: 0.1414\n",
      "the 10-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4477; D_loss_gauss: 1.45; G_loss: 3.848, reco_loss: 0.1414\n",
      "the 11-th batch at \n",
      "Epoch-57; D_loss_cat: 0.4425; D_loss_gauss: 1.325; G_loss: 4.74, reco_loss: 0.1428\n",
      "Train accuracy: 7.990229000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4852; D_loss_gauss: 0.8181; G_loss: 6.699, reco_loss: 0.1432\n",
      "the 1-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4524; D_loss_gauss: 0.156; G_loss: 12.42, reco_loss: 0.1303\n",
      "the 2-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4477; D_loss_gauss: 0.1801; G_loss: 16.56, reco_loss: 0.1292\n",
      "the 3-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4427; D_loss_gauss: 0.2685; G_loss: 19.45, reco_loss: 0.1301\n",
      "the 4-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4538; D_loss_gauss: 0.3401; G_loss: 21.92, reco_loss: 0.1285\n",
      "the 5-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4467; D_loss_gauss: 0.3786; G_loss: 23.81, reco_loss: 0.1278\n",
      "the 6-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4587; D_loss_gauss: 0.4086; G_loss: 25.01, reco_loss: 0.1275\n",
      "the 7-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4386; D_loss_gauss: 0.3666; G_loss: 26.17, reco_loss: 0.1255\n",
      "the 8-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4495; D_loss_gauss: 0.3386; G_loss: 26.71, reco_loss: 0.1249\n",
      "the 9-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4602; D_loss_gauss: 0.2761; G_loss: 26.91, reco_loss: 0.1235\n",
      "the 10-th batch at \n",
      "Epoch-58; D_loss_cat: 0.445; D_loss_gauss: 0.255; G_loss: 27.43, reco_loss: 0.1224\n",
      "the 11-th batch at \n",
      "Epoch-58; D_loss_cat: 0.4461; D_loss_gauss: 0.1764; G_loss: 27.2, reco_loss: 0.1216\n",
      "Train accuracy: 8.044247333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4755; D_loss_gauss: 0.1608; G_loss: 26.49, reco_loss: 0.1352\n",
      "the 1-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4535; D_loss_gauss: 0.128; G_loss: 26.26, reco_loss: 0.1199\n",
      "the 2-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4626; D_loss_gauss: 0.1073; G_loss: 25.67, reco_loss: 0.1181\n",
      "the 3-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4349; D_loss_gauss: 0.08385; G_loss: 24.65, reco_loss: 0.1193\n",
      "the 4-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4552; D_loss_gauss: 0.06609; G_loss: 24.03, reco_loss: 0.1183\n",
      "the 5-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4514; D_loss_gauss: 0.05782; G_loss: 23.66, reco_loss: 0.1184\n",
      "the 6-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4337; D_loss_gauss: 0.05298; G_loss: 22.87, reco_loss: 0.1188\n",
      "the 7-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4616; D_loss_gauss: 0.03763; G_loss: 22.18, reco_loss: 0.1176\n",
      "the 8-th batch at \n",
      "Epoch-59; D_loss_cat: 0.452; D_loss_gauss: 0.0333; G_loss: 21.94, reco_loss: 0.1167\n",
      "the 9-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4292; D_loss_gauss: 0.03094; G_loss: 21.73, reco_loss: 0.1161\n",
      "the 10-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4521; D_loss_gauss: 0.02973; G_loss: 20.92, reco_loss: 0.1174\n",
      "the 11-th batch at \n",
      "Epoch-59; D_loss_cat: 0.4402; D_loss_gauss: 0.02252; G_loss: 20.71, reco_loss: 0.1169\n",
      "Train accuracy: 8.082314 %\n",
      "the 0-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4425; D_loss_gauss: 0.01864; G_loss: 19.97, reco_loss: 0.133\n",
      "the 1-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4243; D_loss_gauss: 0.0166; G_loss: 18.53, reco_loss: 0.1362\n",
      "the 2-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4247; D_loss_gauss: 0.01592; G_loss: 15.66, reco_loss: 0.1372\n",
      "the 3-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4356; D_loss_gauss: 0.0166; G_loss: 12.94, reco_loss: 0.1376\n",
      "the 4-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4511; D_loss_gauss: 0.01919; G_loss: 9.929, reco_loss: 0.1363\n",
      "the 5-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4107; D_loss_gauss: 0.04812; G_loss: 7.649, reco_loss: 0.1392\n",
      "the 6-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4672; D_loss_gauss: 0.1612; G_loss: 5.646, reco_loss: 0.1378\n",
      "the 7-th batch at \n",
      "Epoch-60; D_loss_cat: 0.43; D_loss_gauss: 0.4064; G_loss: 4.924, reco_loss: 0.1384\n",
      "the 8-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4477; D_loss_gauss: 0.8573; G_loss: 3.919, reco_loss: 0.1397\n",
      "the 9-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4369; D_loss_gauss: 1.386; G_loss: 3.251, reco_loss: 0.1403\n",
      "the 10-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4461; D_loss_gauss: 1.655; G_loss: 3.388, reco_loss: 0.1427\n",
      "the 11-th batch at \n",
      "Epoch-60; D_loss_cat: 0.4571; D_loss_gauss: 1.628; G_loss: 3.686, reco_loss: 0.1431\n",
      "Train accuracy: 8.000731333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-61; D_loss_cat: 0.458; D_loss_gauss: 1.478; G_loss: 4.151, reco_loss: 0.1435\n",
      "the 1-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4489; D_loss_gauss: 0.3346; G_loss: 6.548, reco_loss: 0.129\n",
      "the 2-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4348; D_loss_gauss: 0.1136; G_loss: 8.665, reco_loss: 0.1311\n",
      "the 3-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4374; D_loss_gauss: 0.0754; G_loss: 10.54, reco_loss: 0.1292\n",
      "the 4-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4362; D_loss_gauss: 0.1075; G_loss: 12.53, reco_loss: 0.1257\n",
      "the 5-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4545; D_loss_gauss: 0.1454; G_loss: 13.99, reco_loss: 0.1258\n",
      "the 6-th batch at \n",
      "Epoch-61; D_loss_cat: 0.474; D_loss_gauss: 0.1856; G_loss: 15.29, reco_loss: 0.1244\n",
      "the 7-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4419; D_loss_gauss: 0.2023; G_loss: 17.01, reco_loss: 0.1235\n",
      "the 8-th batch at \n",
      "Epoch-61; D_loss_cat: 0.472; D_loss_gauss: 0.2642; G_loss: 17.76, reco_loss: 0.123\n",
      "the 9-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4397; D_loss_gauss: 0.2893; G_loss: 18.34, reco_loss: 0.1211\n",
      "the 10-th batch at \n",
      "Epoch-61; D_loss_cat: 0.457; D_loss_gauss: 0.2729; G_loss: 19.05, reco_loss: 0.1202\n",
      "the 11-th batch at \n",
      "Epoch-61; D_loss_cat: 0.4585; D_loss_gauss: 0.275; G_loss: 19.41, reco_loss: 0.1191\n",
      "Train accuracy: 8.043452666666665 %\n",
      "the 0-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4519; D_loss_gauss: 0.28; G_loss: 19.25, reco_loss: 0.1363\n",
      "the 1-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4351; D_loss_gauss: 0.2253; G_loss: 19.53, reco_loss: 0.1189\n",
      "the 2-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4434; D_loss_gauss: 0.1968; G_loss: 19.47, reco_loss: 0.1177\n",
      "the 3-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4569; D_loss_gauss: 0.1944; G_loss: 18.79, reco_loss: 0.1174\n",
      "the 4-th batch at \n",
      "Epoch-62; D_loss_cat: 0.448; D_loss_gauss: 0.1752; G_loss: 18.62, reco_loss: 0.1173\n",
      "the 5-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4523; D_loss_gauss: 0.1471; G_loss: 18.36, reco_loss: 0.1164\n",
      "the 6-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4568; D_loss_gauss: 0.1213; G_loss: 17.66, reco_loss: 0.1161\n",
      "the 7-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4478; D_loss_gauss: 0.09632; G_loss: 17.32, reco_loss: 0.1165\n",
      "the 8-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4521; D_loss_gauss: 0.09529; G_loss: 17.17, reco_loss: 0.1156\n",
      "the 9-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4198; D_loss_gauss: 0.08148; G_loss: 17.11, reco_loss: 0.1148\n",
      "the 10-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4443; D_loss_gauss: 0.06967; G_loss: 16.34, reco_loss: 0.1163\n",
      "the 11-th batch at \n",
      "Epoch-62; D_loss_cat: 0.4398; D_loss_gauss: 0.06483; G_loss: 16.26, reco_loss: 0.1147\n",
      "Train accuracy: 8.086592999999999 %\n",
      "the 0-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4159; D_loss_gauss: 0.05839; G_loss: 16.26, reco_loss: 0.133\n",
      "the 1-th batch at \n",
      "Epoch-63; D_loss_cat: 0.437; D_loss_gauss: 0.05181; G_loss: 14.78, reco_loss: 0.1387\n",
      "the 2-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4012; D_loss_gauss: 0.04396; G_loss: 12.9, reco_loss: 0.136\n",
      "the 3-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4254; D_loss_gauss: 0.04475; G_loss: 11.18, reco_loss: 0.1363\n",
      "the 4-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4266; D_loss_gauss: 0.04988; G_loss: 9.302, reco_loss: 0.1357\n",
      "the 5-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4308; D_loss_gauss: 0.07664; G_loss: 7.292, reco_loss: 0.1378\n",
      "the 6-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4143; D_loss_gauss: 0.1648; G_loss: 5.945, reco_loss: 0.1392\n",
      "the 7-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4364; D_loss_gauss: 0.3563; G_loss: 4.884, reco_loss: 0.1394\n",
      "the 8-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4409; D_loss_gauss: 0.7574; G_loss: 3.945, reco_loss: 0.1386\n",
      "the 9-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4214; D_loss_gauss: 1.263; G_loss: 3.572, reco_loss: 0.1398\n",
      "the 10-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4567; D_loss_gauss: 1.631; G_loss: 3.204, reco_loss: 0.1394\n",
      "the 11-th batch at \n",
      "Epoch-63; D_loss_cat: 0.4527; D_loss_gauss: 1.831; G_loss: 3.194, reco_loss: 0.1419\n",
      "Train accuracy: 8.047569666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4393; D_loss_gauss: 1.744; G_loss: 3.652, reco_loss: 0.1421\n",
      "the 1-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4224; D_loss_gauss: 0.3567; G_loss: 6.856, reco_loss: 0.1281\n",
      "the 2-th batch at \n",
      "Epoch-64; D_loss_cat: 0.437; D_loss_gauss: 0.09796; G_loss: 9.628, reco_loss: 0.127\n",
      "the 3-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4485; D_loss_gauss: 0.07399; G_loss: 12.41, reco_loss: 0.1255\n",
      "the 4-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4386; D_loss_gauss: 0.08308; G_loss: 14.72, reco_loss: 0.1276\n",
      "the 5-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4342; D_loss_gauss: 0.0961; G_loss: 16.47, reco_loss: 0.125\n",
      "the 6-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4469; D_loss_gauss: 0.1002; G_loss: 18.27, reco_loss: 0.1244\n",
      "the 7-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4541; D_loss_gauss: 0.1265; G_loss: 20.02, reco_loss: 0.1224\n",
      "the 8-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4492; D_loss_gauss: 0.1392; G_loss: 21.43, reco_loss: 0.1194\n",
      "the 9-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4488; D_loss_gauss: 0.1413; G_loss: 22.44, reco_loss: 0.12\n",
      "the 10-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4573; D_loss_gauss: 0.1616; G_loss: 23.31, reco_loss: 0.1192\n",
      "the 11-th batch at \n",
      "Epoch-64; D_loss_cat: 0.4387; D_loss_gauss: 0.1738; G_loss: 24.1, reco_loss: 0.1182\n",
      "Train accuracy: 8.048204333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4384; D_loss_gauss: 0.1799; G_loss: 24.06, reco_loss: 0.1344\n",
      "the 1-th batch at \n",
      "Epoch-65; D_loss_cat: 0.46; D_loss_gauss: 0.1761; G_loss: 24.02, reco_loss: 0.1171\n",
      "the 2-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4298; D_loss_gauss: 0.1559; G_loss: 24.49, reco_loss: 0.1167\n",
      "the 3-th batch at \n",
      "Epoch-65; D_loss_cat: 0.444; D_loss_gauss: 0.1586; G_loss: 24.15, reco_loss: 0.1151\n",
      "the 4-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4414; D_loss_gauss: 0.1418; G_loss: 23.54, reco_loss: 0.1162\n",
      "the 5-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4363; D_loss_gauss: 0.142; G_loss: 23.64, reco_loss: 0.1156\n",
      "the 6-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4333; D_loss_gauss: 0.1258; G_loss: 23.1, reco_loss: 0.1147\n",
      "the 7-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4258; D_loss_gauss: 0.1218; G_loss: 22.37, reco_loss: 0.114\n",
      "the 8-th batch at \n",
      "Epoch-65; D_loss_cat: 0.442; D_loss_gauss: 0.1061; G_loss: 22.6, reco_loss: 0.1144\n",
      "the 9-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4439; D_loss_gauss: 0.1027; G_loss: 22.46, reco_loss: 0.1135\n",
      "the 10-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4291; D_loss_gauss: 0.09926; G_loss: 21.81, reco_loss: 0.1134\n",
      "the 11-th batch at \n",
      "Epoch-65; D_loss_cat: 0.4294; D_loss_gauss: 0.09581; G_loss: 22.01, reco_loss: 0.1133\n",
      "Train accuracy: 8.086516666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4118; D_loss_gauss: 0.07738; G_loss: 21.41, reco_loss: 0.1321\n",
      "the 1-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4158; D_loss_gauss: 0.07196; G_loss: 19.7, reco_loss: 0.1324\n",
      "the 2-th batch at \n",
      "Epoch-66; D_loss_cat: 0.3943; D_loss_gauss: 0.07251; G_loss: 17.5, reco_loss: 0.134\n",
      "the 3-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4128; D_loss_gauss: 0.06996; G_loss: 14.73, reco_loss: 0.1325\n",
      "the 4-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4402; D_loss_gauss: 0.07012; G_loss: 11.45, reco_loss: 0.1342\n",
      "the 5-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4319; D_loss_gauss: 0.08208; G_loss: 9.223, reco_loss: 0.1365\n",
      "the 6-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4352; D_loss_gauss: 0.1546; G_loss: 7.013, reco_loss: 0.1372\n",
      "the 7-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4461; D_loss_gauss: 0.4186; G_loss: 4.763, reco_loss: 0.137\n",
      "the 8-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4524; D_loss_gauss: 0.9637; G_loss: 3.95, reco_loss: 0.1383\n",
      "the 9-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4446; D_loss_gauss: 1.676; G_loss: 3.155, reco_loss: 0.1413\n",
      "the 10-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4681; D_loss_gauss: 2.314; G_loss: 2.528, reco_loss: 0.1399\n",
      "the 11-th batch at \n",
      "Epoch-66; D_loss_cat: 0.4766; D_loss_gauss: 2.587; G_loss: 2.851, reco_loss: 0.1419\n",
      "Train accuracy: 8.010142666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4662; D_loss_gauss: 2.461; G_loss: 2.821, reco_loss: 0.1418\n",
      "the 1-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4326; D_loss_gauss: 1.02; G_loss: 3.804, reco_loss: 0.1255\n",
      "the 2-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4549; D_loss_gauss: 0.3749; G_loss: 5.896, reco_loss: 0.1241\n",
      "the 3-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4367; D_loss_gauss: 0.1711; G_loss: 8.337, reco_loss: 0.1254\n",
      "the 4-th batch at \n",
      "Epoch-67; D_loss_cat: 0.456; D_loss_gauss: 0.1405; G_loss: 10.01, reco_loss: 0.1232\n",
      "the 5-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4275; D_loss_gauss: 0.1413; G_loss: 11.52, reco_loss: 0.1227\n",
      "the 6-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4488; D_loss_gauss: 0.167; G_loss: 13.02, reco_loss: 0.1221\n",
      "the 7-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4616; D_loss_gauss: 0.1864; G_loss: 13.82, reco_loss: 0.1208\n",
      "the 8-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4455; D_loss_gauss: 0.2131; G_loss: 15.03, reco_loss: 0.1209\n",
      "the 9-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4381; D_loss_gauss: 0.2129; G_loss: 16.08, reco_loss: 0.1197\n",
      "the 10-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4499; D_loss_gauss: 0.2316; G_loss: 16.63, reco_loss: 0.117\n",
      "the 11-th batch at \n",
      "Epoch-67; D_loss_cat: 0.4581; D_loss_gauss: 0.2324; G_loss: 17.2, reco_loss: 0.1167\n",
      "Train accuracy: 8.051221333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4484; D_loss_gauss: 0.2334; G_loss: 17.76, reco_loss: 0.1332\n",
      "the 1-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4656; D_loss_gauss: 0.2394; G_loss: 17.58, reco_loss: 0.1151\n",
      "the 2-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4518; D_loss_gauss: 0.2002; G_loss: 17.46, reco_loss: 0.1144\n",
      "the 3-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4575; D_loss_gauss: 0.1995; G_loss: 17.86, reco_loss: 0.1144\n",
      "the 4-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4519; D_loss_gauss: 0.1969; G_loss: 17.56, reco_loss: 0.1141\n",
      "the 5-th batch at \n",
      "Epoch-68; D_loss_cat: 0.456; D_loss_gauss: 0.1835; G_loss: 17.39, reco_loss: 0.1126\n",
      "the 6-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4525; D_loss_gauss: 0.1781; G_loss: 17.39, reco_loss: 0.1138\n",
      "the 7-th batch at \n",
      "Epoch-68; D_loss_cat: 0.428; D_loss_gauss: 0.1632; G_loss: 17.23, reco_loss: 0.1132\n",
      "the 8-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4495; D_loss_gauss: 0.1443; G_loss: 16.64, reco_loss: 0.1146\n",
      "the 9-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4589; D_loss_gauss: 0.1426; G_loss: 17.07, reco_loss: 0.1124\n",
      "the 10-th batch at \n",
      "Epoch-68; D_loss_cat: 0.433; D_loss_gauss: 0.129; G_loss: 17.1, reco_loss: 0.1125\n",
      "the 11-th batch at \n",
      "Epoch-68; D_loss_cat: 0.4586; D_loss_gauss: 0.1273; G_loss: 16.35, reco_loss: 0.1119\n",
      "Train accuracy: 8.082984666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4509; D_loss_gauss: 0.1166; G_loss: 16.39, reco_loss: 0.1295\n",
      "the 1-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4521; D_loss_gauss: 0.1116; G_loss: 15.07, reco_loss: 0.1339\n",
      "the 2-th batch at \n",
      "Epoch-69; D_loss_cat: 0.429; D_loss_gauss: 0.09882; G_loss: 12.87, reco_loss: 0.1323\n",
      "the 3-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4448; D_loss_gauss: 0.09137; G_loss: 11.22, reco_loss: 0.1314\n",
      "the 4-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4293; D_loss_gauss: 0.0954; G_loss: 9.552, reco_loss: 0.133\n",
      "the 5-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4517; D_loss_gauss: 0.09492; G_loss: 7.539, reco_loss: 0.1347\n",
      "the 6-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4603; D_loss_gauss: 0.1259; G_loss: 6.252, reco_loss: 0.1355\n",
      "the 7-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4452; D_loss_gauss: 0.2183; G_loss: 5.476, reco_loss: 0.1361\n",
      "the 8-th batch at \n",
      "Epoch-69; D_loss_cat: 0.468; D_loss_gauss: 0.4363; G_loss: 4.016, reco_loss: 0.1361\n",
      "the 9-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4506; D_loss_gauss: 0.7536; G_loss: 3.492, reco_loss: 0.1367\n",
      "the 10-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4606; D_loss_gauss: 1.102; G_loss: 3.21, reco_loss: 0.1367\n",
      "the 11-th batch at \n",
      "Epoch-69; D_loss_cat: 0.4439; D_loss_gauss: 1.441; G_loss: 2.921, reco_loss: 0.1393\n",
      "Train accuracy: 8.030815333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4628; D_loss_gauss: 1.497; G_loss: 2.912, reco_loss: 0.1393\n",
      "the 1-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4629; D_loss_gauss: 0.499; G_loss: 5.245, reco_loss: 0.1222\n",
      "the 2-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4479; D_loss_gauss: 0.1792; G_loss: 7.632, reco_loss: 0.1213\n",
      "the 3-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4603; D_loss_gauss: 0.1097; G_loss: 9.446, reco_loss: 0.1222\n",
      "the 4-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4501; D_loss_gauss: 0.1003; G_loss: 11.46, reco_loss: 0.1202\n",
      "the 5-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4572; D_loss_gauss: 0.1042; G_loss: 13.14, reco_loss: 0.1187\n",
      "the 6-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4261; D_loss_gauss: 0.1171; G_loss: 14.61, reco_loss: 0.1183\n",
      "the 7-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4604; D_loss_gauss: 0.1258; G_loss: 15.59, reco_loss: 0.1175\n",
      "the 8-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4556; D_loss_gauss: 0.1369; G_loss: 16.97, reco_loss: 0.1175\n",
      "the 9-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4565; D_loss_gauss: 0.1465; G_loss: 18.07, reco_loss: 0.1163\n",
      "the 10-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4529; D_loss_gauss: 0.1383; G_loss: 18.95, reco_loss: 0.1152\n",
      "the 11-th batch at \n",
      "Epoch-70; D_loss_cat: 0.4441; D_loss_gauss: 0.1347; G_loss: 19.8, reco_loss: 0.1143\n",
      "Train accuracy: 8.057474333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4334; D_loss_gauss: 0.1389; G_loss: 20.32, reco_loss: 0.13\n",
      "the 1-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4389; D_loss_gauss: 0.1504; G_loss: 20.2, reco_loss: 0.1134\n",
      "the 2-th batch at \n",
      "Epoch-71; D_loss_cat: 0.449; D_loss_gauss: 0.131; G_loss: 20.35, reco_loss: 0.1123\n",
      "the 3-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4339; D_loss_gauss: 0.1287; G_loss: 20.92, reco_loss: 0.1129\n",
      "the 4-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4344; D_loss_gauss: 0.131; G_loss: 20.83, reco_loss: 0.1128\n",
      "the 5-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4429; D_loss_gauss: 0.1133; G_loss: 20.69, reco_loss: 0.1114\n",
      "the 6-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4236; D_loss_gauss: 0.1116; G_loss: 21.06, reco_loss: 0.1121\n",
      "the 7-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4355; D_loss_gauss: 0.1102; G_loss: 20.94, reco_loss: 0.1119\n",
      "the 8-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4303; D_loss_gauss: 0.1021; G_loss: 20.64, reco_loss: 0.1108\n",
      "the 9-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4213; D_loss_gauss: 0.0896; G_loss: 20.7, reco_loss: 0.1115\n",
      "the 10-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4075; D_loss_gauss: 0.08971; G_loss: 20.63, reco_loss: 0.1105\n",
      "the 11-th batch at \n",
      "Epoch-71; D_loss_cat: 0.4227; D_loss_gauss: 0.08219; G_loss: 20.35, reco_loss: 0.1108\n",
      "Train accuracy: 8.098286333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4288; D_loss_gauss: 0.0775; G_loss: 20.12, reco_loss: 0.1278\n",
      "the 1-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4172; D_loss_gauss: 0.06792; G_loss: 18.86, reco_loss: 0.1306\n",
      "the 2-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4174; D_loss_gauss: 0.06156; G_loss: 16.46, reco_loss: 0.1308\n",
      "the 3-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4366; D_loss_gauss: 0.06448; G_loss: 13.99, reco_loss: 0.1325\n",
      "the 4-th batch at \n",
      "Epoch-72; D_loss_cat: 0.429; D_loss_gauss: 0.06011; G_loss: 12.36, reco_loss: 0.1324\n",
      "the 5-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4502; D_loss_gauss: 0.05847; G_loss: 10.29, reco_loss: 0.1341\n",
      "the 6-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4401; D_loss_gauss: 0.06759; G_loss: 8.616, reco_loss: 0.1341\n",
      "the 7-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4435; D_loss_gauss: 0.1136; G_loss: 7.315, reco_loss: 0.1351\n",
      "the 8-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4565; D_loss_gauss: 0.2627; G_loss: 5.406, reco_loss: 0.1363\n",
      "the 9-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4457; D_loss_gauss: 0.6468; G_loss: 4.264, reco_loss: 0.1374\n",
      "the 10-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4643; D_loss_gauss: 1.162; G_loss: 3.71, reco_loss: 0.1378\n",
      "the 11-th batch at \n",
      "Epoch-72; D_loss_cat: 0.4718; D_loss_gauss: 1.762; G_loss: 2.899, reco_loss: 0.1405\n",
      "Train accuracy: 7.965083666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4565; D_loss_gauss: 1.922; G_loss: 3.06, reco_loss: 0.142\n",
      "the 1-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4448; D_loss_gauss: 0.518; G_loss: 5.712, reco_loss: 0.1283\n",
      "the 2-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4543; D_loss_gauss: 0.1689; G_loss: 8.028, reco_loss: 0.1244\n",
      "the 3-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4476; D_loss_gauss: 0.1033; G_loss: 10.14, reco_loss: 0.1258\n",
      "the 4-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4361; D_loss_gauss: 0.1015; G_loss: 12.29, reco_loss: 0.1241\n",
      "the 5-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4489; D_loss_gauss: 0.09922; G_loss: 13.71, reco_loss: 0.1198\n",
      "the 6-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4544; D_loss_gauss: 0.1122; G_loss: 14.83, reco_loss: 0.121\n",
      "the 7-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4518; D_loss_gauss: 0.1248; G_loss: 16.7, reco_loss: 0.1187\n",
      "the 8-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4415; D_loss_gauss: 0.1337; G_loss: 17.45, reco_loss: 0.1176\n",
      "the 9-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4428; D_loss_gauss: 0.1492; G_loss: 17.7, reco_loss: 0.1169\n",
      "the 10-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4602; D_loss_gauss: 0.16; G_loss: 18.63, reco_loss: 0.1156\n",
      "the 11-th batch at \n",
      "Epoch-73; D_loss_cat: 0.4283; D_loss_gauss: 0.157; G_loss: 19.18, reco_loss: 0.1152\n",
      "Train accuracy: 8.075671 %\n",
      "the 0-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4641; D_loss_gauss: 0.1458; G_loss: 18.66, reco_loss: 0.1302\n",
      "the 1-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4525; D_loss_gauss: 0.1526; G_loss: 19.33, reco_loss: 0.1133\n",
      "the 2-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4388; D_loss_gauss: 0.1524; G_loss: 19.21, reco_loss: 0.1138\n",
      "the 3-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4323; D_loss_gauss: 0.1358; G_loss: 18.67, reco_loss: 0.112\n",
      "the 4-th batch at \n",
      "Epoch-74; D_loss_cat: 0.43; D_loss_gauss: 0.1335; G_loss: 18.93, reco_loss: 0.1122\n",
      "the 5-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4193; D_loss_gauss: 0.1242; G_loss: 18.85, reco_loss: 0.1121\n",
      "the 6-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4082; D_loss_gauss: 0.1156; G_loss: 18.34, reco_loss: 0.1111\n",
      "the 7-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4175; D_loss_gauss: 0.1204; G_loss: 17.84, reco_loss: 0.1112\n",
      "the 8-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4136; D_loss_gauss: 0.09839; G_loss: 17.9, reco_loss: 0.1107\n",
      "the 9-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4145; D_loss_gauss: 0.08461; G_loss: 17.59, reco_loss: 0.111\n",
      "the 10-th batch at \n",
      "Epoch-74; D_loss_cat: 0.3989; D_loss_gauss: 0.09115; G_loss: 17.25, reco_loss: 0.1097\n",
      "the 11-th batch at \n",
      "Epoch-74; D_loss_cat: 0.4174; D_loss_gauss: 0.08554; G_loss: 17.31, reco_loss: 0.1101\n",
      "Train accuracy: 8.112372333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-75; D_loss_cat: 0.3984; D_loss_gauss: 0.07679; G_loss: 16.79, reco_loss: 0.1295\n",
      "the 1-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4052; D_loss_gauss: 0.07135; G_loss: 15.3, reco_loss: 0.1305\n",
      "the 2-th batch at \n",
      "Epoch-75; D_loss_cat: 0.3994; D_loss_gauss: 0.06992; G_loss: 13.42, reco_loss: 0.1326\n",
      "the 3-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4174; D_loss_gauss: 0.06992; G_loss: 11.6, reco_loss: 0.1324\n",
      "the 4-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4101; D_loss_gauss: 0.07629; G_loss: 9.709, reco_loss: 0.1321\n",
      "the 5-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4203; D_loss_gauss: 0.1035; G_loss: 8.257, reco_loss: 0.1326\n",
      "the 6-th batch at \n",
      "Epoch-75; D_loss_cat: 0.449; D_loss_gauss: 0.1533; G_loss: 6.501, reco_loss: 0.1347\n",
      "the 7-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4469; D_loss_gauss: 0.3087; G_loss: 5.753, reco_loss: 0.135\n",
      "the 8-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4483; D_loss_gauss: 0.5975; G_loss: 4.64, reco_loss: 0.1341\n",
      "the 9-th batch at \n",
      "Epoch-75; D_loss_cat: 0.449; D_loss_gauss: 1.017; G_loss: 3.511, reco_loss: 0.1353\n",
      "the 10-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4431; D_loss_gauss: 1.407; G_loss: 3.616, reco_loss: 0.1378\n",
      "the 11-th batch at \n",
      "Epoch-75; D_loss_cat: 0.4204; D_loss_gauss: 1.692; G_loss: 3.655, reco_loss: 0.1379\n",
      "Train accuracy: 8.029437333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4735; D_loss_gauss: 1.707; G_loss: 2.97, reco_loss: 0.1362\n",
      "the 1-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4774; D_loss_gauss: 0.4651; G_loss: 6.302, reco_loss: 0.1238\n",
      "the 2-th batch at \n",
      "Epoch-76; D_loss_cat: 0.435; D_loss_gauss: 0.1485; G_loss: 9.21, reco_loss: 0.1248\n",
      "the 3-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4503; D_loss_gauss: 0.09673; G_loss: 10.98, reco_loss: 0.123\n",
      "the 4-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4514; D_loss_gauss: 0.09944; G_loss: 13.7, reco_loss: 0.1228\n",
      "the 5-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4538; D_loss_gauss: 0.1094; G_loss: 15.38, reco_loss: 0.1206\n",
      "the 6-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4259; D_loss_gauss: 0.1228; G_loss: 16.52, reco_loss: 0.1208\n",
      "the 7-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4322; D_loss_gauss: 0.1374; G_loss: 17.69, reco_loss: 0.1191\n",
      "the 8-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4497; D_loss_gauss: 0.1601; G_loss: 18.6, reco_loss: 0.1179\n",
      "the 9-th batch at \n",
      "Epoch-76; D_loss_cat: 0.455; D_loss_gauss: 0.1592; G_loss: 19.19, reco_loss: 0.1157\n",
      "the 10-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4476; D_loss_gauss: 0.1656; G_loss: 19.97, reco_loss: 0.1158\n",
      "the 11-th batch at \n",
      "Epoch-76; D_loss_cat: 0.4513; D_loss_gauss: 0.1825; G_loss: 20.19, reco_loss: 0.1126\n",
      "Train accuracy: 8.042943000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4571; D_loss_gauss: 0.1726; G_loss: 20.13, reco_loss: 0.1283\n",
      "the 1-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4378; D_loss_gauss: 0.1692; G_loss: 20.34, reco_loss: 0.1127\n",
      "the 2-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4579; D_loss_gauss: 0.1602; G_loss: 20.19, reco_loss: 0.1136\n",
      "the 3-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4416; D_loss_gauss: 0.148; G_loss: 20.17, reco_loss: 0.1102\n",
      "the 4-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4452; D_loss_gauss: 0.1425; G_loss: 20.06, reco_loss: 0.1105\n",
      "the 5-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4578; D_loss_gauss: 0.1389; G_loss: 19.64, reco_loss: 0.1109\n",
      "the 6-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4411; D_loss_gauss: 0.118; G_loss: 19.55, reco_loss: 0.1096\n",
      "the 7-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4352; D_loss_gauss: 0.1221; G_loss: 19.09, reco_loss: 0.1107\n",
      "the 8-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4304; D_loss_gauss: 0.1085; G_loss: 18.65, reco_loss: 0.1105\n",
      "the 9-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4249; D_loss_gauss: 0.09705; G_loss: 18.38, reco_loss: 0.1099\n",
      "the 10-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4327; D_loss_gauss: 0.08434; G_loss: 18.12, reco_loss: 0.1088\n",
      "the 11-th batch at \n",
      "Epoch-77; D_loss_cat: 0.4403; D_loss_gauss: 0.08551; G_loss: 17.79, reco_loss: 0.1089\n",
      "Train accuracy: 8.077862333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4518; D_loss_gauss: 0.07778; G_loss: 17.31, reco_loss: 0.1281\n",
      "the 1-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4315; D_loss_gauss: 0.0659; G_loss: 16.81, reco_loss: 0.1311\n",
      "the 2-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4234; D_loss_gauss: 0.06814; G_loss: 14.58, reco_loss: 0.1317\n",
      "the 3-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4168; D_loss_gauss: 0.05969; G_loss: 12.74, reco_loss: 0.1312\n",
      "the 4-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4297; D_loss_gauss: 0.06038; G_loss: 10.65, reco_loss: 0.1312\n",
      "the 5-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4296; D_loss_gauss: 0.06675; G_loss: 8.597, reco_loss: 0.1315\n",
      "the 6-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4043; D_loss_gauss: 0.09688; G_loss: 7.082, reco_loss: 0.1339\n",
      "the 7-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4362; D_loss_gauss: 0.1903; G_loss: 5.444, reco_loss: 0.1327\n",
      "the 8-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4237; D_loss_gauss: 0.4099; G_loss: 4.566, reco_loss: 0.1334\n",
      "the 9-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4544; D_loss_gauss: 0.7302; G_loss: 3.632, reco_loss: 0.1339\n",
      "the 10-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4477; D_loss_gauss: 1.047; G_loss: 3.436, reco_loss: 0.1358\n",
      "the 11-th batch at \n",
      "Epoch-78; D_loss_cat: 0.4585; D_loss_gauss: 1.291; G_loss: 3.207, reco_loss: 0.136\n",
      "Train accuracy: 8.020235000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4576; D_loss_gauss: 1.4; G_loss: 3.215, reco_loss: 0.1363\n",
      "the 1-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4462; D_loss_gauss: 0.5127; G_loss: 4.98, reco_loss: 0.1221\n",
      "the 2-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4473; D_loss_gauss: 0.1842; G_loss: 7.098, reco_loss: 0.1199\n",
      "the 3-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4573; D_loss_gauss: 0.09955; G_loss: 9.054, reco_loss: 0.1183\n",
      "the 4-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4476; D_loss_gauss: 0.08745; G_loss: 10.88, reco_loss: 0.1195\n",
      "the 5-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4612; D_loss_gauss: 0.08634; G_loss: 12.37, reco_loss: 0.1181\n",
      "the 6-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4678; D_loss_gauss: 0.09407; G_loss: 13.66, reco_loss: 0.1166\n",
      "the 7-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4494; D_loss_gauss: 0.1037; G_loss: 14.97, reco_loss: 0.115\n",
      "the 8-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4548; D_loss_gauss: 0.1144; G_loss: 15.92, reco_loss: 0.1146\n",
      "the 9-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4508; D_loss_gauss: 0.1166; G_loss: 17.04, reco_loss: 0.1146\n",
      "the 10-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4332; D_loss_gauss: 0.1292; G_loss: 17.99, reco_loss: 0.1129\n",
      "the 11-th batch at \n",
      "Epoch-79; D_loss_cat: 0.4345; D_loss_gauss: 0.1227; G_loss: 18.29, reco_loss: 0.112\n",
      "Train accuracy: 8.061435 %\n",
      "the 0-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4555; D_loss_gauss: 0.1207; G_loss: 18.67, reco_loss: 0.1289\n",
      "the 1-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4382; D_loss_gauss: 0.1414; G_loss: 19.16, reco_loss: 0.1105\n",
      "the 2-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4669; D_loss_gauss: 0.1212; G_loss: 18.96, reco_loss: 0.1091\n",
      "the 3-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4488; D_loss_gauss: 0.1162; G_loss: 19.24, reco_loss: 0.1102\n",
      "the 4-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4387; D_loss_gauss: 0.1159; G_loss: 19.42, reco_loss: 0.1097\n",
      "the 5-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4336; D_loss_gauss: 0.1092; G_loss: 19.15, reco_loss: 0.11\n",
      "the 6-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4341; D_loss_gauss: 0.1045; G_loss: 19.22, reco_loss: 0.1091\n",
      "the 7-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4345; D_loss_gauss: 0.09358; G_loss: 19.04, reco_loss: 0.1082\n",
      "the 8-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4287; D_loss_gauss: 0.09388; G_loss: 18.81, reco_loss: 0.1088\n",
      "the 9-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4477; D_loss_gauss: 0.07839; G_loss: 18.72, reco_loss: 0.1081\n",
      "the 10-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4326; D_loss_gauss: 0.08295; G_loss: 18.93, reco_loss: 0.1078\n",
      "the 11-th batch at \n",
      "Epoch-80; D_loss_cat: 0.4405; D_loss_gauss: 0.0782; G_loss: 18.48, reco_loss: 0.1076\n",
      "Train accuracy: 8.099823333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4154; D_loss_gauss: 0.06368; G_loss: 18.13, reco_loss: 0.1263\n",
      "the 1-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4192; D_loss_gauss: 0.06468; G_loss: 17.0, reco_loss: 0.131\n",
      "the 2-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4407; D_loss_gauss: 0.05884; G_loss: 14.68, reco_loss: 0.1292\n",
      "the 3-th batch at \n",
      "Epoch-81; D_loss_cat: 0.44; D_loss_gauss: 0.06026; G_loss: 13.01, reco_loss: 0.1295\n",
      "the 4-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4598; D_loss_gauss: 0.05577; G_loss: 10.62, reco_loss: 0.1307\n",
      "the 5-th batch at \n",
      "Epoch-81; D_loss_cat: 0.45; D_loss_gauss: 0.06528; G_loss: 8.714, reco_loss: 0.1329\n",
      "the 6-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4611; D_loss_gauss: 0.09945; G_loss: 7.46, reco_loss: 0.1342\n",
      "the 7-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4637; D_loss_gauss: 0.211; G_loss: 5.753, reco_loss: 0.1341\n",
      "the 8-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4422; D_loss_gauss: 0.466; G_loss: 4.324, reco_loss: 0.1357\n",
      "the 9-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4622; D_loss_gauss: 0.9502; G_loss: 3.72, reco_loss: 0.1368\n",
      "the 10-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4457; D_loss_gauss: 1.465; G_loss: 3.175, reco_loss: 0.1373\n",
      "the 11-th batch at \n",
      "Epoch-81; D_loss_cat: 0.4591; D_loss_gauss: 1.813; G_loss: 2.816, reco_loss: 0.139\n",
      "Train accuracy: 7.982719333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4663; D_loss_gauss: 1.764; G_loss: 3.518, reco_loss: 0.1421\n",
      "the 1-th batch at \n",
      "Epoch-82; D_loss_cat: 0.463; D_loss_gauss: 0.3554; G_loss: 6.275, reco_loss: 0.128\n",
      "the 2-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4449; D_loss_gauss: 0.1056; G_loss: 8.833, reco_loss: 0.1231\n",
      "the 3-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4362; D_loss_gauss: 0.08795; G_loss: 11.86, reco_loss: 0.124\n",
      "the 4-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4635; D_loss_gauss: 0.09457; G_loss: 12.97, reco_loss: 0.1248\n",
      "the 5-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4505; D_loss_gauss: 0.1159; G_loss: 13.47, reco_loss: 0.1201\n",
      "the 6-th batch at \n",
      "Epoch-82; D_loss_cat: 0.497; D_loss_gauss: 0.1248; G_loss: 16.41, reco_loss: 0.119\n",
      "the 7-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4912; D_loss_gauss: 0.1312; G_loss: 17.21, reco_loss: 0.1195\n",
      "the 8-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4556; D_loss_gauss: 0.1504; G_loss: 16.74, reco_loss: 0.1174\n",
      "the 9-th batch at \n",
      "Epoch-82; D_loss_cat: 0.5061; D_loss_gauss: 0.1648; G_loss: 19.01, reco_loss: 0.1169\n",
      "the 10-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4608; D_loss_gauss: 0.1726; G_loss: 19.59, reco_loss: 0.1147\n",
      "the 11-th batch at \n",
      "Epoch-82; D_loss_cat: 0.4859; D_loss_gauss: 0.1595; G_loss: 18.64, reco_loss: 0.113\n",
      "Train accuracy: 8.076786333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4492; D_loss_gauss: 0.1652; G_loss: 19.2, reco_loss: 0.129\n",
      "the 1-th batch at \n",
      "Epoch-83; D_loss_cat: 0.441; D_loss_gauss: 0.1712; G_loss: 20.46, reco_loss: 0.1115\n",
      "the 2-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4678; D_loss_gauss: 0.1605; G_loss: 19.79, reco_loss: 0.1111\n",
      "the 3-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4177; D_loss_gauss: 0.1542; G_loss: 18.62, reco_loss: 0.1106\n",
      "the 4-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4386; D_loss_gauss: 0.1333; G_loss: 19.53, reco_loss: 0.1096\n",
      "the 5-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4351; D_loss_gauss: 0.1312; G_loss: 19.46, reco_loss: 0.1109\n",
      "the 6-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4745; D_loss_gauss: 0.1156; G_loss: 18.26, reco_loss: 0.1092\n",
      "the 7-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4342; D_loss_gauss: 0.1068; G_loss: 18.1, reco_loss: 0.109\n",
      "the 8-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4004; D_loss_gauss: 0.09948; G_loss: 18.62, reco_loss: 0.1082\n",
      "the 9-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4343; D_loss_gauss: 0.09187; G_loss: 18.06, reco_loss: 0.1083\n",
      "the 10-th batch at \n",
      "Epoch-83; D_loss_cat: 0.3964; D_loss_gauss: 0.08738; G_loss: 16.9, reco_loss: 0.1086\n",
      "the 11-th batch at \n",
      "Epoch-83; D_loss_cat: 0.4162; D_loss_gauss: 0.07854; G_loss: 17.31, reco_loss: 0.1086\n",
      "Train accuracy: 8.122469 %\n",
      "the 0-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4006; D_loss_gauss: 0.07925; G_loss: 17.21, reco_loss: 0.1265\n",
      "the 1-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4109; D_loss_gauss: 0.0715; G_loss: 15.75, reco_loss: 0.1295\n",
      "the 2-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4125; D_loss_gauss: 0.05953; G_loss: 13.75, reco_loss: 0.128\n",
      "the 3-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4435; D_loss_gauss: 0.05688; G_loss: 12.01, reco_loss: 0.1297\n",
      "the 4-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4326; D_loss_gauss: 0.05974; G_loss: 10.34, reco_loss: 0.1311\n",
      "the 5-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4509; D_loss_gauss: 0.07194; G_loss: 8.387, reco_loss: 0.1329\n",
      "the 6-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4507; D_loss_gauss: 0.1047; G_loss: 6.726, reco_loss: 0.1338\n",
      "the 7-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4418; D_loss_gauss: 0.2074; G_loss: 6.047, reco_loss: 0.1338\n",
      "the 8-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4464; D_loss_gauss: 0.4107; G_loss: 5.24, reco_loss: 0.1347\n",
      "the 9-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4566; D_loss_gauss: 0.8271; G_loss: 3.896, reco_loss: 0.1341\n",
      "the 10-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4675; D_loss_gauss: 1.176; G_loss: 3.277, reco_loss: 0.1363\n",
      "the 11-th batch at \n",
      "Epoch-84; D_loss_cat: 0.4584; D_loss_gauss: 1.43; G_loss: 3.418, reco_loss: 0.1375\n",
      "Train accuracy: 7.997217999999999 %\n",
      "the 0-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4574; D_loss_gauss: 1.538; G_loss: 3.363, reco_loss: 0.1378\n",
      "the 1-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4672; D_loss_gauss: 0.4819; G_loss: 5.111, reco_loss: 0.1249\n",
      "the 2-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4672; D_loss_gauss: 0.1589; G_loss: 7.783, reco_loss: 0.1229\n",
      "the 3-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4493; D_loss_gauss: 0.0967; G_loss: 10.18, reco_loss: 0.1195\n",
      "the 4-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4721; D_loss_gauss: 0.0935; G_loss: 11.66, reco_loss: 0.1191\n",
      "the 5-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4551; D_loss_gauss: 0.0999; G_loss: 12.69, reco_loss: 0.1201\n",
      "the 6-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4598; D_loss_gauss: 0.1101; G_loss: 14.32, reco_loss: 0.117\n",
      "the 7-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4624; D_loss_gauss: 0.1125; G_loss: 15.5, reco_loss: 0.1157\n",
      "the 8-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4478; D_loss_gauss: 0.1257; G_loss: 16.07, reco_loss: 0.1161\n",
      "the 9-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4425; D_loss_gauss: 0.1278; G_loss: 16.84, reco_loss: 0.1146\n",
      "the 10-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4258; D_loss_gauss: 0.1397; G_loss: 17.85, reco_loss: 0.1128\n",
      "the 11-th batch at \n",
      "Epoch-85; D_loss_cat: 0.4377; D_loss_gauss: 0.1407; G_loss: 18.26, reco_loss: 0.1116\n",
      "Train accuracy: 8.056428000000002 %\n",
      "the 0-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4387; D_loss_gauss: 0.1373; G_loss: 18.2, reco_loss: 0.1283\n",
      "the 1-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4366; D_loss_gauss: 0.1431; G_loss: 18.38, reco_loss: 0.1105\n",
      "the 2-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4412; D_loss_gauss: 0.1367; G_loss: 18.63, reco_loss: 0.1101\n",
      "the 3-th batch at \n",
      "Epoch-86; D_loss_cat: 0.454; D_loss_gauss: 0.1316; G_loss: 18.41, reco_loss: 0.1087\n",
      "the 4-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4318; D_loss_gauss: 0.1345; G_loss: 18.26, reco_loss: 0.1087\n",
      "the 5-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4256; D_loss_gauss: 0.1154; G_loss: 18.48, reco_loss: 0.109\n",
      "the 6-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4336; D_loss_gauss: 0.1091; G_loss: 18.53, reco_loss: 0.1078\n",
      "the 7-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4257; D_loss_gauss: 0.09741; G_loss: 18.2, reco_loss: 0.1076\n",
      "the 8-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4293; D_loss_gauss: 0.1007; G_loss: 17.85, reco_loss: 0.108\n",
      "the 9-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4232; D_loss_gauss: 0.08438; G_loss: 17.91, reco_loss: 0.1059\n",
      "the 10-th batch at \n",
      "Epoch-86; D_loss_cat: 0.429; D_loss_gauss: 0.07706; G_loss: 17.85, reco_loss: 0.1065\n",
      "the 11-th batch at \n",
      "Epoch-86; D_loss_cat: 0.4179; D_loss_gauss: 0.07941; G_loss: 17.46, reco_loss: 0.1068\n",
      "Train accuracy: 8.089746333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4386; D_loss_gauss: 0.069; G_loss: 16.54, reco_loss: 0.1249\n",
      "the 1-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4297; D_loss_gauss: 0.05919; G_loss: 15.94, reco_loss: 0.1281\n",
      "the 2-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4281; D_loss_gauss: 0.06099; G_loss: 14.59, reco_loss: 0.1292\n",
      "the 3-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4369; D_loss_gauss: 0.06131; G_loss: 12.56, reco_loss: 0.1298\n",
      "the 4-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4355; D_loss_gauss: 0.05639; G_loss: 10.69, reco_loss: 0.1293\n",
      "the 5-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4295; D_loss_gauss: 0.06177; G_loss: 9.415, reco_loss: 0.1304\n",
      "the 6-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4694; D_loss_gauss: 0.07928; G_loss: 7.694, reco_loss: 0.1318\n",
      "the 7-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4397; D_loss_gauss: 0.144; G_loss: 6.135, reco_loss: 0.1317\n",
      "the 8-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4315; D_loss_gauss: 0.2639; G_loss: 5.515, reco_loss: 0.1336\n",
      "the 9-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4496; D_loss_gauss: 0.5329; G_loss: 4.521, reco_loss: 0.1332\n",
      "the 10-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4659; D_loss_gauss: 0.834; G_loss: 3.514, reco_loss: 0.135\n",
      "the 11-th batch at \n",
      "Epoch-87; D_loss_cat: 0.4462; D_loss_gauss: 1.199; G_loss: 3.188, reco_loss: 0.1366\n",
      "Train accuracy: 8.000197666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4561; D_loss_gauss: 1.467; G_loss: 3.461, reco_loss: 0.1373\n",
      "the 1-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4804; D_loss_gauss: 0.3778; G_loss: 5.696, reco_loss: 0.1218\n",
      "the 2-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4536; D_loss_gauss: 0.1268; G_loss: 7.945, reco_loss: 0.1207\n",
      "the 3-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4447; D_loss_gauss: 0.07561; G_loss: 10.35, reco_loss: 0.1196\n",
      "the 4-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4657; D_loss_gauss: 0.07326; G_loss: 11.84, reco_loss: 0.1192\n",
      "the 5-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4449; D_loss_gauss: 0.08228; G_loss: 12.81, reco_loss: 0.1187\n",
      "the 6-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4383; D_loss_gauss: 0.08452; G_loss: 14.11, reco_loss: 0.1168\n",
      "the 7-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4327; D_loss_gauss: 0.101; G_loss: 15.25, reco_loss: 0.1141\n",
      "the 8-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4289; D_loss_gauss: 0.09326; G_loss: 15.9, reco_loss: 0.1143\n",
      "the 9-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4132; D_loss_gauss: 0.1087; G_loss: 16.58, reco_loss: 0.114\n",
      "the 10-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4268; D_loss_gauss: 0.1072; G_loss: 17.51, reco_loss: 0.1123\n",
      "the 11-th batch at \n",
      "Epoch-88; D_loss_cat: 0.4132; D_loss_gauss: 0.1162; G_loss: 18.02, reco_loss: 0.1107\n",
      "Train accuracy: 8.068836666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-89; D_loss_cat: 0.428; D_loss_gauss: 0.1193; G_loss: 17.96, reco_loss: 0.1267\n",
      "the 1-th batch at \n",
      "Epoch-89; D_loss_cat: 0.4104; D_loss_gauss: 0.1211; G_loss: 18.2, reco_loss: 0.1093\n",
      "the 2-th batch at \n",
      "Epoch-89; D_loss_cat: 0.4196; D_loss_gauss: 0.1203; G_loss: 18.52, reco_loss: 0.1088\n",
      "the 3-th batch at \n",
      "Epoch-89; D_loss_cat: 0.4058; D_loss_gauss: 0.1192; G_loss: 18.62, reco_loss: 0.1076\n",
      "the 4-th batch at \n",
      "Epoch-89; D_loss_cat: 0.4074; D_loss_gauss: 0.1132; G_loss: 18.35, reco_loss: 0.1076\n",
      "the 5-th batch at \n",
      "Epoch-89; D_loss_cat: 0.4271; D_loss_gauss: 0.1142; G_loss: 18.15, reco_loss: 0.1069\n",
      "the 6-th batch at \n",
      "Epoch-89; D_loss_cat: 0.3931; D_loss_gauss: 0.093; G_loss: 18.45, reco_loss: 0.106\n",
      "the 7-th batch at \n",
      "Epoch-89; D_loss_cat: 0.3953; D_loss_gauss: 0.08827; G_loss: 18.39, reco_loss: 0.1064\n",
      "the 8-th batch at \n",
      "Epoch-89; D_loss_cat: 0.3889; D_loss_gauss: 0.08474; G_loss: 17.82, reco_loss: 0.1064\n",
      "the 9-th batch at \n",
      "Epoch-89; D_loss_cat: 0.4147; D_loss_gauss: 0.08297; G_loss: 17.76, reco_loss: 0.1068\n",
      "the 10-th batch at \n",
      "Epoch-89; D_loss_cat: 0.4067; D_loss_gauss: 0.07674; G_loss: 18.04, reco_loss: 0.1059\n",
      "the 11-th batch at \n",
      "Epoch-89; D_loss_cat: 0.3848; D_loss_gauss: 0.06253; G_loss: 17.95, reco_loss: 0.1061\n",
      "Train accuracy: 8.115717 %\n",
      "the 0-th batch at \n",
      "Epoch-90; D_loss_cat: 0.3625; D_loss_gauss: 0.0667; G_loss: 17.1, reco_loss: 0.1254\n",
      "the 1-th batch at \n",
      "Epoch-90; D_loss_cat: 0.3877; D_loss_gauss: 0.05706; G_loss: 15.5, reco_loss: 0.1328\n",
      "the 2-th batch at \n",
      "Epoch-90; D_loss_cat: 0.3921; D_loss_gauss: 0.05611; G_loss: 14.09, reco_loss: 0.1315\n",
      "the 3-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4054; D_loss_gauss: 0.05835; G_loss: 11.93, reco_loss: 0.1328\n",
      "the 4-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4297; D_loss_gauss: 0.05812; G_loss: 9.32, reco_loss: 0.1304\n",
      "the 5-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4392; D_loss_gauss: 0.09211; G_loss: 7.25, reco_loss: 0.1328\n",
      "the 6-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4436; D_loss_gauss: 0.1862; G_loss: 5.779, reco_loss: 0.1351\n",
      "the 7-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4499; D_loss_gauss: 0.3781; G_loss: 4.65, reco_loss: 0.1345\n",
      "the 8-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4314; D_loss_gauss: 0.7329; G_loss: 3.887, reco_loss: 0.1369\n",
      "the 9-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4437; D_loss_gauss: 1.114; G_loss: 3.552, reco_loss: 0.1348\n",
      "the 10-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4566; D_loss_gauss: 1.317; G_loss: 3.484, reco_loss: 0.1384\n",
      "the 11-th batch at \n",
      "Epoch-90; D_loss_cat: 0.4514; D_loss_gauss: 1.366; G_loss: 3.594, reco_loss: 0.1378\n",
      "Train accuracy: 8.009848666666665 %\n",
      "the 0-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4505; D_loss_gauss: 1.388; G_loss: 4.173, reco_loss: 0.1372\n",
      "the 1-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4376; D_loss_gauss: 0.2824; G_loss: 7.62, reco_loss: 0.1233\n",
      "the 2-th batch at \n",
      "Epoch-91; D_loss_cat: 0.435; D_loss_gauss: 0.1306; G_loss: 10.45, reco_loss: 0.1241\n",
      "the 3-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4705; D_loss_gauss: 0.1164; G_loss: 12.86, reco_loss: 0.1226\n",
      "the 4-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4521; D_loss_gauss: 0.145; G_loss: 15.24, reco_loss: 0.121\n",
      "the 5-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4488; D_loss_gauss: 0.1751; G_loss: 16.89, reco_loss: 0.1196\n",
      "the 6-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4474; D_loss_gauss: 0.209; G_loss: 17.72, reco_loss: 0.1182\n",
      "the 7-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4569; D_loss_gauss: 0.2355; G_loss: 18.95, reco_loss: 0.1169\n",
      "the 8-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4483; D_loss_gauss: 0.2481; G_loss: 19.95, reco_loss: 0.1147\n",
      "the 9-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4303; D_loss_gauss: 0.2356; G_loss: 20.58, reco_loss: 0.1152\n",
      "the 10-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4653; D_loss_gauss: 0.2109; G_loss: 20.59, reco_loss: 0.1123\n",
      "the 11-th batch at \n",
      "Epoch-91; D_loss_cat: 0.4486; D_loss_gauss: 0.221; G_loss: 21.12, reco_loss: 0.1109\n",
      "Train accuracy: 8.043118333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4705; D_loss_gauss: 0.1889; G_loss: 20.74, reco_loss: 0.1273\n",
      "the 1-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4419; D_loss_gauss: 0.174; G_loss: 20.6, reco_loss: 0.1103\n",
      "the 2-th batch at \n",
      "Epoch-92; D_loss_cat: 0.437; D_loss_gauss: 0.1696; G_loss: 20.37, reco_loss: 0.1087\n",
      "the 3-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4539; D_loss_gauss: 0.1305; G_loss: 20.05, reco_loss: 0.108\n",
      "the 4-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4472; D_loss_gauss: 0.1064; G_loss: 19.35, reco_loss: 0.1079\n",
      "the 5-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4357; D_loss_gauss: 0.08395; G_loss: 18.92, reco_loss: 0.1064\n",
      "the 6-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4575; D_loss_gauss: 0.06544; G_loss: 18.36, reco_loss: 0.1065\n",
      "the 7-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4471; D_loss_gauss: 0.05904; G_loss: 18.18, reco_loss: 0.1067\n",
      "the 8-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4392; D_loss_gauss: 0.04293; G_loss: 17.93, reco_loss: 0.1062\n",
      "the 9-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4336; D_loss_gauss: 0.03341; G_loss: 17.54, reco_loss: 0.106\n",
      "the 10-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4288; D_loss_gauss: 0.02996; G_loss: 17.23, reco_loss: 0.1057\n",
      "the 11-th batch at \n",
      "Epoch-92; D_loss_cat: 0.4126; D_loss_gauss: 0.02494; G_loss: 16.95, reco_loss: 0.1055\n",
      "Train accuracy: 8.081713666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4062; D_loss_gauss: 0.02208; G_loss: 16.02, reco_loss: 0.1253\n",
      "the 1-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4235; D_loss_gauss: 0.02053; G_loss: 14.91, reco_loss: 0.1358\n",
      "the 2-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4374; D_loss_gauss: 0.02229; G_loss: 13.53, reco_loss: 0.1304\n",
      "the 3-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4402; D_loss_gauss: 0.02584; G_loss: 11.65, reco_loss: 0.1316\n",
      "the 4-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4518; D_loss_gauss: 0.055; G_loss: 9.096, reco_loss: 0.1322\n",
      "the 5-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4591; D_loss_gauss: 0.1028; G_loss: 7.427, reco_loss: 0.1358\n",
      "the 6-th batch at \n",
      "Epoch-93; D_loss_cat: 0.455; D_loss_gauss: 0.1951; G_loss: 6.508, reco_loss: 0.1335\n",
      "the 7-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4508; D_loss_gauss: 0.4016; G_loss: 5.29, reco_loss: 0.1348\n",
      "the 8-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4522; D_loss_gauss: 0.7443; G_loss: 4.142, reco_loss: 0.1362\n",
      "the 9-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4547; D_loss_gauss: 1.052; G_loss: 4.143, reco_loss: 0.136\n",
      "the 10-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4552; D_loss_gauss: 1.159; G_loss: 4.164, reco_loss: 0.1378\n",
      "the 11-th batch at \n",
      "Epoch-93; D_loss_cat: 0.4704; D_loss_gauss: 1.268; G_loss: 3.872, reco_loss: 0.1379\n",
      "Train accuracy: 8.004472 %\n",
      "the 0-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4793; D_loss_gauss: 1.282; G_loss: 4.755, reco_loss: 0.1385\n",
      "the 1-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4596; D_loss_gauss: 0.13; G_loss: 9.496, reco_loss: 0.1248\n",
      "the 2-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4349; D_loss_gauss: 0.07023; G_loss: 12.76, reco_loss: 0.1258\n",
      "the 3-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4523; D_loss_gauss: 0.1179; G_loss: 14.92, reco_loss: 0.1253\n",
      "the 4-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4533; D_loss_gauss: 0.1545; G_loss: 17.61, reco_loss: 0.1231\n",
      "the 5-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4463; D_loss_gauss: 0.2165; G_loss: 19.66, reco_loss: 0.1228\n",
      "the 6-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4308; D_loss_gauss: 0.2455; G_loss: 21.07, reco_loss: 0.1198\n",
      "the 7-th batch at \n",
      "Epoch-94; D_loss_cat: 0.448; D_loss_gauss: 0.3063; G_loss: 21.99, reco_loss: 0.1176\n",
      "the 8-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4524; D_loss_gauss: 0.3441; G_loss: 22.32, reco_loss: 0.117\n",
      "the 9-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4381; D_loss_gauss: 0.3177; G_loss: 22.39, reco_loss: 0.1152\n",
      "the 10-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4349; D_loss_gauss: 0.3301; G_loss: 22.02, reco_loss: 0.1144\n",
      "the 11-th batch at \n",
      "Epoch-94; D_loss_cat: 0.4479; D_loss_gauss: 0.2546; G_loss: 21.76, reco_loss: 0.1118\n",
      "Train accuracy: 8.044991 %\n",
      "the 0-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4532; D_loss_gauss: 0.2454; G_loss: 21.22, reco_loss: 0.1285\n",
      "the 1-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4309; D_loss_gauss: 0.2086; G_loss: 21.03, reco_loss: 0.1097\n",
      "the 2-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4515; D_loss_gauss: 0.1633; G_loss: 20.25, reco_loss: 0.109\n",
      "the 3-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4278; D_loss_gauss: 0.1509; G_loss: 19.61, reco_loss: 0.1089\n",
      "the 4-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4419; D_loss_gauss: 0.1203; G_loss: 18.93, reco_loss: 0.108\n",
      "the 5-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4447; D_loss_gauss: 0.1047; G_loss: 18.38, reco_loss: 0.1074\n",
      "the 6-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4202; D_loss_gauss: 0.09711; G_loss: 18.01, reco_loss: 0.1078\n",
      "the 7-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4348; D_loss_gauss: 0.0759; G_loss: 17.52, reco_loss: 0.1077\n",
      "the 8-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4281; D_loss_gauss: 0.07218; G_loss: 16.91, reco_loss: 0.1062\n",
      "the 9-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4187; D_loss_gauss: 0.06289; G_loss: 16.87, reco_loss: 0.1056\n",
      "the 10-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4086; D_loss_gauss: 0.05152; G_loss: 16.39, reco_loss: 0.1054\n",
      "the 11-th batch at \n",
      "Epoch-95; D_loss_cat: 0.4313; D_loss_gauss: 0.04693; G_loss: 15.66, reco_loss: 0.1058\n",
      "Train accuracy: 8.082149 %\n",
      "the 0-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4065; D_loss_gauss: 0.04608; G_loss: 15.19, reco_loss: 0.1259\n",
      "the 1-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4188; D_loss_gauss: 0.0413; G_loss: 14.15, reco_loss: 0.1385\n",
      "the 2-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4276; D_loss_gauss: 0.03995; G_loss: 11.83, reco_loss: 0.1294\n",
      "the 3-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4324; D_loss_gauss: 0.04059; G_loss: 9.593, reco_loss: 0.1337\n",
      "the 4-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4469; D_loss_gauss: 0.06548; G_loss: 8.03, reco_loss: 0.1309\n",
      "the 5-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4467; D_loss_gauss: 0.1203; G_loss: 6.374, reco_loss: 0.1337\n",
      "the 6-th batch at \n",
      "Epoch-96; D_loss_cat: 0.458; D_loss_gauss: 0.2374; G_loss: 4.972, reco_loss: 0.1356\n",
      "the 7-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4556; D_loss_gauss: 0.3875; G_loss: 4.634, reco_loss: 0.1327\n",
      "the 8-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4717; D_loss_gauss: 0.6285; G_loss: 4.005, reco_loss: 0.1374\n",
      "the 9-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4553; D_loss_gauss: 0.8703; G_loss: 3.308, reco_loss: 0.1338\n",
      "the 10-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4425; D_loss_gauss: 0.9561; G_loss: 3.65, reco_loss: 0.1378\n",
      "the 11-th batch at \n",
      "Epoch-96; D_loss_cat: 0.4435; D_loss_gauss: 0.992; G_loss: 3.794, reco_loss: 0.1351\n",
      "Train accuracy: 8.006806333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4852; D_loss_gauss: 0.95; G_loss: 3.746, reco_loss: 0.1349\n",
      "the 1-th batch at \n",
      "Epoch-97; D_loss_cat: 0.463; D_loss_gauss: 0.2277; G_loss: 6.708, reco_loss: 0.122\n",
      "the 2-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4532; D_loss_gauss: 0.0918; G_loss: 9.211, reco_loss: 0.122\n",
      "the 3-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4441; D_loss_gauss: 0.07051; G_loss: 10.76, reco_loss: 0.1221\n",
      "the 4-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4654; D_loss_gauss: 0.08065; G_loss: 12.34, reco_loss: 0.1208\n",
      "the 5-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4481; D_loss_gauss: 0.08622; G_loss: 14.44, reco_loss: 0.1175\n",
      "the 6-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4594; D_loss_gauss: 0.1019; G_loss: 15.53, reco_loss: 0.1167\n",
      "the 7-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4605; D_loss_gauss: 0.1111; G_loss: 16.08, reco_loss: 0.1154\n",
      "the 8-th batch at \n",
      "Epoch-97; D_loss_cat: 0.469; D_loss_gauss: 0.1321; G_loss: 17.74, reco_loss: 0.1136\n",
      "the 9-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4698; D_loss_gauss: 0.1347; G_loss: 18.26, reco_loss: 0.1124\n",
      "the 10-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4575; D_loss_gauss: 0.1318; G_loss: 18.34, reco_loss: 0.1108\n",
      "the 11-th batch at \n",
      "Epoch-97; D_loss_cat: 0.4571; D_loss_gauss: 0.1468; G_loss: 19.31, reco_loss: 0.1105\n",
      "Train accuracy: 8.052261333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4478; D_loss_gauss: 0.1349; G_loss: 19.93, reco_loss: 0.1266\n",
      "the 1-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4269; D_loss_gauss: 0.1247; G_loss: 20.14, reco_loss: 0.1075\n",
      "the 2-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4426; D_loss_gauss: 0.1371; G_loss: 20.01, reco_loss: 0.1081\n",
      "the 3-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4305; D_loss_gauss: 0.1244; G_loss: 20.49, reco_loss: 0.1091\n",
      "the 4-th batch at \n",
      "Epoch-98; D_loss_cat: 0.417; D_loss_gauss: 0.111; G_loss: 20.46, reco_loss: 0.106\n",
      "the 5-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4317; D_loss_gauss: 0.1074; G_loss: 19.93, reco_loss: 0.1051\n",
      "the 6-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4112; D_loss_gauss: 0.1012; G_loss: 19.95, reco_loss: 0.1063\n",
      "the 7-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4212; D_loss_gauss: 0.0985; G_loss: 20.06, reco_loss: 0.1054\n",
      "the 8-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4123; D_loss_gauss: 0.09293; G_loss: 19.69, reco_loss: 0.1055\n",
      "the 9-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4064; D_loss_gauss: 0.07216; G_loss: 19.28, reco_loss: 0.1046\n",
      "the 10-th batch at \n",
      "Epoch-98; D_loss_cat: 0.4092; D_loss_gauss: 0.07209; G_loss: 19.51, reco_loss: 0.1044\n",
      "the 11-th batch at \n",
      "Epoch-98; D_loss_cat: 0.3967; D_loss_gauss: 0.07121; G_loss: 19.33, reco_loss: 0.1048\n",
      "Train accuracy: 8.088294333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-99; D_loss_cat: 0.3978; D_loss_gauss: 0.06245; G_loss: 18.53, reco_loss: 0.1244\n",
      "the 1-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4186; D_loss_gauss: 0.05315; G_loss: 17.12, reco_loss: 0.1323\n",
      "the 2-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4353; D_loss_gauss: 0.05336; G_loss: 15.49, reco_loss: 0.1279\n",
      "the 3-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4328; D_loss_gauss: 0.05366; G_loss: 13.19, reco_loss: 0.1281\n",
      "the 4-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4469; D_loss_gauss: 0.04875; G_loss: 10.32, reco_loss: 0.1285\n",
      "the 5-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4726; D_loss_gauss: 0.06912; G_loss: 8.1, reco_loss: 0.1322\n",
      "the 6-th batch at \n",
      "Epoch-99; D_loss_cat: 0.458; D_loss_gauss: 0.1217; G_loss: 6.685, reco_loss: 0.1345\n",
      "the 7-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4702; D_loss_gauss: 0.2883; G_loss: 4.97, reco_loss: 0.133\n",
      "the 8-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4592; D_loss_gauss: 0.6804; G_loss: 3.764, reco_loss: 0.1355\n",
      "the 9-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4573; D_loss_gauss: 1.095; G_loss: 3.406, reco_loss: 0.1355\n",
      "the 10-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4493; D_loss_gauss: 1.357; G_loss: 3.167, reco_loss: 0.1377\n",
      "the 11-th batch at \n",
      "Epoch-99; D_loss_cat: 0.4637; D_loss_gauss: 1.536; G_loss: 2.894, reco_loss: 0.1385\n",
      "Train accuracy: 7.993031666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4705; D_loss_gauss: 1.504; G_loss: 3.711, reco_loss: 0.1371\n",
      "the 1-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4349; D_loss_gauss: 0.2536; G_loss: 7.019, reco_loss: 0.1236\n",
      "the 2-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4614; D_loss_gauss: 0.1012; G_loss: 9.047, reco_loss: 0.1247\n",
      "the 3-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4345; D_loss_gauss: 0.1054; G_loss: 11.76, reco_loss: 0.1229\n",
      "the 4-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4233; D_loss_gauss: 0.133; G_loss: 13.63, reco_loss: 0.1223\n",
      "the 5-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4053; D_loss_gauss: 0.1328; G_loss: 14.79, reco_loss: 0.1213\n",
      "the 6-th batch at \n",
      "Epoch-100; D_loss_cat: 0.3994; D_loss_gauss: 0.1547; G_loss: 16.3, reco_loss: 0.1187\n",
      "the 7-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4376; D_loss_gauss: 0.1759; G_loss: 17.66, reco_loss: 0.116\n",
      "the 8-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4234; D_loss_gauss: 0.1807; G_loss: 18.43, reco_loss: 0.1148\n",
      "the 9-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4323; D_loss_gauss: 0.2171; G_loss: 18.84, reco_loss: 0.112\n",
      "the 10-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4306; D_loss_gauss: 0.1923; G_loss: 19.74, reco_loss: 0.1122\n",
      "the 11-th batch at \n",
      "Epoch-100; D_loss_cat: 0.4493; D_loss_gauss: 0.2212; G_loss: 19.82, reco_loss: 0.1107\n",
      "Train accuracy: 8.054213666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4403; D_loss_gauss: 0.207; G_loss: 19.67, reco_loss: 0.1286\n",
      "the 1-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4331; D_loss_gauss: 0.1818; G_loss: 19.87, reco_loss: 0.1088\n",
      "the 2-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4365; D_loss_gauss: 0.164; G_loss: 19.57, reco_loss: 0.1081\n",
      "the 3-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4243; D_loss_gauss: 0.1516; G_loss: 19.17, reco_loss: 0.1069\n",
      "the 4-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4312; D_loss_gauss: 0.1347; G_loss: 19.28, reco_loss: 0.106\n",
      "the 5-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4326; D_loss_gauss: 0.1312; G_loss: 19.1, reco_loss: 0.1062\n",
      "the 6-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4296; D_loss_gauss: 0.1251; G_loss: 18.92, reco_loss: 0.1062\n",
      "the 7-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4268; D_loss_gauss: 0.1194; G_loss: 18.64, reco_loss: 0.1049\n",
      "the 8-th batch at \n",
      "Epoch-101; D_loss_cat: 0.4076; D_loss_gauss: 0.09615; G_loss: 18.61, reco_loss: 0.1044\n",
      "the 9-th batch at \n",
      "Epoch-101; D_loss_cat: 0.3945; D_loss_gauss: 0.08496; G_loss: 18.57, reco_loss: 0.1047\n",
      "the 10-th batch at \n",
      "Epoch-101; D_loss_cat: 0.401; D_loss_gauss: 0.07559; G_loss: 18.18, reco_loss: 0.1041\n",
      "the 11-th batch at \n",
      "Epoch-101; D_loss_cat: 0.3817; D_loss_gauss: 0.07336; G_loss: 18.28, reco_loss: 0.1044\n",
      "Train accuracy: 8.098057666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-102; D_loss_cat: 0.3826; D_loss_gauss: 0.07156; G_loss: 17.48, reco_loss: 0.1242\n",
      "the 1-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4384; D_loss_gauss: 0.06461; G_loss: 15.8, reco_loss: 0.1353\n",
      "the 2-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4142; D_loss_gauss: 0.05448; G_loss: 14.1, reco_loss: 0.1291\n",
      "the 3-th batch at \n",
      "Epoch-102; D_loss_cat: 0.422; D_loss_gauss: 0.05284; G_loss: 11.77, reco_loss: 0.13\n",
      "the 4-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4368; D_loss_gauss: 0.06232; G_loss: 9.006, reco_loss: 0.1298\n",
      "the 5-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4421; D_loss_gauss: 0.1177; G_loss: 7.119, reco_loss: 0.131\n",
      "the 6-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4432; D_loss_gauss: 0.2282; G_loss: 5.896, reco_loss: 0.1354\n",
      "the 7-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4541; D_loss_gauss: 0.4489; G_loss: 4.482, reco_loss: 0.1325\n",
      "the 8-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4411; D_loss_gauss: 0.8668; G_loss: 3.661, reco_loss: 0.1357\n",
      "the 9-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4373; D_loss_gauss: 1.367; G_loss: 3.33, reco_loss: 0.1352\n",
      "the 10-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4551; D_loss_gauss: 1.521; G_loss: 3.16, reco_loss: 0.1397\n",
      "the 11-th batch at \n",
      "Epoch-102; D_loss_cat: 0.4367; D_loss_gauss: 1.437; G_loss: 3.539, reco_loss: 0.1359\n",
      "Train accuracy: 8.005162 %\n",
      "the 0-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4652; D_loss_gauss: 1.276; G_loss: 4.487, reco_loss: 0.1359\n",
      "the 1-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4439; D_loss_gauss: 0.2309; G_loss: 8.174, reco_loss: 0.1228\n",
      "the 2-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4384; D_loss_gauss: 0.1227; G_loss: 11.04, reco_loss: 0.1237\n",
      "the 3-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4556; D_loss_gauss: 0.1189; G_loss: 13.7, reco_loss: 0.123\n",
      "the 4-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4336; D_loss_gauss: 0.1526; G_loss: 16.07, reco_loss: 0.1213\n",
      "the 5-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4446; D_loss_gauss: 0.1937; G_loss: 17.46, reco_loss: 0.1205\n",
      "the 6-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4276; D_loss_gauss: 0.2208; G_loss: 19.21, reco_loss: 0.1182\n",
      "the 7-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4561; D_loss_gauss: 0.2318; G_loss: 20.13, reco_loss: 0.1158\n",
      "the 8-th batch at \n",
      "Epoch-103; D_loss_cat: 0.442; D_loss_gauss: 0.2388; G_loss: 20.53, reco_loss: 0.1148\n",
      "the 9-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4434; D_loss_gauss: 0.2504; G_loss: 21.37, reco_loss: 0.1138\n",
      "the 10-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4494; D_loss_gauss: 0.2422; G_loss: 21.56, reco_loss: 0.1113\n",
      "the 11-th batch at \n",
      "Epoch-103; D_loss_cat: 0.4434; D_loss_gauss: 0.2223; G_loss: 21.59, reco_loss: 0.112\n",
      "Train accuracy: 8.045721333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4423; D_loss_gauss: 0.2248; G_loss: 21.48, reco_loss: 0.1266\n",
      "the 1-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4453; D_loss_gauss: 0.2069; G_loss: 21.06, reco_loss: 0.1075\n",
      "the 2-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4356; D_loss_gauss: 0.1884; G_loss: 20.57, reco_loss: 0.107\n",
      "the 3-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4498; D_loss_gauss: 0.1715; G_loss: 20.33, reco_loss: 0.1069\n",
      "the 4-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4222; D_loss_gauss: 0.1603; G_loss: 20.3, reco_loss: 0.106\n",
      "the 5-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4246; D_loss_gauss: 0.1427; G_loss: 19.5, reco_loss: 0.1059\n",
      "the 6-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4376; D_loss_gauss: 0.123; G_loss: 19.0, reco_loss: 0.1056\n",
      "the 7-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4384; D_loss_gauss: 0.1139; G_loss: 19.06, reco_loss: 0.105\n",
      "the 8-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4374; D_loss_gauss: 0.1069; G_loss: 18.49, reco_loss: 0.1047\n",
      "the 9-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4042; D_loss_gauss: 0.09627; G_loss: 18.36, reco_loss: 0.1045\n",
      "the 10-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4012; D_loss_gauss: 0.08429; G_loss: 18.26, reco_loss: 0.1035\n",
      "the 11-th batch at \n",
      "Epoch-104; D_loss_cat: 0.4023; D_loss_gauss: 0.08265; G_loss: 17.93, reco_loss: 0.1049\n",
      "Train accuracy: 8.083573 %\n",
      "the 0-th batch at \n",
      "Epoch-105; D_loss_cat: 0.3904; D_loss_gauss: 0.07575; G_loss: 17.01, reco_loss: 0.1237\n",
      "the 1-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4266; D_loss_gauss: 0.06908; G_loss: 16.09, reco_loss: 0.1317\n",
      "the 2-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4201; D_loss_gauss: 0.05985; G_loss: 13.88, reco_loss: 0.1283\n",
      "the 3-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4355; D_loss_gauss: 0.06193; G_loss: 11.79, reco_loss: 0.1291\n",
      "the 4-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4424; D_loss_gauss: 0.06049; G_loss: 9.854, reco_loss: 0.1275\n",
      "the 5-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4406; D_loss_gauss: 0.07755; G_loss: 7.973, reco_loss: 0.1279\n",
      "the 6-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4404; D_loss_gauss: 0.1364; G_loss: 6.245, reco_loss: 0.1301\n",
      "the 7-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4386; D_loss_gauss: 0.2809; G_loss: 4.992, reco_loss: 0.1302\n",
      "the 8-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4592; D_loss_gauss: 0.6154; G_loss: 3.872, reco_loss: 0.1323\n",
      "the 9-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4407; D_loss_gauss: 1.078; G_loss: 3.272, reco_loss: 0.1323\n",
      "the 10-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4661; D_loss_gauss: 1.477; G_loss: 2.967, reco_loss: 0.135\n",
      "the 11-th batch at \n",
      "Epoch-105; D_loss_cat: 0.4576; D_loss_gauss: 1.67; G_loss: 3.127, reco_loss: 0.1334\n",
      "Train accuracy: 8.007968333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4424; D_loss_gauss: 1.756; G_loss: 3.279, reco_loss: 0.1338\n",
      "the 1-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4743; D_loss_gauss: 0.5564; G_loss: 5.036, reco_loss: 0.117\n",
      "the 2-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4425; D_loss_gauss: 0.2012; G_loss: 7.802, reco_loss: 0.1185\n",
      "the 3-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4564; D_loss_gauss: 0.124; G_loss: 9.743, reco_loss: 0.1175\n",
      "the 4-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4539; D_loss_gauss: 0.1073; G_loss: 11.38, reco_loss: 0.1161\n",
      "the 5-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4513; D_loss_gauss: 0.1216; G_loss: 13.75, reco_loss: 0.1158\n",
      "the 6-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4516; D_loss_gauss: 0.1287; G_loss: 14.99, reco_loss: 0.1142\n",
      "the 7-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4286; D_loss_gauss: 0.1602; G_loss: 15.76, reco_loss: 0.113\n",
      "the 8-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4626; D_loss_gauss: 0.1724; G_loss: 16.76, reco_loss: 0.1102\n",
      "the 9-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4282; D_loss_gauss: 0.1817; G_loss: 17.68, reco_loss: 0.1098\n",
      "the 10-th batch at \n",
      "Epoch-106; D_loss_cat: 0.451; D_loss_gauss: 0.1877; G_loss: 17.93, reco_loss: 0.1082\n",
      "the 11-th batch at \n",
      "Epoch-106; D_loss_cat: 0.4594; D_loss_gauss: 0.1881; G_loss: 18.85, reco_loss: 0.1081\n",
      "Train accuracy: 8.050382333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4417; D_loss_gauss: 0.1933; G_loss: 19.64, reco_loss: 0.1251\n",
      "the 1-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4449; D_loss_gauss: 0.1918; G_loss: 19.74, reco_loss: 0.1055\n",
      "the 2-th batch at \n",
      "Epoch-107; D_loss_cat: 0.458; D_loss_gauss: 0.1707; G_loss: 19.42, reco_loss: 0.1059\n",
      "the 3-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4612; D_loss_gauss: 0.1723; G_loss: 20.2, reco_loss: 0.1058\n",
      "the 4-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4518; D_loss_gauss: 0.1666; G_loss: 20.12, reco_loss: 0.1047\n",
      "the 5-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4553; D_loss_gauss: 0.1532; G_loss: 19.38, reco_loss: 0.1038\n",
      "the 6-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4808; D_loss_gauss: 0.1396; G_loss: 20.27, reco_loss: 0.1034\n",
      "the 7-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4696; D_loss_gauss: 0.133; G_loss: 19.99, reco_loss: 0.1031\n",
      "the 8-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4479; D_loss_gauss: 0.1231; G_loss: 18.78, reco_loss: 0.1034\n",
      "the 9-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4551; D_loss_gauss: 0.1151; G_loss: 19.4, reco_loss: 0.1035\n",
      "the 10-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4315; D_loss_gauss: 0.09744; G_loss: 19.42, reco_loss: 0.1029\n",
      "the 11-th batch at \n",
      "Epoch-107; D_loss_cat: 0.4381; D_loss_gauss: 0.09649; G_loss: 18.57, reco_loss: 0.1018\n",
      "Train accuracy: 8.076779 %\n",
      "the 0-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4185; D_loss_gauss: 0.08679; G_loss: 18.42, reco_loss: 0.123\n",
      "the 1-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4282; D_loss_gauss: 0.07598; G_loss: 17.08, reco_loss: 0.1302\n",
      "the 2-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4534; D_loss_gauss: 0.07638; G_loss: 14.33, reco_loss: 0.1283\n",
      "the 3-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4335; D_loss_gauss: 0.07049; G_loss: 11.82, reco_loss: 0.1275\n",
      "the 4-th batch at \n",
      "Epoch-108; D_loss_cat: 0.43; D_loss_gauss: 0.07404; G_loss: 9.511, reco_loss: 0.1273\n",
      "the 5-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4576; D_loss_gauss: 0.1425; G_loss: 6.643, reco_loss: 0.1323\n",
      "the 6-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4594; D_loss_gauss: 0.3218; G_loss: 4.866, reco_loss: 0.1337\n",
      "the 7-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4626; D_loss_gauss: 0.6746; G_loss: 4.285, reco_loss: 0.1312\n",
      "the 8-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4582; D_loss_gauss: 1.287; G_loss: 3.354, reco_loss: 0.1338\n",
      "the 9-th batch at \n",
      "Epoch-108; D_loss_cat: 0.457; D_loss_gauss: 1.815; G_loss: 2.594, reco_loss: 0.1326\n",
      "the 10-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4674; D_loss_gauss: 2.001; G_loss: 2.95, reco_loss: 0.1332\n",
      "the 11-th batch at \n",
      "Epoch-108; D_loss_cat: 0.4637; D_loss_gauss: 1.994; G_loss: 3.151, reco_loss: 0.1336\n",
      "Train accuracy: 8.022203 %\n",
      "the 0-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4622; D_loss_gauss: 1.666; G_loss: 3.351, reco_loss: 0.1348\n",
      "the 1-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4558; D_loss_gauss: 0.3999; G_loss: 6.55, reco_loss: 0.1224\n",
      "the 2-th batch at \n",
      "Epoch-109; D_loss_cat: 0.453; D_loss_gauss: 0.1715; G_loss: 9.627, reco_loss: 0.1241\n",
      "the 3-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4411; D_loss_gauss: 0.1637; G_loss: 11.73, reco_loss: 0.1227\n",
      "the 4-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4191; D_loss_gauss: 0.184; G_loss: 13.72, reco_loss: 0.1214\n",
      "the 5-th batch at \n",
      "Epoch-109; D_loss_cat: 0.456; D_loss_gauss: 0.2177; G_loss: 15.32, reco_loss: 0.1197\n",
      "the 6-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4377; D_loss_gauss: 0.25; G_loss: 16.75, reco_loss: 0.1174\n",
      "the 7-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4303; D_loss_gauss: 0.2549; G_loss: 18.07, reco_loss: 0.1161\n",
      "the 8-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4535; D_loss_gauss: 0.2767; G_loss: 18.86, reco_loss: 0.1138\n",
      "the 9-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4293; D_loss_gauss: 0.2619; G_loss: 19.38, reco_loss: 0.1122\n",
      "the 10-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4335; D_loss_gauss: 0.289; G_loss: 19.65, reco_loss: 0.1107\n",
      "the 11-th batch at \n",
      "Epoch-109; D_loss_cat: 0.4543; D_loss_gauss: 0.2779; G_loss: 19.51, reco_loss: 0.1092\n",
      "Train accuracy: 8.028523 %\n",
      "the 0-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4398; D_loss_gauss: 0.2714; G_loss: 20.02, reco_loss: 0.127\n",
      "the 1-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4586; D_loss_gauss: 0.2636; G_loss: 19.94, reco_loss: 0.1072\n",
      "the 2-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4565; D_loss_gauss: 0.2537; G_loss: 19.36, reco_loss: 0.1054\n",
      "the 3-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4375; D_loss_gauss: 0.2288; G_loss: 19.31, reco_loss: 0.1062\n",
      "the 4-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4499; D_loss_gauss: 0.2018; G_loss: 18.91, reco_loss: 0.105\n",
      "the 5-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4436; D_loss_gauss: 0.1939; G_loss: 18.65, reco_loss: 0.1047\n",
      "the 6-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4311; D_loss_gauss: 0.1717; G_loss: 18.37, reco_loss: 0.1046\n",
      "the 7-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4348; D_loss_gauss: 0.1508; G_loss: 18.0, reco_loss: 0.1041\n",
      "the 8-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4407; D_loss_gauss: 0.143; G_loss: 17.66, reco_loss: 0.1028\n",
      "the 9-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4227; D_loss_gauss: 0.1307; G_loss: 17.61, reco_loss: 0.103\n",
      "the 10-th batch at \n",
      "Epoch-110; D_loss_cat: 0.4128; D_loss_gauss: 0.1163; G_loss: 17.62, reco_loss: 0.1035\n",
      "the 11-th batch at \n",
      "Epoch-110; D_loss_cat: 0.425; D_loss_gauss: 0.1108; G_loss: 17.17, reco_loss: 0.1022\n",
      "Train accuracy: 8.079205333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4134; D_loss_gauss: 0.1059; G_loss: 16.44, reco_loss: 0.1242\n",
      "the 1-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4413; D_loss_gauss: 0.09693; G_loss: 15.6, reco_loss: 0.1317\n",
      "the 2-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4478; D_loss_gauss: 0.08836; G_loss: 13.66, reco_loss: 0.1293\n",
      "the 3-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4305; D_loss_gauss: 0.0845; G_loss: 11.06, reco_loss: 0.1278\n",
      "the 4-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4677; D_loss_gauss: 0.0868; G_loss: 8.935, reco_loss: 0.1291\n",
      "the 5-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4583; D_loss_gauss: 0.1344; G_loss: 7.235, reco_loss: 0.1278\n",
      "the 6-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4418; D_loss_gauss: 0.2315; G_loss: 5.8, reco_loss: 0.1322\n",
      "the 7-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4711; D_loss_gauss: 0.4037; G_loss: 4.549, reco_loss: 0.13\n",
      "the 8-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4435; D_loss_gauss: 0.6831; G_loss: 3.97, reco_loss: 0.1312\n",
      "the 9-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4613; D_loss_gauss: 1.129; G_loss: 3.065, reco_loss: 0.1311\n",
      "the 10-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4559; D_loss_gauss: 1.548; G_loss: 2.713, reco_loss: 0.1326\n",
      "the 11-th batch at \n",
      "Epoch-111; D_loss_cat: 0.4574; D_loss_gauss: 1.72; G_loss: 3.073, reco_loss: 0.1334\n",
      "Train accuracy: 8.011937000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4662; D_loss_gauss: 1.765; G_loss: 3.083, reco_loss: 0.1315\n",
      "the 1-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4568; D_loss_gauss: 0.7142; G_loss: 4.442, reco_loss: 0.1201\n",
      "the 2-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4404; D_loss_gauss: 0.3137; G_loss: 6.296, reco_loss: 0.1191\n",
      "the 3-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4317; D_loss_gauss: 0.1751; G_loss: 7.943, reco_loss: 0.1168\n",
      "the 4-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4443; D_loss_gauss: 0.136; G_loss: 9.293, reco_loss: 0.1168\n",
      "the 5-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4354; D_loss_gauss: 0.1239; G_loss: 11.26, reco_loss: 0.1142\n",
      "the 6-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4508; D_loss_gauss: 0.1348; G_loss: 12.85, reco_loss: 0.1128\n",
      "the 7-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4215; D_loss_gauss: 0.143; G_loss: 14.11, reco_loss: 0.111\n",
      "the 8-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4366; D_loss_gauss: 0.1558; G_loss: 14.86, reco_loss: 0.1111\n",
      "the 9-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4441; D_loss_gauss: 0.1679; G_loss: 15.82, reco_loss: 0.1087\n",
      "the 10-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4478; D_loss_gauss: 0.17; G_loss: 16.59, reco_loss: 0.1074\n",
      "the 11-th batch at \n",
      "Epoch-112; D_loss_cat: 0.4465; D_loss_gauss: 0.1647; G_loss: 17.25, reco_loss: 0.1077\n",
      "Train accuracy: 8.0592 %\n",
      "the 0-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4382; D_loss_gauss: 0.1716; G_loss: 17.78, reco_loss: 0.1249\n",
      "the 1-th batch at \n",
      "Epoch-113; D_loss_cat: 0.429; D_loss_gauss: 0.1815; G_loss: 18.19, reco_loss: 0.1057\n",
      "the 2-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4204; D_loss_gauss: 0.1831; G_loss: 18.26, reco_loss: 0.1045\n",
      "the 3-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4319; D_loss_gauss: 0.168; G_loss: 18.26, reco_loss: 0.105\n",
      "the 4-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4455; D_loss_gauss: 0.17; G_loss: 18.47, reco_loss: 0.1038\n",
      "the 5-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4443; D_loss_gauss: 0.1509; G_loss: 18.65, reco_loss: 0.1021\n",
      "the 6-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4229; D_loss_gauss: 0.1428; G_loss: 18.53, reco_loss: 0.1025\n",
      "the 7-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4352; D_loss_gauss: 0.1415; G_loss: 18.29, reco_loss: 0.1029\n",
      "the 8-th batch at \n",
      "Epoch-113; D_loss_cat: 0.427; D_loss_gauss: 0.1319; G_loss: 18.18, reco_loss: 0.1019\n",
      "the 9-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4265; D_loss_gauss: 0.1123; G_loss: 18.16, reco_loss: 0.1019\n",
      "the 10-th batch at \n",
      "Epoch-113; D_loss_cat: 0.413; D_loss_gauss: 0.117; G_loss: 18.27, reco_loss: 0.102\n",
      "the 11-th batch at \n",
      "Epoch-113; D_loss_cat: 0.4047; D_loss_gauss: 0.1092; G_loss: 18.26, reco_loss: 0.1012\n",
      "Train accuracy: 8.086669666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4064; D_loss_gauss: 0.09571; G_loss: 17.4, reco_loss: 0.1217\n",
      "the 1-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4115; D_loss_gauss: 0.09747; G_loss: 16.47, reco_loss: 0.1268\n",
      "the 2-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4368; D_loss_gauss: 0.08217; G_loss: 14.53, reco_loss: 0.1277\n",
      "the 3-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4413; D_loss_gauss: 0.07824; G_loss: 11.85, reco_loss: 0.1246\n",
      "the 4-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4617; D_loss_gauss: 0.07822; G_loss: 9.814, reco_loss: 0.1261\n",
      "the 5-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4537; D_loss_gauss: 0.1172; G_loss: 7.474, reco_loss: 0.1261\n",
      "the 6-th batch at \n",
      "Epoch-114; D_loss_cat: 0.448; D_loss_gauss: 0.2378; G_loss: 5.314, reco_loss: 0.1293\n",
      "the 7-th batch at \n",
      "Epoch-114; D_loss_cat: 0.461; D_loss_gauss: 0.5402; G_loss: 4.263, reco_loss: 0.1309\n",
      "the 8-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4652; D_loss_gauss: 1.025; G_loss: 3.394, reco_loss: 0.1306\n",
      "the 9-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4555; D_loss_gauss: 1.646; G_loss: 2.685, reco_loss: 0.1308\n",
      "the 10-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4555; D_loss_gauss: 2.032; G_loss: 2.888, reco_loss: 0.132\n",
      "the 11-th batch at \n",
      "Epoch-114; D_loss_cat: 0.4704; D_loss_gauss: 2.186; G_loss: 2.788, reco_loss: 0.1318\n",
      "Train accuracy: 7.986980999999999 %\n",
      "the 0-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4632; D_loss_gauss: 2.087; G_loss: 2.852, reco_loss: 0.1336\n",
      "the 1-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4411; D_loss_gauss: 0.6457; G_loss: 5.207, reco_loss: 0.1162\n",
      "the 2-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4394; D_loss_gauss: 0.2227; G_loss: 7.806, reco_loss: 0.1166\n",
      "the 3-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4443; D_loss_gauss: 0.15; G_loss: 10.06, reco_loss: 0.116\n",
      "the 4-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4343; D_loss_gauss: 0.1673; G_loss: 12.27, reco_loss: 0.1152\n",
      "the 5-th batch at \n",
      "Epoch-115; D_loss_cat: 0.427; D_loss_gauss: 0.199; G_loss: 14.07, reco_loss: 0.1134\n",
      "the 6-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4424; D_loss_gauss: 0.2323; G_loss: 15.13, reco_loss: 0.1129\n",
      "the 7-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4319; D_loss_gauss: 0.2447; G_loss: 16.84, reco_loss: 0.111\n",
      "the 8-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4206; D_loss_gauss: 0.2717; G_loss: 17.86, reco_loss: 0.1094\n",
      "the 9-th batch at \n",
      "Epoch-115; D_loss_cat: 0.423; D_loss_gauss: 0.2775; G_loss: 18.41, reco_loss: 0.1074\n",
      "the 10-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4318; D_loss_gauss: 0.2768; G_loss: 19.26, reco_loss: 0.1074\n",
      "the 11-th batch at \n",
      "Epoch-115; D_loss_cat: 0.4176; D_loss_gauss: 0.2821; G_loss: 19.95, reco_loss: 0.1058\n",
      "Train accuracy: 8.064840666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-116; D_loss_cat: 0.4008; D_loss_gauss: 0.2552; G_loss: 20.06, reco_loss: 0.1239\n",
      "the 1-th batch at \n",
      "Epoch-116; D_loss_cat: 0.4144; D_loss_gauss: 0.2558; G_loss: 19.81, reco_loss: 0.104\n",
      "the 2-th batch at \n",
      "Epoch-116; D_loss_cat: 0.4154; D_loss_gauss: 0.2533; G_loss: 20.35, reco_loss: 0.1032\n",
      "the 3-th batch at \n",
      "Epoch-116; D_loss_cat: 0.4197; D_loss_gauss: 0.2366; G_loss: 20.33, reco_loss: 0.1032\n",
      "the 4-th batch at \n",
      "Epoch-116; D_loss_cat: 0.4082; D_loss_gauss: 0.2095; G_loss: 19.76, reco_loss: 0.1036\n",
      "the 5-th batch at \n",
      "Epoch-116; D_loss_cat: 0.4328; D_loss_gauss: 0.1999; G_loss: 20.24, reco_loss: 0.102\n",
      "the 6-th batch at \n",
      "Epoch-116; D_loss_cat: 0.3939; D_loss_gauss: 0.1873; G_loss: 20.36, reco_loss: 0.1029\n",
      "the 7-th batch at \n",
      "Epoch-116; D_loss_cat: 0.4238; D_loss_gauss: 0.1767; G_loss: 19.63, reco_loss: 0.1013\n",
      "the 8-th batch at \n",
      "Epoch-116; D_loss_cat: 0.3982; D_loss_gauss: 0.1736; G_loss: 19.55, reco_loss: 0.1013\n",
      "the 9-th batch at \n",
      "Epoch-116; D_loss_cat: 0.3958; D_loss_gauss: 0.1475; G_loss: 19.61, reco_loss: 0.1013\n",
      "the 10-th batch at \n",
      "Epoch-116; D_loss_cat: 0.3869; D_loss_gauss: 0.1395; G_loss: 19.21, reco_loss: 0.1012\n",
      "the 11-th batch at \n",
      "Epoch-116; D_loss_cat: 0.3755; D_loss_gauss: 0.1199; G_loss: 18.87, reco_loss: 0.1006\n",
      "Train accuracy: 8.102734333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-117; D_loss_cat: 0.3872; D_loss_gauss: 0.1136; G_loss: 18.28, reco_loss: 0.1211\n",
      "the 1-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4099; D_loss_gauss: 0.109; G_loss: 16.94, reco_loss: 0.1289\n",
      "the 2-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4079; D_loss_gauss: 0.09855; G_loss: 14.98, reco_loss: 0.126\n",
      "the 3-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4332; D_loss_gauss: 0.0969; G_loss: 12.42, reco_loss: 0.1261\n",
      "the 4-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4325; D_loss_gauss: 0.08679; G_loss: 10.21, reco_loss: 0.1259\n",
      "the 5-th batch at \n",
      "Epoch-117; D_loss_cat: 0.454; D_loss_gauss: 0.106; G_loss: 8.031, reco_loss: 0.1258\n",
      "the 6-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4434; D_loss_gauss: 0.159; G_loss: 6.4, reco_loss: 0.1299\n",
      "the 7-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4574; D_loss_gauss: 0.3107; G_loss: 5.173, reco_loss: 0.1281\n",
      "the 8-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4451; D_loss_gauss: 0.5724; G_loss: 4.032, reco_loss: 0.1288\n",
      "the 9-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4537; D_loss_gauss: 1.038; G_loss: 3.258, reco_loss: 0.1298\n",
      "the 10-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4342; D_loss_gauss: 1.485; G_loss: 3.163, reco_loss: 0.1329\n",
      "the 11-th batch at \n",
      "Epoch-117; D_loss_cat: 0.4563; D_loss_gauss: 1.678; G_loss: 2.827, reco_loss: 0.1301\n",
      "Train accuracy: 8.014039333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4671; D_loss_gauss: 1.792; G_loss: 3.128, reco_loss: 0.132\n",
      "the 1-th batch at \n",
      "Epoch-118; D_loss_cat: 0.428; D_loss_gauss: 0.6519; G_loss: 5.071, reco_loss: 0.1182\n",
      "the 2-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4306; D_loss_gauss: 0.2741; G_loss: 6.527, reco_loss: 0.1203\n",
      "the 3-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4305; D_loss_gauss: 0.1837; G_loss: 8.318, reco_loss: 0.1183\n",
      "the 4-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4159; D_loss_gauss: 0.1538; G_loss: 10.27, reco_loss: 0.1178\n",
      "the 5-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4223; D_loss_gauss: 0.169; G_loss: 11.52, reco_loss: 0.1158\n",
      "the 6-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4058; D_loss_gauss: 0.1756; G_loss: 12.78, reco_loss: 0.1148\n",
      "the 7-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4087; D_loss_gauss: 0.1938; G_loss: 14.24, reco_loss: 0.1134\n",
      "the 8-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4331; D_loss_gauss: 0.2012; G_loss: 15.16, reco_loss: 0.1106\n",
      "the 9-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4338; D_loss_gauss: 0.2238; G_loss: 15.62, reco_loss: 0.1082\n",
      "the 10-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4297; D_loss_gauss: 0.2036; G_loss: 16.52, reco_loss: 0.1077\n",
      "the 11-th batch at \n",
      "Epoch-118; D_loss_cat: 0.4567; D_loss_gauss: 0.2093; G_loss: 16.86, reco_loss: 0.1078\n",
      "Train accuracy: 8.053874333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4233; D_loss_gauss: 0.2126; G_loss: 17.21, reco_loss: 0.1247\n",
      "the 1-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4246; D_loss_gauss: 0.2148; G_loss: 17.37, reco_loss: 0.1045\n",
      "the 2-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4201; D_loss_gauss: 0.1987; G_loss: 17.46, reco_loss: 0.1038\n",
      "the 3-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4194; D_loss_gauss: 0.1697; G_loss: 17.79, reco_loss: 0.1034\n",
      "the 4-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4052; D_loss_gauss: 0.1711; G_loss: 17.81, reco_loss: 0.1034\n",
      "the 5-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4276; D_loss_gauss: 0.1629; G_loss: 17.41, reco_loss: 0.1025\n",
      "the 6-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4011; D_loss_gauss: 0.1431; G_loss: 17.6, reco_loss: 0.1026\n",
      "the 7-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4085; D_loss_gauss: 0.1416; G_loss: 17.46, reco_loss: 0.1021\n",
      "the 8-th batch at \n",
      "Epoch-119; D_loss_cat: 0.4038; D_loss_gauss: 0.121; G_loss: 17.21, reco_loss: 0.1007\n",
      "the 9-th batch at \n",
      "Epoch-119; D_loss_cat: 0.3946; D_loss_gauss: 0.117; G_loss: 17.18, reco_loss: 0.1016\n",
      "the 10-th batch at \n",
      "Epoch-119; D_loss_cat: 0.3963; D_loss_gauss: 0.107; G_loss: 17.22, reco_loss: 0.102\n",
      "the 11-th batch at \n",
      "Epoch-119; D_loss_cat: 0.3981; D_loss_gauss: 0.09804; G_loss: 16.97, reco_loss: 0.1012\n",
      "Train accuracy: 8.081748333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4081; D_loss_gauss: 0.08679; G_loss: 15.81, reco_loss: 0.1216\n",
      "the 1-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4133; D_loss_gauss: 0.0822; G_loss: 14.89, reco_loss: 0.1284\n",
      "the 2-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4384; D_loss_gauss: 0.08451; G_loss: 13.05, reco_loss: 0.1297\n",
      "the 3-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4448; D_loss_gauss: 0.07803; G_loss: 10.6, reco_loss: 0.1258\n",
      "the 4-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4469; D_loss_gauss: 0.08741; G_loss: 8.909, reco_loss: 0.1264\n",
      "the 5-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4566; D_loss_gauss: 0.1498; G_loss: 6.692, reco_loss: 0.1266\n",
      "the 6-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4577; D_loss_gauss: 0.2761; G_loss: 5.117, reco_loss: 0.128\n",
      "the 7-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4542; D_loss_gauss: 0.5087; G_loss: 4.47, reco_loss: 0.1278\n",
      "the 8-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4523; D_loss_gauss: 0.8585; G_loss: 3.514, reco_loss: 0.1297\n",
      "the 9-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4641; D_loss_gauss: 1.282; G_loss: 3.004, reco_loss: 0.1304\n",
      "the 10-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4606; D_loss_gauss: 1.441; G_loss: 3.687, reco_loss: 0.1322\n",
      "the 11-th batch at \n",
      "Epoch-120; D_loss_cat: 0.4699; D_loss_gauss: 1.406; G_loss: 3.39, reco_loss: 0.1313\n",
      "Train accuracy: 8.011063333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4603; D_loss_gauss: 1.227; G_loss: 3.925, reco_loss: 0.132\n",
      "the 1-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4558; D_loss_gauss: 0.3027; G_loss: 7.574, reco_loss: 0.1184\n",
      "the 2-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4582; D_loss_gauss: 0.1382; G_loss: 10.31, reco_loss: 0.1176\n",
      "the 3-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4539; D_loss_gauss: 0.135; G_loss: 12.96, reco_loss: 0.1174\n",
      "the 4-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4575; D_loss_gauss: 0.1532; G_loss: 15.99, reco_loss: 0.1159\n",
      "the 5-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4573; D_loss_gauss: 0.1726; G_loss: 17.68, reco_loss: 0.1141\n",
      "the 6-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4291; D_loss_gauss: 0.2045; G_loss: 18.98, reco_loss: 0.1133\n",
      "the 7-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4467; D_loss_gauss: 0.2172; G_loss: 20.77, reco_loss: 0.1111\n",
      "the 8-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4562; D_loss_gauss: 0.22; G_loss: 21.7, reco_loss: 0.1094\n",
      "the 9-th batch at \n",
      "Epoch-121; D_loss_cat: 0.438; D_loss_gauss: 0.2297; G_loss: 22.08, reco_loss: 0.1094\n",
      "the 10-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4429; D_loss_gauss: 0.2264; G_loss: 22.75, reco_loss: 0.1078\n",
      "the 11-th batch at \n",
      "Epoch-121; D_loss_cat: 0.4421; D_loss_gauss: 0.2174; G_loss: 22.75, reco_loss: 0.1059\n",
      "Train accuracy: 8.036689666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4356; D_loss_gauss: 0.1957; G_loss: 22.36, reco_loss: 0.1238\n",
      "the 1-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4351; D_loss_gauss: 0.1909; G_loss: 22.59, reco_loss: 0.1045\n",
      "the 2-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4412; D_loss_gauss: 0.1666; G_loss: 22.24, reco_loss: 0.1029\n",
      "the 3-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4337; D_loss_gauss: 0.16; G_loss: 21.87, reco_loss: 0.1031\n",
      "the 4-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4409; D_loss_gauss: 0.1454; G_loss: 22.3, reco_loss: 0.1024\n",
      "the 5-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4481; D_loss_gauss: 0.1277; G_loss: 21.83, reco_loss: 0.1022\n",
      "the 6-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4347; D_loss_gauss: 0.1223; G_loss: 21.09, reco_loss: 0.1022\n",
      "the 7-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4348; D_loss_gauss: 0.1139; G_loss: 21.63, reco_loss: 0.1014\n",
      "the 8-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4331; D_loss_gauss: 0.1023; G_loss: 21.2, reco_loss: 0.1011\n",
      "the 9-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4428; D_loss_gauss: 0.09973; G_loss: 20.27, reco_loss: 0.1008\n",
      "the 10-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4419; D_loss_gauss: 0.08491; G_loss: 21.32, reco_loss: 0.1012\n",
      "the 11-th batch at \n",
      "Epoch-122; D_loss_cat: 0.4724; D_loss_gauss: 0.08516; G_loss: 20.87, reco_loss: 0.09926\n",
      "Train accuracy: 8.072380333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4311; D_loss_gauss: 0.07578; G_loss: 18.92, reco_loss: 0.1213\n",
      "the 1-th batch at \n",
      "Epoch-123; D_loss_cat: 0.484; D_loss_gauss: 0.07127; G_loss: 18.69, reco_loss: 0.1277\n",
      "the 2-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4814; D_loss_gauss: 0.06352; G_loss: 16.0, reco_loss: 0.1247\n",
      "the 3-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4589; D_loss_gauss: 0.05897; G_loss: 12.1, reco_loss: 0.1267\n",
      "the 4-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4858; D_loss_gauss: 0.0648; G_loss: 9.818, reco_loss: 0.1256\n",
      "the 5-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4508; D_loss_gauss: 0.1056; G_loss: 7.69, reco_loss: 0.1256\n",
      "the 6-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4632; D_loss_gauss: 0.2072; G_loss: 5.396, reco_loss: 0.1299\n",
      "the 7-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4412; D_loss_gauss: 0.4053; G_loss: 4.58, reco_loss: 0.129\n",
      "the 8-th batch at \n",
      "Epoch-123; D_loss_cat: 0.445; D_loss_gauss: 0.6957; G_loss: 3.995, reco_loss: 0.1312\n",
      "the 9-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4564; D_loss_gauss: 1.086; G_loss: 3.162, reco_loss: 0.13\n",
      "the 10-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4541; D_loss_gauss: 1.415; G_loss: 2.964, reco_loss: 0.1304\n",
      "the 11-th batch at \n",
      "Epoch-123; D_loss_cat: 0.4634; D_loss_gauss: 1.56; G_loss: 3.061, reco_loss: 0.1318\n",
      "Train accuracy: 8.009187 %\n",
      "the 0-th batch at \n",
      "Epoch-124; D_loss_cat: 0.443; D_loss_gauss: 1.6; G_loss: 3.271, reco_loss: 0.1319\n",
      "the 1-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4617; D_loss_gauss: 0.627; G_loss: 4.706, reco_loss: 0.1148\n",
      "the 2-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4497; D_loss_gauss: 0.2624; G_loss: 6.905, reco_loss: 0.1132\n",
      "the 3-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4592; D_loss_gauss: 0.1615; G_loss: 8.474, reco_loss: 0.1139\n",
      "the 4-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4567; D_loss_gauss: 0.1274; G_loss: 9.898, reco_loss: 0.1138\n",
      "the 5-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4555; D_loss_gauss: 0.1348; G_loss: 11.87, reco_loss: 0.1117\n",
      "the 6-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4349; D_loss_gauss: 0.1359; G_loss: 13.27, reco_loss: 0.1096\n",
      "the 7-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4437; D_loss_gauss: 0.155; G_loss: 13.95, reco_loss: 0.109\n",
      "the 8-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4503; D_loss_gauss: 0.1581; G_loss: 14.8, reco_loss: 0.1079\n",
      "the 9-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4577; D_loss_gauss: 0.1696; G_loss: 15.87, reco_loss: 0.1067\n",
      "the 10-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4505; D_loss_gauss: 0.1654; G_loss: 16.45, reco_loss: 0.1056\n",
      "the 11-th batch at \n",
      "Epoch-124; D_loss_cat: 0.4524; D_loss_gauss: 0.1655; G_loss: 17.09, reco_loss: 0.1045\n",
      "Train accuracy: 8.062339 %\n",
      "the 0-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4478; D_loss_gauss: 0.1706; G_loss: 17.71, reco_loss: 0.1232\n",
      "the 1-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4485; D_loss_gauss: 0.1649; G_loss: 18.01, reco_loss: 0.1029\n",
      "the 2-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4222; D_loss_gauss: 0.1596; G_loss: 18.04, reco_loss: 0.1026\n",
      "the 3-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4438; D_loss_gauss: 0.1564; G_loss: 18.12, reco_loss: 0.1017\n",
      "the 4-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4414; D_loss_gauss: 0.1442; G_loss: 18.61, reco_loss: 0.1013\n",
      "the 5-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4363; D_loss_gauss: 0.1402; G_loss: 18.78, reco_loss: 0.1022\n",
      "the 6-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4235; D_loss_gauss: 0.1288; G_loss: 18.71, reco_loss: 0.101\n",
      "the 7-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4239; D_loss_gauss: 0.1202; G_loss: 18.62, reco_loss: 0.1002\n",
      "the 8-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4195; D_loss_gauss: 0.1043; G_loss: 18.32, reco_loss: 0.1005\n",
      "the 9-th batch at \n",
      "Epoch-125; D_loss_cat: 0.3935; D_loss_gauss: 0.106; G_loss: 18.31, reco_loss: 0.09952\n",
      "the 10-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4116; D_loss_gauss: 0.09824; G_loss: 18.31, reco_loss: 0.09815\n",
      "the 11-th batch at \n",
      "Epoch-125; D_loss_cat: 0.4125; D_loss_gauss: 0.08787; G_loss: 18.26, reco_loss: 0.09914\n",
      "Train accuracy: 8.087001333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-126; D_loss_cat: 0.3972; D_loss_gauss: 0.08779; G_loss: 17.18, reco_loss: 0.1194\n",
      "the 1-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4225; D_loss_gauss: 0.0737; G_loss: 15.89, reco_loss: 0.1271\n",
      "the 2-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4364; D_loss_gauss: 0.07197; G_loss: 13.88, reco_loss: 0.1287\n",
      "the 3-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4415; D_loss_gauss: 0.07588; G_loss: 11.36, reco_loss: 0.1267\n",
      "the 4-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4673; D_loss_gauss: 0.09057; G_loss: 8.655, reco_loss: 0.1278\n",
      "the 5-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4505; D_loss_gauss: 0.1509; G_loss: 6.845, reco_loss: 0.1292\n",
      "the 6-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4601; D_loss_gauss: 0.3128; G_loss: 5.208, reco_loss: 0.131\n",
      "the 7-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4702; D_loss_gauss: 0.5835; G_loss: 3.949, reco_loss: 0.131\n",
      "the 8-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4681; D_loss_gauss: 1.004; G_loss: 3.27, reco_loss: 0.1321\n",
      "the 9-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4465; D_loss_gauss: 1.486; G_loss: 3.159, reco_loss: 0.1318\n",
      "the 10-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4664; D_loss_gauss: 1.693; G_loss: 2.897, reco_loss: 0.1357\n",
      "the 11-th batch at \n",
      "Epoch-126; D_loss_cat: 0.4774; D_loss_gauss: 1.695; G_loss: 3.264, reco_loss: 0.134\n",
      "Train accuracy: 7.992046333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4437; D_loss_gauss: 1.464; G_loss: 4.547, reco_loss: 0.1331\n",
      "the 1-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4768; D_loss_gauss: 0.311; G_loss: 7.569, reco_loss: 0.1198\n",
      "the 2-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4545; D_loss_gauss: 0.1658; G_loss: 10.75, reco_loss: 0.1211\n",
      "the 3-th batch at \n",
      "Epoch-127; D_loss_cat: 0.455; D_loss_gauss: 0.1767; G_loss: 13.88, reco_loss: 0.1176\n",
      "the 4-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4466; D_loss_gauss: 0.2269; G_loss: 15.84, reco_loss: 0.1165\n",
      "the 5-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4348; D_loss_gauss: 0.2565; G_loss: 17.11, reco_loss: 0.1164\n",
      "the 6-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4506; D_loss_gauss: 0.284; G_loss: 19.11, reco_loss: 0.1153\n",
      "the 7-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4577; D_loss_gauss: 0.3101; G_loss: 19.9, reco_loss: 0.1121\n",
      "the 8-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4293; D_loss_gauss: 0.312; G_loss: 20.29, reco_loss: 0.1094\n",
      "the 9-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4395; D_loss_gauss: 0.3062; G_loss: 20.9, reco_loss: 0.109\n",
      "the 10-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4336; D_loss_gauss: 0.2942; G_loss: 21.52, reco_loss: 0.1087\n",
      "the 11-th batch at \n",
      "Epoch-127; D_loss_cat: 0.4362; D_loss_gauss: 0.2759; G_loss: 21.65, reco_loss: 0.1074\n",
      "Train accuracy: 8.051405666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4388; D_loss_gauss: 0.2617; G_loss: 21.04, reco_loss: 0.1239\n",
      "the 1-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4306; D_loss_gauss: 0.2592; G_loss: 20.77, reco_loss: 0.1045\n",
      "the 2-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4373; D_loss_gauss: 0.2293; G_loss: 20.91, reco_loss: 0.1045\n",
      "the 3-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4365; D_loss_gauss: 0.214; G_loss: 20.4, reco_loss: 0.103\n",
      "the 4-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4188; D_loss_gauss: 0.1869; G_loss: 19.93, reco_loss: 0.1023\n",
      "the 5-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4128; D_loss_gauss: 0.1721; G_loss: 19.75, reco_loss: 0.1015\n",
      "the 6-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4107; D_loss_gauss: 0.1639; G_loss: 19.15, reco_loss: 0.1024\n",
      "the 7-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4259; D_loss_gauss: 0.1461; G_loss: 18.76, reco_loss: 0.1014\n",
      "the 8-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4266; D_loss_gauss: 0.1371; G_loss: 18.78, reco_loss: 0.1002\n",
      "the 9-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4023; D_loss_gauss: 0.1205; G_loss: 18.92, reco_loss: 0.1001\n",
      "the 10-th batch at \n",
      "Epoch-128; D_loss_cat: 0.4114; D_loss_gauss: 0.1128; G_loss: 18.46, reco_loss: 0.1011\n",
      "the 11-th batch at \n",
      "Epoch-128; D_loss_cat: 0.408; D_loss_gauss: 0.1063; G_loss: 18.05, reco_loss: 0.09965\n",
      "Train accuracy: 8.080587666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4153; D_loss_gauss: 0.09223; G_loss: 16.98, reco_loss: 0.1212\n",
      "the 1-th batch at \n",
      "Epoch-129; D_loss_cat: 0.3976; D_loss_gauss: 0.08198; G_loss: 15.99, reco_loss: 0.1274\n",
      "the 2-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4334; D_loss_gauss: 0.07373; G_loss: 13.15, reco_loss: 0.1254\n",
      "the 3-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4284; D_loss_gauss: 0.07741; G_loss: 10.49, reco_loss: 0.126\n",
      "the 4-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4573; D_loss_gauss: 0.09279; G_loss: 8.475, reco_loss: 0.1263\n",
      "the 5-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4543; D_loss_gauss: 0.1861; G_loss: 6.116, reco_loss: 0.1272\n",
      "the 6-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4476; D_loss_gauss: 0.3854; G_loss: 4.518, reco_loss: 0.1309\n",
      "the 7-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4411; D_loss_gauss: 0.6295; G_loss: 4.124, reco_loss: 0.1297\n",
      "the 8-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4478; D_loss_gauss: 0.9465; G_loss: 3.476, reco_loss: 0.1304\n",
      "the 9-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4521; D_loss_gauss: 1.232; G_loss: 2.852, reco_loss: 0.1294\n",
      "the 10-th batch at \n",
      "Epoch-129; D_loss_cat: 0.465; D_loss_gauss: 1.354; G_loss: 3.285, reco_loss: 0.1311\n",
      "the 11-th batch at \n",
      "Epoch-129; D_loss_cat: 0.4491; D_loss_gauss: 1.411; G_loss: 3.339, reco_loss: 0.1292\n",
      "Train accuracy: 8.011159333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-130; D_loss_cat: 0.464; D_loss_gauss: 1.332; G_loss: 3.229, reco_loss: 0.1321\n",
      "the 1-th batch at \n",
      "Epoch-130; D_loss_cat: 0.45; D_loss_gauss: 0.5123; G_loss: 5.709, reco_loss: 0.1144\n",
      "the 2-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4319; D_loss_gauss: 0.2381; G_loss: 7.844, reco_loss: 0.1148\n",
      "the 3-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4645; D_loss_gauss: 0.1755; G_loss: 8.875, reco_loss: 0.1143\n",
      "the 4-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4555; D_loss_gauss: 0.1612; G_loss: 11.04, reco_loss: 0.1126\n",
      "the 5-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4299; D_loss_gauss: 0.1698; G_loss: 12.97, reco_loss: 0.1112\n",
      "the 6-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4493; D_loss_gauss: 0.1791; G_loss: 13.56, reco_loss: 0.1106\n",
      "the 7-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4474; D_loss_gauss: 0.2069; G_loss: 14.35, reco_loss: 0.1092\n",
      "the 8-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4463; D_loss_gauss: 0.2157; G_loss: 16.66, reco_loss: 0.1083\n",
      "the 9-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4723; D_loss_gauss: 0.2227; G_loss: 16.99, reco_loss: 0.106\n",
      "the 10-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4373; D_loss_gauss: 0.2271; G_loss: 16.63, reco_loss: 0.1059\n",
      "the 11-th batch at \n",
      "Epoch-130; D_loss_cat: 0.4337; D_loss_gauss: 0.2176; G_loss: 17.64, reco_loss: 0.1052\n",
      "Train accuracy: 8.074800333333334 %\n",
      "the 0-th batch at \n",
      "Epoch-131; D_loss_cat: 0.4098; D_loss_gauss: 0.2124; G_loss: 18.17, reco_loss: 0.1228\n",
      "the 1-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3979; D_loss_gauss: 0.2007; G_loss: 17.98, reco_loss: 0.1034\n",
      "the 2-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3912; D_loss_gauss: 0.1725; G_loss: 17.5, reco_loss: 0.1024\n",
      "the 3-th batch at \n",
      "Epoch-131; D_loss_cat: 0.4169; D_loss_gauss: 0.1753; G_loss: 18.06, reco_loss: 0.1024\n",
      "the 4-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3821; D_loss_gauss: 0.1624; G_loss: 18.22, reco_loss: 0.1016\n",
      "the 5-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3801; D_loss_gauss: 0.1496; G_loss: 17.88, reco_loss: 0.1003\n",
      "the 6-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3901; D_loss_gauss: 0.1355; G_loss: 17.34, reco_loss: 0.1009\n",
      "the 7-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3961; D_loss_gauss: 0.1347; G_loss: 17.68, reco_loss: 0.1002\n",
      "the 8-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3788; D_loss_gauss: 0.1249; G_loss: 17.74, reco_loss: 0.09937\n",
      "the 9-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3792; D_loss_gauss: 0.1099; G_loss: 17.17, reco_loss: 0.09909\n",
      "the 10-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3663; D_loss_gauss: 0.09887; G_loss: 17.14, reco_loss: 0.1001\n",
      "the 11-th batch at \n",
      "Epoch-131; D_loss_cat: 0.3761; D_loss_gauss: 0.09128; G_loss: 17.17, reco_loss: 0.09892\n",
      "Train accuracy: 8.097290000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-132; D_loss_cat: 0.3721; D_loss_gauss: 0.08889; G_loss: 15.82, reco_loss: 0.1195\n",
      "the 1-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4272; D_loss_gauss: 0.07843; G_loss: 13.96, reco_loss: 0.1278\n",
      "the 2-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4392; D_loss_gauss: 0.08977; G_loss: 12.02, reco_loss: 0.1283\n",
      "the 3-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4452; D_loss_gauss: 0.09372; G_loss: 9.573, reco_loss: 0.1268\n",
      "the 4-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4727; D_loss_gauss: 0.1476; G_loss: 6.725, reco_loss: 0.1284\n",
      "the 5-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4711; D_loss_gauss: 0.3077; G_loss: 5.369, reco_loss: 0.1309\n",
      "the 6-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4564; D_loss_gauss: 0.5895; G_loss: 4.651, reco_loss: 0.1327\n",
      "the 7-th batch at \n",
      "Epoch-132; D_loss_cat: 0.469; D_loss_gauss: 0.8669; G_loss: 3.87, reco_loss: 0.1311\n",
      "the 8-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4672; D_loss_gauss: 1.241; G_loss: 2.932, reco_loss: 0.1299\n",
      "the 9-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4672; D_loss_gauss: 1.456; G_loss: 3.078, reco_loss: 0.1319\n",
      "the 10-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4645; D_loss_gauss: 1.457; G_loss: 3.373, reco_loss: 0.1319\n",
      "the 11-th batch at \n",
      "Epoch-132; D_loss_cat: 0.4602; D_loss_gauss: 1.361; G_loss: 3.512, reco_loss: 0.1306\n",
      "Train accuracy: 7.996202666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4615; D_loss_gauss: 1.19; G_loss: 4.694, reco_loss: 0.1315\n",
      "the 1-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4512; D_loss_gauss: 0.2457; G_loss: 8.783, reco_loss: 0.1203\n",
      "the 2-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4678; D_loss_gauss: 0.1657; G_loss: 11.7, reco_loss: 0.1204\n",
      "the 3-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4599; D_loss_gauss: 0.2119; G_loss: 14.59, reco_loss: 0.1181\n",
      "the 4-th batch at \n",
      "Epoch-133; D_loss_cat: 0.454; D_loss_gauss: 0.246; G_loss: 17.14, reco_loss: 0.1158\n",
      "the 5-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4385; D_loss_gauss: 0.3045; G_loss: 18.98, reco_loss: 0.1148\n",
      "the 6-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4524; D_loss_gauss: 0.3156; G_loss: 20.25, reco_loss: 0.113\n",
      "the 7-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4634; D_loss_gauss: 0.3209; G_loss: 21.16, reco_loss: 0.1119\n",
      "the 8-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4589; D_loss_gauss: 0.3256; G_loss: 21.92, reco_loss: 0.11\n",
      "the 9-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4633; D_loss_gauss: 0.3015; G_loss: 22.42, reco_loss: 0.108\n",
      "the 10-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4527; D_loss_gauss: 0.3103; G_loss: 22.68, reco_loss: 0.106\n",
      "the 11-th batch at \n",
      "Epoch-133; D_loss_cat: 0.4343; D_loss_gauss: 0.2936; G_loss: 22.99, reco_loss: 0.1061\n",
      "Train accuracy: 8.055510666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-134; D_loss_cat: 0.446; D_loss_gauss: 0.2559; G_loss: 22.48, reco_loss: 0.125\n",
      "the 1-th batch at \n",
      "Epoch-134; D_loss_cat: 0.439; D_loss_gauss: 0.2337; G_loss: 21.98, reco_loss: 0.1036\n",
      "the 2-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4372; D_loss_gauss: 0.2116; G_loss: 21.62, reco_loss: 0.1039\n",
      "the 3-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4321; D_loss_gauss: 0.1862; G_loss: 21.52, reco_loss: 0.1023\n",
      "the 4-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4382; D_loss_gauss: 0.179; G_loss: 21.38, reco_loss: 0.1017\n",
      "the 5-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4281; D_loss_gauss: 0.1683; G_loss: 21.03, reco_loss: 0.1017\n",
      "the 6-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4457; D_loss_gauss: 0.1494; G_loss: 20.71, reco_loss: 0.1016\n",
      "the 7-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4522; D_loss_gauss: 0.132; G_loss: 20.22, reco_loss: 0.09996\n",
      "the 8-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4435; D_loss_gauss: 0.127; G_loss: 19.67, reco_loss: 0.0997\n",
      "the 9-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4417; D_loss_gauss: 0.1175; G_loss: 19.25, reco_loss: 0.1001\n",
      "the 10-th batch at \n",
      "Epoch-134; D_loss_cat: 0.43; D_loss_gauss: 0.1068; G_loss: 19.33, reco_loss: 0.09973\n",
      "the 11-th batch at \n",
      "Epoch-134; D_loss_cat: 0.4249; D_loss_gauss: 0.09301; G_loss: 19.11, reco_loss: 0.09933\n",
      "Train accuracy: 8.075868333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-135; D_loss_cat: 0.421; D_loss_gauss: 0.08712; G_loss: 17.55, reco_loss: 0.1204\n",
      "the 1-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4376; D_loss_gauss: 0.0827; G_loss: 15.78, reco_loss: 0.1344\n",
      "the 2-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4395; D_loss_gauss: 0.07823; G_loss: 13.19, reco_loss: 0.1301\n",
      "the 3-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4631; D_loss_gauss: 0.07706; G_loss: 9.91, reco_loss: 0.1277\n",
      "the 4-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4629; D_loss_gauss: 0.1082; G_loss: 7.451, reco_loss: 0.1282\n",
      "the 5-th batch at \n",
      "Epoch-135; D_loss_cat: 0.457; D_loss_gauss: 0.2659; G_loss: 5.414, reco_loss: 0.1303\n",
      "the 6-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4762; D_loss_gauss: 0.5552; G_loss: 3.866, reco_loss: 0.1344\n",
      "the 7-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4661; D_loss_gauss: 0.9514; G_loss: 3.118, reco_loss: 0.1307\n",
      "the 8-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4497; D_loss_gauss: 1.437; G_loss: 3.061, reco_loss: 0.134\n",
      "the 9-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4624; D_loss_gauss: 1.807; G_loss: 2.766, reco_loss: 0.133\n",
      "the 10-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4651; D_loss_gauss: 1.707; G_loss: 2.691, reco_loss: 0.1339\n",
      "the 11-th batch at \n",
      "Epoch-135; D_loss_cat: 0.4673; D_loss_gauss: 1.509; G_loss: 3.277, reco_loss: 0.1321\n",
      "Train accuracy: 8.007384333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4754; D_loss_gauss: 1.32; G_loss: 3.825, reco_loss: 0.1317\n",
      "the 1-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4528; D_loss_gauss: 0.4387; G_loss: 5.73, reco_loss: 0.1206\n",
      "the 2-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4596; D_loss_gauss: 0.2309; G_loss: 7.981, reco_loss: 0.1203\n",
      "the 3-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4493; D_loss_gauss: 0.1849; G_loss: 10.0, reco_loss: 0.1191\n",
      "the 4-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4447; D_loss_gauss: 0.1966; G_loss: 11.35, reco_loss: 0.1165\n",
      "the 5-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4511; D_loss_gauss: 0.219; G_loss: 12.64, reco_loss: 0.1163\n",
      "the 6-th batch at \n",
      "Epoch-136; D_loss_cat: 0.441; D_loss_gauss: 0.2372; G_loss: 14.29, reco_loss: 0.1132\n",
      "the 7-th batch at \n",
      "Epoch-136; D_loss_cat: 0.447; D_loss_gauss: 0.2621; G_loss: 15.12, reco_loss: 0.1112\n",
      "the 8-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4624; D_loss_gauss: 0.2701; G_loss: 15.35, reco_loss: 0.1096\n",
      "the 9-th batch at \n",
      "Epoch-136; D_loss_cat: 0.452; D_loss_gauss: 0.292; G_loss: 16.23, reco_loss: 0.1092\n",
      "the 10-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4566; D_loss_gauss: 0.2791; G_loss: 16.78, reco_loss: 0.1077\n",
      "the 11-th batch at \n",
      "Epoch-136; D_loss_cat: 0.4579; D_loss_gauss: 0.2726; G_loss: 16.53, reco_loss: 0.1055\n",
      "Train accuracy: 8.037730333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4453; D_loss_gauss: 0.2618; G_loss: 16.96, reco_loss: 0.1243\n",
      "the 1-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4323; D_loss_gauss: 0.2534; G_loss: 17.18, reco_loss: 0.1039\n",
      "the 2-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4676; D_loss_gauss: 0.238; G_loss: 16.45, reco_loss: 0.1028\n",
      "the 3-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4394; D_loss_gauss: 0.2264; G_loss: 16.35, reco_loss: 0.1025\n",
      "the 4-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4424; D_loss_gauss: 0.2004; G_loss: 16.47, reco_loss: 0.1027\n",
      "the 5-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4323; D_loss_gauss: 0.1829; G_loss: 16.41, reco_loss: 0.102\n",
      "the 6-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4353; D_loss_gauss: 0.1738; G_loss: 16.07, reco_loss: 0.1011\n",
      "the 7-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4509; D_loss_gauss: 0.1573; G_loss: 16.26, reco_loss: 0.1004\n",
      "the 8-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4497; D_loss_gauss: 0.1523; G_loss: 16.25, reco_loss: 0.09996\n",
      "the 9-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4358; D_loss_gauss: 0.1429; G_loss: 15.66, reco_loss: 0.09936\n",
      "the 10-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4247; D_loss_gauss: 0.1182; G_loss: 15.74, reco_loss: 0.1004\n",
      "the 11-th batch at \n",
      "Epoch-137; D_loss_cat: 0.4347; D_loss_gauss: 0.1158; G_loss: 15.85, reco_loss: 0.09895\n",
      "Train accuracy: 8.068038 %\n",
      "the 0-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4176; D_loss_gauss: 0.1051; G_loss: 14.58, reco_loss: 0.1212\n",
      "the 1-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4276; D_loss_gauss: 0.1005; G_loss: 13.27, reco_loss: 0.1266\n",
      "the 2-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4377; D_loss_gauss: 0.09816; G_loss: 11.46, reco_loss: 0.1263\n",
      "the 3-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4338; D_loss_gauss: 0.09137; G_loss: 9.535, reco_loss: 0.1238\n",
      "the 4-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4618; D_loss_gauss: 0.1144; G_loss: 7.349, reco_loss: 0.1244\n",
      "the 5-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4605; D_loss_gauss: 0.1951; G_loss: 5.878, reco_loss: 0.1249\n",
      "the 6-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4463; D_loss_gauss: 0.3831; G_loss: 4.877, reco_loss: 0.1255\n",
      "the 7-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4466; D_loss_gauss: 0.6584; G_loss: 3.88, reco_loss: 0.1259\n",
      "the 8-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4523; D_loss_gauss: 1.034; G_loss: 2.966, reco_loss: 0.1264\n",
      "the 9-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4591; D_loss_gauss: 1.429; G_loss: 3.035, reco_loss: 0.1278\n",
      "the 10-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4609; D_loss_gauss: 1.715; G_loss: 3.001, reco_loss: 0.1271\n",
      "the 11-th batch at \n",
      "Epoch-138; D_loss_cat: 0.4853; D_loss_gauss: 1.69; G_loss: 2.686, reco_loss: 0.1293\n",
      "Train accuracy: 7.997686999999999 %\n",
      "the 0-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4851; D_loss_gauss: 1.572; G_loss: 3.415, reco_loss: 0.1279\n",
      "the 1-th batch at \n",
      "Epoch-139; D_loss_cat: 0.46; D_loss_gauss: 0.5861; G_loss: 5.437, reco_loss: 0.1146\n",
      "the 2-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4559; D_loss_gauss: 0.2495; G_loss: 7.228, reco_loss: 0.1118\n",
      "the 3-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4506; D_loss_gauss: 0.1846; G_loss: 9.491, reco_loss: 0.1117\n",
      "the 4-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4729; D_loss_gauss: 0.1718; G_loss: 11.5, reco_loss: 0.1119\n",
      "the 5-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4412; D_loss_gauss: 0.1876; G_loss: 13.22, reco_loss: 0.1101\n",
      "the 6-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4384; D_loss_gauss: 0.2; G_loss: 14.66, reco_loss: 0.1077\n",
      "the 7-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4435; D_loss_gauss: 0.205; G_loss: 15.73, reco_loss: 0.1079\n",
      "the 8-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4399; D_loss_gauss: 0.2217; G_loss: 16.63, reco_loss: 0.1054\n",
      "the 9-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4444; D_loss_gauss: 0.2192; G_loss: 17.46, reco_loss: 0.1046\n",
      "the 10-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4337; D_loss_gauss: 0.2239; G_loss: 18.05, reco_loss: 0.104\n",
      "the 11-th batch at \n",
      "Epoch-139; D_loss_cat: 0.4199; D_loss_gauss: 0.2325; G_loss: 18.44, reco_loss: 0.1024\n",
      "Train accuracy: 8.063579333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4287; D_loss_gauss: 0.2326; G_loss: 18.58, reco_loss: 0.121\n",
      "the 1-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4208; D_loss_gauss: 0.2238; G_loss: 19.04, reco_loss: 0.1005\n",
      "the 2-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4177; D_loss_gauss: 0.223; G_loss: 19.03, reco_loss: 0.101\n",
      "the 3-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4073; D_loss_gauss: 0.2044; G_loss: 19.22, reco_loss: 0.1006\n",
      "the 4-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4251; D_loss_gauss: 0.2031; G_loss: 19.1, reco_loss: 0.09983\n",
      "the 5-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4212; D_loss_gauss: 0.1785; G_loss: 19.15, reco_loss: 0.09918\n",
      "the 6-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4151; D_loss_gauss: 0.177; G_loss: 19.01, reco_loss: 0.1003\n",
      "the 7-th batch at \n",
      "Epoch-140; D_loss_cat: 0.423; D_loss_gauss: 0.1554; G_loss: 18.78, reco_loss: 0.09906\n",
      "the 8-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4163; D_loss_gauss: 0.1492; G_loss: 18.97, reco_loss: 0.09848\n",
      "the 9-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4084; D_loss_gauss: 0.1337; G_loss: 18.88, reco_loss: 0.09792\n",
      "the 10-th batch at \n",
      "Epoch-140; D_loss_cat: 0.4152; D_loss_gauss: 0.1237; G_loss: 18.58, reco_loss: 0.098\n",
      "the 11-th batch at \n",
      "Epoch-140; D_loss_cat: 0.3862; D_loss_gauss: 0.1182; G_loss: 18.41, reco_loss: 0.0975\n",
      "Train accuracy: 8.087761333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-141; D_loss_cat: 0.3966; D_loss_gauss: 0.1054; G_loss: 17.44, reco_loss: 0.1186\n",
      "the 1-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4329; D_loss_gauss: 0.09418; G_loss: 15.8, reco_loss: 0.1225\n",
      "the 2-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4423; D_loss_gauss: 0.09078; G_loss: 13.48, reco_loss: 0.1231\n",
      "the 3-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4587; D_loss_gauss: 0.08624; G_loss: 10.63, reco_loss: 0.1232\n",
      "the 4-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4516; D_loss_gauss: 0.1047; G_loss: 8.138, reco_loss: 0.1236\n",
      "the 5-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4611; D_loss_gauss: 0.1943; G_loss: 5.901, reco_loss: 0.1248\n",
      "the 6-th batch at \n",
      "Epoch-141; D_loss_cat: 0.471; D_loss_gauss: 0.4239; G_loss: 4.217, reco_loss: 0.1267\n",
      "the 7-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4681; D_loss_gauss: 0.8418; G_loss: 3.323, reco_loss: 0.1265\n",
      "the 8-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4466; D_loss_gauss: 1.436; G_loss: 3.053, reco_loss: 0.1264\n",
      "the 9-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4741; D_loss_gauss: 1.997; G_loss: 2.472, reco_loss: 0.1276\n",
      "the 10-th batch at \n",
      "Epoch-141; D_loss_cat: 0.459; D_loss_gauss: 2.188; G_loss: 2.805, reco_loss: 0.128\n",
      "the 11-th batch at \n",
      "Epoch-141; D_loss_cat: 0.4606; D_loss_gauss: 1.985; G_loss: 3.197, reco_loss: 0.1287\n",
      "Train accuracy: 7.9767063333333335 %\n",
      "the 0-th batch at \n",
      "Epoch-142; D_loss_cat: 0.446; D_loss_gauss: 1.725; G_loss: 3.33, reco_loss: 0.1282\n",
      "the 1-th batch at \n",
      "Epoch-142; D_loss_cat: 0.452; D_loss_gauss: 0.5745; G_loss: 5.261, reco_loss: 0.113\n",
      "the 2-th batch at \n",
      "Epoch-142; D_loss_cat: 0.455; D_loss_gauss: 0.2794; G_loss: 7.849, reco_loss: 0.1126\n",
      "the 3-th batch at \n",
      "Epoch-142; D_loss_cat: 0.458; D_loss_gauss: 0.2273; G_loss: 10.01, reco_loss: 0.1128\n",
      "the 4-th batch at \n",
      "Epoch-142; D_loss_cat: 0.4492; D_loss_gauss: 0.2462; G_loss: 11.7, reco_loss: 0.1123\n",
      "the 5-th batch at \n",
      "Epoch-142; D_loss_cat: 0.4581; D_loss_gauss: 0.2917; G_loss: 13.56, reco_loss: 0.1105\n",
      "the 6-th batch at \n",
      "Epoch-142; D_loss_cat: 0.4458; D_loss_gauss: 0.334; G_loss: 14.99, reco_loss: 0.1086\n",
      "the 7-th batch at \n",
      "Epoch-142; D_loss_cat: 0.454; D_loss_gauss: 0.3385; G_loss: 15.63, reco_loss: 0.1081\n",
      "the 8-th batch at \n",
      "Epoch-142; D_loss_cat: 0.4612; D_loss_gauss: 0.366; G_loss: 16.62, reco_loss: 0.1063\n",
      "the 9-th batch at \n",
      "Epoch-142; D_loss_cat: 0.4623; D_loss_gauss: 0.3682; G_loss: 17.62, reco_loss: 0.1046\n",
      "the 10-th batch at \n",
      "Epoch-142; D_loss_cat: 0.4402; D_loss_gauss: 0.349; G_loss: 17.97, reco_loss: 0.1034\n",
      "the 11-th batch at \n",
      "Epoch-142; D_loss_cat: 0.4327; D_loss_gauss: 0.3417; G_loss: 18.17, reco_loss: 0.1033\n",
      "Train accuracy: 8.059841666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-143; D_loss_cat: 0.431; D_loss_gauss: 0.3295; G_loss: 18.34, reco_loss: 0.121\n",
      "the 1-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4502; D_loss_gauss: 0.3073; G_loss: 18.04, reco_loss: 0.1015\n",
      "the 2-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4283; D_loss_gauss: 0.295; G_loss: 17.66, reco_loss: 0.1008\n",
      "the 3-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4281; D_loss_gauss: 0.2591; G_loss: 17.9, reco_loss: 0.1008\n",
      "the 4-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4189; D_loss_gauss: 0.2568; G_loss: 17.95, reco_loss: 0.09904\n",
      "the 5-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4208; D_loss_gauss: 0.2217; G_loss: 17.98, reco_loss: 0.09824\n",
      "the 6-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4299; D_loss_gauss: 0.2147; G_loss: 17.33, reco_loss: 0.09941\n",
      "the 7-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4257; D_loss_gauss: 0.1875; G_loss: 17.37, reco_loss: 0.09869\n",
      "the 8-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4117; D_loss_gauss: 0.1734; G_loss: 17.43, reco_loss: 0.09787\n",
      "the 9-th batch at \n",
      "Epoch-143; D_loss_cat: 0.4153; D_loss_gauss: 0.1587; G_loss: 16.88, reco_loss: 0.09804\n",
      "the 10-th batch at \n",
      "Epoch-143; D_loss_cat: 0.417; D_loss_gauss: 0.1449; G_loss: 16.69, reco_loss: 0.09807\n",
      "the 11-th batch at \n",
      "Epoch-143; D_loss_cat: 0.3977; D_loss_gauss: 0.1369; G_loss: 16.95, reco_loss: 0.0976\n",
      "Train accuracy: 8.088811 %\n",
      "the 0-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4027; D_loss_gauss: 0.1269; G_loss: 15.48, reco_loss: 0.1185\n",
      "the 1-th batch at \n",
      "Epoch-144; D_loss_cat: 0.409; D_loss_gauss: 0.1185; G_loss: 13.96, reco_loss: 0.124\n",
      "the 2-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4221; D_loss_gauss: 0.1082; G_loss: 12.61, reco_loss: 0.124\n",
      "the 3-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4421; D_loss_gauss: 0.1029; G_loss: 10.49, reco_loss: 0.1222\n",
      "the 4-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4496; D_loss_gauss: 0.1186; G_loss: 7.786, reco_loss: 0.1256\n",
      "the 5-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4665; D_loss_gauss: 0.1797; G_loss: 6.102, reco_loss: 0.1248\n",
      "the 6-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4668; D_loss_gauss: 0.364; G_loss: 4.795, reco_loss: 0.1279\n",
      "the 7-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4668; D_loss_gauss: 0.6324; G_loss: 3.669, reco_loss: 0.1271\n",
      "the 8-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4617; D_loss_gauss: 1.05; G_loss: 3.357, reco_loss: 0.1266\n",
      "the 9-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4657; D_loss_gauss: 1.595; G_loss: 3.042, reco_loss: 0.1269\n",
      "the 10-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4601; D_loss_gauss: 1.893; G_loss: 2.773, reco_loss: 0.1274\n",
      "the 11-th batch at \n",
      "Epoch-144; D_loss_cat: 0.4573; D_loss_gauss: 1.847; G_loss: 2.976, reco_loss: 0.1288\n",
      "Train accuracy: 8.002768000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4642; D_loss_gauss: 1.541; G_loss: 4.191, reco_loss: 0.1289\n",
      "the 1-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4629; D_loss_gauss: 0.4807; G_loss: 7.364, reco_loss: 0.1157\n",
      "the 2-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4771; D_loss_gauss: 0.2734; G_loss: 10.09, reco_loss: 0.1148\n",
      "the 3-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4603; D_loss_gauss: 0.2569; G_loss: 12.78, reco_loss: 0.1141\n",
      "the 4-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4561; D_loss_gauss: 0.3051; G_loss: 14.91, reco_loss: 0.113\n",
      "the 5-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4475; D_loss_gauss: 0.3518; G_loss: 16.65, reco_loss: 0.1103\n",
      "the 6-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4478; D_loss_gauss: 0.3924; G_loss: 17.92, reco_loss: 0.1093\n",
      "the 7-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4662; D_loss_gauss: 0.417; G_loss: 18.84, reco_loss: 0.108\n",
      "the 8-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4609; D_loss_gauss: 0.4026; G_loss: 19.74, reco_loss: 0.1064\n",
      "the 9-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4384; D_loss_gauss: 0.3814; G_loss: 20.42, reco_loss: 0.1052\n",
      "the 10-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4541; D_loss_gauss: 0.3484; G_loss: 20.47, reco_loss: 0.1044\n",
      "the 11-th batch at \n",
      "Epoch-145; D_loss_cat: 0.4646; D_loss_gauss: 0.3277; G_loss: 20.41, reco_loss: 0.1028\n",
      "Train accuracy: 8.050213999999999 %\n",
      "the 0-th batch at \n",
      "Epoch-146; D_loss_cat: 0.453; D_loss_gauss: 0.2923; G_loss: 19.78, reco_loss: 0.1214\n",
      "the 1-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4359; D_loss_gauss: 0.2715; G_loss: 19.21, reco_loss: 0.1011\n",
      "the 2-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4327; D_loss_gauss: 0.2452; G_loss: 18.86, reco_loss: 0.09965\n",
      "the 3-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4415; D_loss_gauss: 0.2333; G_loss: 18.52, reco_loss: 0.09995\n",
      "the 4-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4436; D_loss_gauss: 0.2004; G_loss: 18.15, reco_loss: 0.09981\n",
      "the 5-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4425; D_loss_gauss: 0.1993; G_loss: 17.96, reco_loss: 0.09965\n",
      "the 6-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4265; D_loss_gauss: 0.1811; G_loss: 17.95, reco_loss: 0.0984\n",
      "the 7-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4347; D_loss_gauss: 0.1622; G_loss: 17.47, reco_loss: 0.0989\n",
      "the 8-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4253; D_loss_gauss: 0.1593; G_loss: 17.35, reco_loss: 0.09846\n",
      "the 9-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4202; D_loss_gauss: 0.142; G_loss: 17.57, reco_loss: 0.09769\n",
      "the 10-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4135; D_loss_gauss: 0.1306; G_loss: 16.98, reco_loss: 0.09804\n",
      "the 11-th batch at \n",
      "Epoch-146; D_loss_cat: 0.4138; D_loss_gauss: 0.1214; G_loss: 16.81, reco_loss: 0.09708\n",
      "Train accuracy: 8.078075000000002 %\n",
      "the 0-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4057; D_loss_gauss: 0.117; G_loss: 15.49, reco_loss: 0.1177\n",
      "the 1-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4422; D_loss_gauss: 0.1053; G_loss: 13.81, reco_loss: 0.1237\n",
      "the 2-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4342; D_loss_gauss: 0.1018; G_loss: 11.05, reco_loss: 0.1217\n",
      "the 3-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4489; D_loss_gauss: 0.1159; G_loss: 8.691, reco_loss: 0.1239\n",
      "the 4-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4655; D_loss_gauss: 0.204; G_loss: 6.171, reco_loss: 0.1251\n",
      "the 5-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4659; D_loss_gauss: 0.4332; G_loss: 4.536, reco_loss: 0.1242\n",
      "the 6-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4651; D_loss_gauss: 0.8094; G_loss: 3.787, reco_loss: 0.1282\n",
      "the 7-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4554; D_loss_gauss: 1.162; G_loss: 3.209, reco_loss: 0.1272\n",
      "the 8-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4568; D_loss_gauss: 1.538; G_loss: 2.868, reco_loss: 0.1281\n",
      "the 9-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4552; D_loss_gauss: 1.872; G_loss: 2.896, reco_loss: 0.1273\n",
      "the 10-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4723; D_loss_gauss: 1.9; G_loss: 2.82, reco_loss: 0.1275\n",
      "the 11-th batch at \n",
      "Epoch-147; D_loss_cat: 0.4588; D_loss_gauss: 1.638; G_loss: 3.138, reco_loss: 0.128\n",
      "Train accuracy: 8.004623666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4667; D_loss_gauss: 1.373; G_loss: 4.12, reco_loss: 0.1278\n",
      "the 1-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4641; D_loss_gauss: 0.481; G_loss: 6.924, reco_loss: 0.113\n",
      "the 2-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4627; D_loss_gauss: 0.2769; G_loss: 9.25, reco_loss: 0.1123\n",
      "the 3-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4639; D_loss_gauss: 0.2605; G_loss: 11.4, reco_loss: 0.1115\n",
      "the 4-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4658; D_loss_gauss: 0.2707; G_loss: 13.03, reco_loss: 0.1088\n",
      "the 5-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4612; D_loss_gauss: 0.2844; G_loss: 14.5, reco_loss: 0.108\n",
      "the 6-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4529; D_loss_gauss: 0.3243; G_loss: 16.44, reco_loss: 0.1071\n",
      "the 7-th batch at \n",
      "Epoch-148; D_loss_cat: 0.447; D_loss_gauss: 0.3412; G_loss: 17.9, reco_loss: 0.1075\n",
      "the 8-th batch at \n",
      "Epoch-148; D_loss_cat: 0.448; D_loss_gauss: 0.3544; G_loss: 18.59, reco_loss: 0.105\n",
      "the 9-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4621; D_loss_gauss: 0.3445; G_loss: 19.26, reco_loss: 0.1037\n",
      "the 10-th batch at \n",
      "Epoch-148; D_loss_cat: 0.435; D_loss_gauss: 0.3353; G_loss: 19.89, reco_loss: 0.1036\n",
      "the 11-th batch at \n",
      "Epoch-148; D_loss_cat: 0.4455; D_loss_gauss: 0.337; G_loss: 20.15, reco_loss: 0.1019\n",
      "Train accuracy: 8.052132666666665 %\n",
      "the 0-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4419; D_loss_gauss: 0.3245; G_loss: 20.32, reco_loss: 0.1204\n",
      "the 1-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4541; D_loss_gauss: 0.3011; G_loss: 20.29, reco_loss: 0.101\n",
      "the 2-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4488; D_loss_gauss: 0.2799; G_loss: 20.18, reco_loss: 0.101\n",
      "the 3-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4529; D_loss_gauss: 0.2522; G_loss: 20.01, reco_loss: 0.1004\n",
      "the 4-th batch at \n",
      "Epoch-149; D_loss_cat: 0.431; D_loss_gauss: 0.249; G_loss: 20.22, reco_loss: 0.09956\n",
      "the 5-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4291; D_loss_gauss: 0.2256; G_loss: 19.88, reco_loss: 0.09855\n",
      "the 6-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4208; D_loss_gauss: 0.2085; G_loss: 19.68, reco_loss: 0.09821\n",
      "the 7-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4472; D_loss_gauss: 0.1874; G_loss: 19.16, reco_loss: 0.09777\n",
      "the 8-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4345; D_loss_gauss: 0.1784; G_loss: 18.97, reco_loss: 0.09797\n",
      "the 9-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4299; D_loss_gauss: 0.1703; G_loss: 19.03, reco_loss: 0.09663\n",
      "the 10-th batch at \n",
      "Epoch-149; D_loss_cat: 0.429; D_loss_gauss: 0.1523; G_loss: 18.75, reco_loss: 0.09662\n",
      "the 11-th batch at \n",
      "Epoch-149; D_loss_cat: 0.4377; D_loss_gauss: 0.1395; G_loss: 18.53, reco_loss: 0.09662\n",
      "Train accuracy: 8.064672 %\n",
      "the 0-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4271; D_loss_gauss: 0.1262; G_loss: 17.33, reco_loss: 0.1181\n",
      "the 1-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4318; D_loss_gauss: 0.1206; G_loss: 15.08, reco_loss: 0.1244\n",
      "the 2-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4478; D_loss_gauss: 0.1167; G_loss: 12.25, reco_loss: 0.1285\n",
      "the 3-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4697; D_loss_gauss: 0.1144; G_loss: 9.683, reco_loss: 0.1251\n",
      "the 4-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4542; D_loss_gauss: 0.1805; G_loss: 6.987, reco_loss: 0.1266\n",
      "the 5-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4664; D_loss_gauss: 0.432; G_loss: 4.702, reco_loss: 0.1297\n",
      "the 6-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4626; D_loss_gauss: 0.8286; G_loss: 3.703, reco_loss: 0.1315\n",
      "the 7-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4806; D_loss_gauss: 1.265; G_loss: 3.159, reco_loss: 0.1284\n",
      "the 8-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4894; D_loss_gauss: 1.686; G_loss: 2.594, reco_loss: 0.1305\n",
      "the 9-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4535; D_loss_gauss: 1.944; G_loss: 2.999, reco_loss: 0.1295\n",
      "the 10-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4364; D_loss_gauss: 1.983; G_loss: 3.159, reco_loss: 0.1296\n",
      "the 11-th batch at \n",
      "Epoch-150; D_loss_cat: 0.4683; D_loss_gauss: 1.827; G_loss: 2.873, reco_loss: 0.129\n",
      "Train accuracy: 7.992995000000001 %\n",
      "the 0-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4542; D_loss_gauss: 1.679; G_loss: 3.342, reco_loss: 0.1292\n",
      "the 1-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4658; D_loss_gauss: 0.5774; G_loss: 5.389, reco_loss: 0.1183\n",
      "the 2-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4614; D_loss_gauss: 0.2916; G_loss: 7.431, reco_loss: 0.119\n",
      "the 3-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4535; D_loss_gauss: 0.2596; G_loss: 9.547, reco_loss: 0.1166\n",
      "the 4-th batch at \n",
      "Epoch-151; D_loss_cat: 0.455; D_loss_gauss: 0.2651; G_loss: 10.97, reco_loss: 0.1139\n",
      "the 5-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4523; D_loss_gauss: 0.2949; G_loss: 12.09, reco_loss: 0.1133\n",
      "the 6-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4524; D_loss_gauss: 0.3169; G_loss: 13.25, reco_loss: 0.1104\n",
      "the 7-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4443; D_loss_gauss: 0.3325; G_loss: 14.17, reco_loss: 0.1093\n",
      "the 8-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4418; D_loss_gauss: 0.3514; G_loss: 14.56, reco_loss: 0.1078\n",
      "the 9-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4486; D_loss_gauss: 0.3479; G_loss: 14.85, reco_loss: 0.1058\n",
      "the 10-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4178; D_loss_gauss: 0.3645; G_loss: 15.53, reco_loss: 0.1054\n",
      "the 11-th batch at \n",
      "Epoch-151; D_loss_cat: 0.4742; D_loss_gauss: 0.3621; G_loss: 15.47, reco_loss: 0.1031\n",
      "Train accuracy: 8.050247666666667 %\n",
      "the 0-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4446; D_loss_gauss: 0.3431; G_loss: 15.39, reco_loss: 0.1217\n",
      "the 1-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4284; D_loss_gauss: 0.3231; G_loss: 16.09, reco_loss: 0.1015\n",
      "the 2-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4238; D_loss_gauss: 0.3072; G_loss: 15.95, reco_loss: 0.1013\n",
      "the 3-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4403; D_loss_gauss: 0.2803; G_loss: 15.17, reco_loss: 0.1001\n",
      "the 4-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4491; D_loss_gauss: 0.2532; G_loss: 15.31, reco_loss: 0.09999\n",
      "the 5-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4295; D_loss_gauss: 0.2352; G_loss: 15.36, reco_loss: 0.09937\n",
      "the 6-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4583; D_loss_gauss: 0.2349; G_loss: 14.7, reco_loss: 0.09846\n",
      "the 7-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4539; D_loss_gauss: 0.2173; G_loss: 15.42, reco_loss: 0.09927\n",
      "the 8-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4399; D_loss_gauss: 0.1977; G_loss: 15.51, reco_loss: 0.09813\n",
      "the 9-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4412; D_loss_gauss: 0.1801; G_loss: 14.77, reco_loss: 0.09866\n",
      "the 10-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4158; D_loss_gauss: 0.1725; G_loss: 14.78, reco_loss: 0.09846\n",
      "the 11-th batch at \n",
      "Epoch-152; D_loss_cat: 0.4234; D_loss_gauss: 0.1515; G_loss: 15.03, reco_loss: 0.09646\n",
      "Train accuracy: 8.071653666666666 %\n",
      "the 0-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4327; D_loss_gauss: 0.1407; G_loss: 13.38, reco_loss: 0.1186\n",
      "the 1-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4453; D_loss_gauss: 0.1328; G_loss: 12.17, reco_loss: 0.1277\n",
      "the 2-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4505; D_loss_gauss: 0.1294; G_loss: 11.0, reco_loss: 0.1253\n",
      "the 3-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4621; D_loss_gauss: 0.1308; G_loss: 8.76, reco_loss: 0.1236\n",
      "the 4-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4515; D_loss_gauss: 0.1645; G_loss: 6.425, reco_loss: 0.1262\n",
      "the 5-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4784; D_loss_gauss: 0.2835; G_loss: 5.765, reco_loss: 0.1245\n",
      "the 6-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4946; D_loss_gauss: 0.4706; G_loss: 4.433, reco_loss: 0.1267\n",
      "the 7-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4638; D_loss_gauss: 0.6756; G_loss: 3.227, reco_loss: 0.125\n",
      "the 8-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4903; D_loss_gauss: 1.012; G_loss: 3.422, reco_loss: 0.1269\n",
      "the 9-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4612; D_loss_gauss: 1.411; G_loss: 3.224, reco_loss: 0.1265\n",
      "the 10-th batch at \n",
      "Epoch-153; D_loss_cat: 0.4424; D_loss_gauss: 1.817; G_loss: 2.545, reco_loss: 0.1264\n",
      "the 11-th batch at \n",
      "Epoch-153; D_loss_cat: 0.466; D_loss_gauss: 2.0; G_loss: 2.575, reco_loss: 0.1284\n",
      "Train accuracy: 8.011190333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4636; D_loss_gauss: 1.943; G_loss: 3.254, reco_loss: 0.1283\n",
      "the 1-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4654; D_loss_gauss: 0.7952; G_loss: 4.595, reco_loss: 0.1127\n",
      "the 2-th batch at \n",
      "Epoch-154; D_loss_cat: 0.449; D_loss_gauss: 0.39; G_loss: 5.911, reco_loss: 0.1122\n",
      "the 3-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4662; D_loss_gauss: 0.2599; G_loss: 7.778, reco_loss: 0.1103\n",
      "the 4-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4496; D_loss_gauss: 0.2445; G_loss: 9.225, reco_loss: 0.1109\n",
      "the 5-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4485; D_loss_gauss: 0.2396; G_loss: 10.49, reco_loss: 0.1094\n",
      "the 6-th batch at \n",
      "Epoch-154; D_loss_cat: 0.456; D_loss_gauss: 0.2597; G_loss: 11.78, reco_loss: 0.1071\n",
      "the 7-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4637; D_loss_gauss: 0.2646; G_loss: 12.88, reco_loss: 0.1053\n",
      "the 8-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4478; D_loss_gauss: 0.3035; G_loss: 13.47, reco_loss: 0.1053\n",
      "the 9-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4571; D_loss_gauss: 0.2941; G_loss: 13.98, reco_loss: 0.1026\n",
      "the 10-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4642; D_loss_gauss: 0.3004; G_loss: 14.64, reco_loss: 0.1016\n",
      "the 11-th batch at \n",
      "Epoch-154; D_loss_cat: 0.4439; D_loss_gauss: 0.302; G_loss: 15.2, reco_loss: 0.1016\n",
      "Train accuracy: 8.035474 %\n",
      "the 0-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4365; D_loss_gauss: 0.2795; G_loss: 15.69, reco_loss: 0.12\n",
      "the 1-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4596; D_loss_gauss: 0.283; G_loss: 15.86, reco_loss: 0.09955\n",
      "the 2-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4457; D_loss_gauss: 0.261; G_loss: 16.14, reco_loss: 0.09869\n",
      "the 3-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4504; D_loss_gauss: 0.248; G_loss: 16.12, reco_loss: 0.09835\n",
      "the 4-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4564; D_loss_gauss: 0.2257; G_loss: 16.13, reco_loss: 0.09941\n",
      "the 5-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4625; D_loss_gauss: 0.2205; G_loss: 16.52, reco_loss: 0.09857\n",
      "the 6-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4514; D_loss_gauss: 0.2146; G_loss: 16.72, reco_loss: 0.09822\n",
      "the 7-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4479; D_loss_gauss: 0.1974; G_loss: 16.35, reco_loss: 0.09719\n",
      "the 8-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4401; D_loss_gauss: 0.1717; G_loss: 16.21, reco_loss: 0.09716\n",
      "the 9-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4425; D_loss_gauss: 0.1539; G_loss: 16.36, reco_loss: 0.09623\n",
      "the 10-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4505; D_loss_gauss: 0.1468; G_loss: 16.26, reco_loss: 0.097\n",
      "the 11-th batch at \n",
      "Epoch-155; D_loss_cat: 0.4327; D_loss_gauss: 0.1457; G_loss: 16.02, reco_loss: 0.09713\n",
      "Train accuracy: 8.059968333333332 %\n",
      "the 0-th batch at \n",
      "Epoch-156; D_loss_cat: 0.432; D_loss_gauss: 0.1301; G_loss: 15.01, reco_loss: 0.1183\n",
      "the 1-th batch at \n",
      "Epoch-156; D_loss_cat: 0.427; D_loss_gauss: 0.1223; G_loss: 13.89, reco_loss: 0.1211\n",
      "the 2-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4659; D_loss_gauss: 0.1134; G_loss: 12.1, reco_loss: 0.1225\n",
      "the 3-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4444; D_loss_gauss: 0.1088; G_loss: 10.17, reco_loss: 0.1202\n",
      "the 4-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4793; D_loss_gauss: 0.1301; G_loss: 8.013, reco_loss: 0.1214\n",
      "the 5-th batch at \n",
      "Epoch-156; D_loss_cat: 0.45; D_loss_gauss: 0.1918; G_loss: 5.832, reco_loss: 0.1226\n",
      "the 6-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4669; D_loss_gauss: 0.3895; G_loss: 4.306, reco_loss: 0.1256\n",
      "the 7-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4826; D_loss_gauss: 0.7494; G_loss: 3.659, reco_loss: 0.1267\n",
      "the 8-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4553; D_loss_gauss: 1.183; G_loss: 3.32, reco_loss: 0.1273\n",
      "the 9-th batch at \n",
      "Epoch-156; D_loss_cat: 0.455; D_loss_gauss: 1.677; G_loss: 2.83, reco_loss: 0.1282\n",
      "the 10-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4628; D_loss_gauss: 1.884; G_loss: 2.814, reco_loss: 0.1275\n",
      "the 11-th batch at \n",
      "Epoch-156; D_loss_cat: 0.4582; D_loss_gauss: 1.737; G_loss: 3.236, reco_loss: 0.1276\n",
      "Train accuracy: 8.012309333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4611; D_loss_gauss: 1.521; G_loss: 3.695, reco_loss: 0.1272\n",
      "the 1-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4559; D_loss_gauss: 0.4043; G_loss: 6.654, reco_loss: 0.1162\n",
      "the 2-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4573; D_loss_gauss: 0.2224; G_loss: 9.952, reco_loss: 0.1176\n",
      "the 3-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4553; D_loss_gauss: 0.222; G_loss: 12.32, reco_loss: 0.1166\n",
      "the 4-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4662; D_loss_gauss: 0.2622; G_loss: 13.68, reco_loss: 0.1156\n",
      "the 5-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4723; D_loss_gauss: 0.2845; G_loss: 15.7, reco_loss: 0.1137\n",
      "the 6-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4405; D_loss_gauss: 0.3145; G_loss: 17.88, reco_loss: 0.11\n",
      "the 7-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4707; D_loss_gauss: 0.321; G_loss: 19.03, reco_loss: 0.1081\n",
      "the 8-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4574; D_loss_gauss: 0.3233; G_loss: 19.91, reco_loss: 0.1084\n",
      "the 9-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4763; D_loss_gauss: 0.3074; G_loss: 21.08, reco_loss: 0.1058\n",
      "the 10-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4694; D_loss_gauss: 0.3065; G_loss: 21.13, reco_loss: 0.1043\n",
      "the 11-th batch at \n",
      "Epoch-157; D_loss_cat: 0.4402; D_loss_gauss: 0.2961; G_loss: 20.61, reco_loss: 0.1038\n",
      "Train accuracy: 8.057989333333333 %\n",
      "the 0-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4389; D_loss_gauss: 0.287; G_loss: 20.75, reco_loss: 0.1213\n",
      "the 1-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4589; D_loss_gauss: 0.2647; G_loss: 19.99, reco_loss: 0.1004\n",
      "the 2-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4254; D_loss_gauss: 0.2515; G_loss: 19.45, reco_loss: 0.1012\n",
      "the 3-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4546; D_loss_gauss: 0.2249; G_loss: 18.65, reco_loss: 0.09999\n",
      "the 4-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4581; D_loss_gauss: 0.2195; G_loss: 18.74, reco_loss: 0.09998\n",
      "the 5-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4425; D_loss_gauss: 0.202; G_loss: 18.59, reco_loss: 0.09933\n",
      "the 6-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4395; D_loss_gauss: 0.1895; G_loss: 18.59, reco_loss: 0.09838\n",
      "the 7-th batch at \n",
      "Epoch-158; D_loss_cat: 0.43; D_loss_gauss: 0.1741; G_loss: 18.44, reco_loss: 0.09775\n",
      "the 8-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4241; D_loss_gauss: 0.1531; G_loss: 18.2, reco_loss: 0.09729\n",
      "the 9-th batch at \n",
      "Epoch-158; D_loss_cat: 0.4283; D_loss_gauss: 0.1449; G_loss: 17.74, reco_loss: 0.09701\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-b57262f24d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-264-a2644fabcd22>\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m(train_labeled_loader)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                                          \u001b[0mQ_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_generator_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                                          \u001b[0mD_cat_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_gauss_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                                                          train_labeled_loader)\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labeled_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-263-adee93c753b8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, P, Q, D_cat, D_gauss, P_solver, Q_solver, Q_generator_solver, D_cat_solver, D_gauss_solver, train_labeled_loader)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mrecon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTINY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTINY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mrecon_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mP_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mQ_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munless\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvolatile\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hxiong/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Q, P = generate_model(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
