{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "train_mnist = loadmat('mnist_train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_mnist['train_X']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_mnist['train_labels']\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyMNISTDataset(object):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataset = MyMNISTDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=2000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label-added VAE and multi-classifier model and training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 250 \n",
    "epochs = 10 \n",
    "rnd_seed = 5\n",
    "log_interval = 10\n",
    "num_clusters = 10\n",
    "\n",
    "input_label_dim, h1_dim, h2_dim, h3_dim, embed_dim, output_dim  = 784 + num_cluster, 500, 500, 2000, 10, 784\n",
    "\n",
    "input_dim, g_dim = 784, 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define discriminative model p(y|x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class multiclassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(multiclassifier, self).__init__()\n",
    "        # hidden layer \n",
    "        self.fc1 = nn.Linear(input_dim, g_dim)\n",
    "        self.fc2 = nn.Linear(g_dim, num_clusters)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define VAE model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        # encoder phase\n",
    "        self.fc1 = nn.Linear(input_dim, h1_dim)\n",
    "        self.fc2 = nn.Linear(h1_dim, h2_dim)\n",
    "        self.fc3 = nn.Linear(h2_dim, h3_dim)\n",
    "        self.fc41 = nn.Linear(h3_dim, embed_dim)\n",
    "        self.fc42 = nn.Linear(h3_dim, embed_dim)\n",
    "        # decoder phase\n",
    "        self.fc5 = nn.Linear(embed_dim, h3_dim)\n",
    "        self.fc6 = nn.Linear(h3_dim, h2_dim)\n",
    "        self.fc7 = nn.Linear(h2_dim, h1_dim)\n",
    "        self.fc8 = nn.Linear(h1_dim, input_dim)\n",
    "        # define activation\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h3 = self.relu(self.fc3(self.relu(self.fc2(self.relu(self.fc1(x))))))\n",
    "        return self.fc41(h3), self.fc42(h3)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        recon = self.sigmoid(self.fc8(self.relu(self.fc7(self.relu(self.fc6(self.relu(self.fc5(z))))))))\n",
    "        return recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define ELOB loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction_function = nn.BCELoss()\n",
    "reconstruction_function.size_average = False\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        data = Variable(data.float())\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader),\n",
    "                loss.data[0] / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finnally !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 200.859844\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 193.738234\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 184.248172\n",
      "====> Epoch: 1 Average loss: 172.6084\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 184.882187\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 190.426578\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 179.935188\n",
      "====> Epoch: 2 Average loss: 171.6789\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 183.365953\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 195.861500\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 181.942719\n",
      "====> Epoch: 3 Average loss: 169.8551\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 182.318984\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 188.015125\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 179.552687\n",
      "====> Epoch: 4 Average loss: 169.0107\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 187.827516\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 197.179297\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 179.025781\n",
      "====> Epoch: 5 Average loss: 169.8673\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 202.657922\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 189.743281\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 187.578609\n",
      "====> Epoch: 6 Average loss: 173.6892\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 197.519875\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 201.083594\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 179.381219\n",
      "====> Epoch: 7 Average loss: 172.4004\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 201.447031\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 192.301453\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 181.183031\n",
      "====> Epoch: 8 Average loss: 172.2737\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 184.308812\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 190.207766\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 180.419156\n",
      "====> Epoch: 9 Average loss: 171.7689\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 186.861813\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 189.521422\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 181.334313\n",
      "====> Epoch: 10 Average loss: 173.8294\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check out the trained model: generate a realistic example from 10-dim Guassian points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps = torch.FloatTensor(np.zeros(10)).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-327a04253e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "one_example = model.decode(Variable(eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b502d9ca233c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'one_example' is not defined"
     ]
    }
   ],
   "source": [
    "one_example = one_example.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_example = np.reshape(one_example, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b492a58>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEr1JREFUeJzt3V1sZOV5B/D/fz78uV/eZXEMLCyr0BKEmo1qkUpBaSqa\niKBIkIuicBFtJZTNRRo1Ui6K6EW5RFWTiIsq0qasslQpSaUEgVTUClapUFSEMJTwkQ1hQ5bCsl5D\nzK4/ZzyeeXrhQ2TA53mN5+OMef4/yfJ43jme18fznzMzz3nfl2YGEYmnVHQHRKQYCr9IUAq/SFAK\nv0hQCr9IUAq/SFAKv0hQCr9IUAq/SFCVXt7ZAAdtCKO9vEuRUGpYxIrVuZnbthV+kjcDuA9AGcC/\nmNm93u2HMIpP86Z27lJEHE/ZyU3fdssv+0mWAfwzgC8CuA7AHSSv2+rvE5Heauc9/w0ATpvZq2a2\nAuDHAG7tTLdEpNvaCf/lAF5f9/Mb2XXvQfIoySmSUw3U27g7Eemkrn/ab2bHzGzSzCarGOz23YnI\nJrUT/rMADqz7+YrsOhHZBtoJ/9MAriF5NckBAF8B8EhnuiUi3bblUp+ZrZL8GwD/hbVS33Eze6lj\nPRORrmqrzm9mjwJ4tEN9EZEe0um9IkEp/CJBKfwiQSn8IkEp/CJBKfwiQSn8IkEp/CJBKfwiQSn8\nIkEp/CJBKfwiQSn8IkEp/CJBKfwiQSn8IkEp/CJBKfwiQSn8IkEp/CJBKfwiQfV0ie6PLCZWRKb/\nHMty2d++tKkVl7em2XSbrWVuO7vZt8R+a2u/JP4uWMtvTuw3WOL39wEd+UWCUvhFglL4RYJS+EWC\nUvhFglL4RYJS+EWCaqvOT/IMgHkATQCrZjbZiU4VgRV/V3BgIL9teMjfdmTEbW+N7XDbV3f5v781\nkDhPwFFq+PVsJurhlqhnm1eLT5wfwVW/b+Xlhr/98kp+2+Kyu60tJ9prdb+9nmhfXXXbe6ETJ/n8\nhZm93YHfIyI9pJf9IkG1G34D8DjJZ0ge7USHRKQ32n3Zf6OZnSV5KYDHSP7azJ5Yf4PsSeEoAAzB\nf+8rIr3T1pHfzM5m32cAPATghg1uc8zMJs1ssorBdu5ORDpoy+EnOUpy57uXAXwBwIud6piIdFc7\nL/vHATzEtXJNBcC/mdl/dqRXItJ1Ww6/mb0K4JMd7EtXsZpfpweA0uiwv/3Ynty2xkR+GwAsXebX\n6eeu9Ov0S5f59e7WUH6t3SqJceUt/77Zam+8fqmev3113n/hOXDB/90jM/5+GX47v5Y+OJN4PFxI\nnDuRmsMhdf6Dd/5EKzFXQIeo1CcSlMIvEpTCLxKUwi8SlMIvEpTCLxLUR2bq7mQpb5c/bBb7xtzm\n5Svzy3kXD/n3feFav+xz6SfOu+1/Ojbjtjctv+w0Wx91t32nlihxuq1AteyXpRZX8vdNveE//Oam\nd7rtq8OJYdjN/PbKQtXfdinRnhgCbonp2L0pzxOzhneMjvwiQSn8IkEp/CJBKfwiQSn8IkEp/CJB\nKfwiQW2vOr8zjJLlxDLYQ/6w2uYuv95d25df91044G6K/df6kxv/1YH/ddvHqxfd9ifnPp7b9uvZ\ncXfb38/65z+Ycw4BAAyP+lNUX7ZnLrdtcNSfvvr/3FagdsEfSr06tPXhyGz4fUtOvd3wpxVPLX3e\nCzryiwSl8IsEpfCLBKXwiwSl8IsEpfCLBKXwiwS1ver87WglBkknl5rOb2sO+9se2v17t/3jg9Nu\n+8v1Cbf9v1/Pr/OvvLzL3Xb4ol8L9/5uAKhd6s9lMF3K3zef2O/PY7BryD+HYHHQ3+8lZ6qB0kpi\neuxUnb+ev/w3AFgz9Xjr0aB9h478IkEp/CJBKfwiQSn8IkEp/CJBKfwiQSn8IkEl6/wkjwP4EoAZ\nM7s+u24vgJ8AOAjgDIDbzeyd7nUzLVVXtRW/Lluar7ntA/Pe/Pf+c+glgwtu+2zTH1N/cuZat71+\nOr+Wv/tVd1NUF/z91hxInAdA/2+vfyz/Iba7mtjnu/xa/JvV/W57aTW/76XlxHj7mt+35Hj9Zm+W\n2W7HZo78PwRw8/uuuwvASTO7BsDJ7GcR2UaS4TezJwDMvu/qWwGcyC6fAHBbh/slIl221ff842Z2\nLrs8DcCfK0pE+k7bH/iZmQHIPcma5FGSUySnGvDP1RaR3tlq+M+TnACA7HvuSpJmdszMJs1ssorB\nLd6diHTaVsP/CIAj2eUjAB7uTHdEpFeS4Sf5IIAnAfwxyTdI3gngXgCfJ/kKgL/MfhaRbSRZ5zez\nO3KabupwX9qSqqvasl+35cV5t33Qmd+ezRF/25I/NvzNlTG3/dWZfW77yLn8evbQrL9fmBpWnpj6\nni3/BkND+fXwq4f99QymV/y5CND077tczx/vz2X/8ydbSdXx2xyvn5g/ohd0hp9IUAq/SFAKv0hQ\nCr9IUAq/SFAKv0hQ22vqbrc80t6QXiZKgaWG8/sT5bCGld32haZ/5uPqiv9vcqcVH2xvau7lff4N\nlq7yy5ifdqbn/vMdp9xtH5+/3m1nYtRsZcm5Qao0nBqSmyrlJYY6w4of8qsjv0hQCr9IUAq/SFAK\nv0hQCr9IUAq/SFAKv0hQ26vO70ktsd1KtKe2L+fXy1P15pnaTre94q0lDaA66NfSl/fn931ll//8\nbhX/714Z8+97/Mr3z+36XjfvezG37VBlyd12pOwPu2ViVCybWx82y7J/bgYqieisJpb4Nuf8ix4N\n99WRXyQohV8kKIVfJCiFXyQohV8kKIVfJCiFXySoj06dv01kainq/PZyzd/2d3N73fb9I4tu+8iQ\nPxfBwpX5z+GtRDF8IHEOwfioX4v/k71vuu2HB1/PbZuo+EuTDzFRK08cuho78x/egzu9JdeBUmLq\n7pTUeSOp+QR6QUd+kaAUfpGgFH6RoBR+kaAUfpGgFH6RoBR+kaCSdX6SxwF8CcCMmV2fXXcPgK8B\neCu72d1m9mi3OtkTVX9X0FmSefAd/1dPv+kvwb20b8BtL5f8OeLH987ltlUS2w5V/Hr2jqo/pn5P\n1T8PoJpcA3zrWqN+rby+O/9/OrLD3+elpSH/zlPrQKTG83vz+vdoTv/NHPl/CODmDa7/npkdzr62\nd/BFAkqG38yeAOBP1yIi20477/m/SfJ5ksdJ+q9rRaTvbDX83wdwCMBhAOcAfCfvhiSPkpwiOdWA\n//5RRHpnS+E3s/Nm1jSzFoAfALjBue0xM5s0s8kq/AUpRaR3thR+khPrfvwygPwpWkWkL22m1Pcg\ngM8BuITkGwD+AcDnSB4GYADOAPh6F/soIl2QDL+Z3bHB1fd3oS/FSszrX1rKr4fvOOvXZZtDfk15\n/gp/jnjb6deMF4by2yvVRN+a/ou/UsnfL0ur/t82Ofq73LYRTrvbnqntc9vR8udRaDm7tVXp8vlt\nre6d39ApOsNPJCiFXyQohV8kKIVfJCiFXyQohV8kqDhTd5tferHEEM3SxYXcth2vJYYDt/xpogcu\n+s/Btb3+mZGrI/nltkQFE/CrZWgmVqo+teCX+v5j5JO5bdM7d7vbvnjhMre9tOzvt+pS/h9frieG\nzS7X3GZLTO1tzhDwtRsUXwrUkV8kKIVfJCiFXyQohV8kKIVfJCiFXyQohV8kqDh1/gRLTbU8P5/b\nVi75xfIdDb+mPDTrTxNdH6u67atD+c/hqWWsUxoj/t823/Lr/P+z62Bu2+LH/G1nFvwlvKtz/h9X\nqeXv99KiP6WcNRJLdKfa+6COn6Ijv0hQCr9IUAq/SFAKv0hQCr9IUAq/SFAKv0hQcer85g9st4Zf\n528hf3x3KTXtd92fK6C6OOK2l+f89tZw/r/Rqu09v9cSy4fXLvEH/C8v5W9/fnmnu+1SLbGMdmJI\nfrmeX2tnzf+fpMbjW+rx1Ex0LrF9L+jILxKUwi8SlMIvEpTCLxKUwi8SlMIvEpTCLxJUss5P8gCA\nBwCMAzAAx8zsPpJ7AfwEwEEAZwDcbmbvdK+r/StV80VirgAmzjEo1RNjx52ncPPWqQbQGvTbVwf9\n8fyWmPe/XMmvl5fo77dKJbG8eMXfnl6pPrGEdmp+h/SCCP1vM0f+VQDfNrPrAPwZgG+QvA7AXQBO\nmtk1AE5mP4vINpEMv5mdM7Nns8vzAE4BuBzArQBOZDc7AeC2bnVSRDrvQ73nJ3kQwKcAPAVg3MzO\nZU3TWHtbICLbxKbDT3IHgJ8C+JaZza1vs7U3vRu+CSJ5lOQUyakG/HnTRKR3NhV+klWsBf9HZvaz\n7OrzJCey9gkAMxtta2bHzGzSzCar8BecFJHeSYafJAHcD+CUmX13XdMjAI5kl48AeLjz3RORbtnM\nkN7PAPgqgBdIPpdddzeAewH8O8k7AbwG4PbudLH/sew/h7LqT71tA357a9hvbzpLdDeH/VJefY//\nEKiNJZYPv9QvmR3cn1/9PbTzbXfb+br/SnGu7tcZK4tOuS4xzBrJIbn9PzV3SjL8ZvYL5K/iflNn\nuyMivaIz/ESCUvhFglL4RYJS+EWCUvhFglL4RYKKM3V3m9bOdcprTDyHDvpTULd2DbvtjT3+Et61\nvfn/xlSdvr7Xr5UvHfDr3Vf90bTb/tn9p3PbGuafg7BQ8+v8lWW3GeXl/KHQqSW4U1NvW2pIbx9M\nzZ2iI79IUAq/SFAKv0hQCr9IUAq/SFAKv0hQCr9IUKrzvysxPtubnpupsd2J5Z656re3Kn4tvjGa\n/xxeH0vU8S/369kjEwtu+8TInNs+t5p/jsJvF/a72y5Oj7rtl76dWBp9MX/aONN4fh35RaJS+EWC\nUvhFglL4RYJS+EWCUvhFglL4RYJSnX+znLqvrSSW0F72B56XLvrPwUPeXAIAgJHcFjb9Of+ZWMJ7\nubbLbX9y1p+LIHfSdwClOf/hN/ay/3fvPr3k3/U7+ecgtFb8On9qPP92GK+foiO/SFAKv0hQCr9I\nUAq/SFAKv0hQCr9IUAq/SFDJOj/JAwAeADAOwAAcM7P7SN4D4GsA3spuereZPdqtjnZdom7r1X0t\nUcdnoqaMi/P+9jP+v2n4TH4tf2TYr8PbTn/MfHNP/jkEANDY48+t36rm1+orS/5+qb6VqOO/Neu2\nNy9czG2z1P/kI1DHT9nMST6rAL5tZs+S3AngGZKPZW3fM7N/6l73RKRbkuE3s3MAzmWX50meAnB5\ntzsmIt31od7zkzwI4FMAnsqu+ibJ50keJzmWs81RklMkpxrIn1ZJRHpr0+EnuQPATwF8y8zmAHwf\nwCEAh7H2yuA7G21nZsfMbNLMJqvw3x+KSO9sKvwkq1gL/o/M7GcAYGbnzaxpZi0APwBwQ/e6KSKd\nlgw/15anvR/AKTP77rrrJ9bd7MsAXux890SkWzbzaf9nAHwVwAskn8uuuxvAHSQPY638dwbA17vS\nw37RRunHVlfbu+tGoixVyx+Wy8VEGXJh0W0vz/rLi1eq/pBhT3KZ7MT02q1EidUdlhuglJeymU/7\nf4GNR2Vv35q+iOgMP5GoFH6RoBR+kaAUfpGgFH6RoBR+kaA0dfdHQcsZbuy0AYCtJqYdX+zi8SG1\nzLVq8V2lI79IUAq/SFAKv0hQCr9IUAq/SFAKv0hQCr9IULQe1lJJvgXgtXVXXQLg7Z514MPp1771\na78A9W2rOtm3q8xs/2Zu2NPwf+DOySkzmyysA45+7Vu/9gtQ37aqqL7pZb9IUAq/SFBFh/9Ywffv\n6de+9Wu/APVtqwrpW6Hv+UWkOEUf+UWkIIWEn+TNJF8meZrkXUX0IQ/JMyRfIPkcyamC+3Kc5AzJ\nF9ddt5fkYyRfyb5vuExaQX27h+TZbN89R/KWgvp2gOTPSf6K5Esk/za7vtB95/SrkP3W85f9JMsA\nfgPg8wDeAPA0gDvM7Fc97UgOkmcATJpZ4TVhkp8FsADgATO7PrvuHwHMmtm92RPnmJn9XZ/07R4A\nC0Wv3JwtKDOxfmVpALcB+GsUuO+cft2OAvZbEUf+GwCcNrNXzWwFwI8B3FpAP/qemT0B4P2L0N8K\n4ER2+QTWHjw9l9O3vmBm58zs2ezyPIB3V5YudN85/SpEEeG/HMDr635+A/215LcBeJzkMySPFt2Z\nDYxny6YDwDSA8SI7s4Hkys299L6Vpftm321lxetO0wd+H3SjmR0G8EUA38he3vYlW3vP1k/lmk2t\n3NwrG6ws/QdF7rutrnjdaUWE/yyAA+t+viK7ri+Y2dns+wyAh9B/qw+ff3eR1Oz7TMH9+YN+Wrl5\no5Wl0Qf7rp9WvC4i/E8DuIbk1SQHAHwFwCMF9OMDSI5mH8SA5CiAL6D/Vh9+BMCR7PIRAA8X2Jf3\n6JeVm/NWlkbB+67vVrw2s55/AbgFa5/4/xbA3xfRh5x+HQLwy+zrpaL7BuBBrL0MbGDts5E7AewD\ncBLAKwAeB7C3j/r2rwBeAPA81oI2UVDfbsTaS/rnATyXfd1S9L5z+lXIftMZfiJB6QM/kaAUfpGg\nFH6RoBR+kaAUfpGgFH6RoBR+kaAUfpGg/h/JnSf283HAKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e262978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(one_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
